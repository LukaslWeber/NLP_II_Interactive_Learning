{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Common Variables and Imports",
   "id": "2f51c4a3d74244ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:15:44.932843Z",
     "start_time": "2025-01-13T11:15:30.273843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, time, warnings, pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, log_loss, pairwise_distances\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling, entropy_sampling, margin_sampling, classifier_uncertainty, classifier_entropy, classifier_margin\n",
    "from modAL.batch import uncertainty_batch_sampling\n",
    "from modAL.expected_error import expected_error_reduction\n",
    "from modAL.density import information_density\n",
    "\n",
    "from utils import load_MNIST, log_metrics, initialize_random_number_generators, create_log_reg_model, save_model_and_metrics, load_file, save_file, train_active_learner, train_active_learner_stream\n",
    "\n",
    "# Filter FutureWarnings to make outputs look more pleasant and ConvergenceWarnings which are given by sklearn LogisticRegressors when explicitly settings the multi_class to multinomial. Here, this could be omitted but I liked to leave it in for clarity to show that I'm not training 10 binary classifiers but one classifier with 10 outputs, each resembling the probabilities of a digit\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ],
   "id": "bf40dce6e55cb97a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:26:10.978995Z",
     "start_time": "2025-01-13T11:26:10.962629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RANDOM_SEED = 42\n",
    "epochs = 1500 \n",
    "model_parameters=load_file(\"shallow_classifier_parameters.pkl\")\n",
    "\n",
    "initialize_random_number_generators(RANDOM_SEED)\n",
    "\n",
    "experiment = \"2\" # \"1\" or \"2\" or \"3\"\n",
    "dataset_name = \"MNIST\""
   ],
   "id": "a8442883d6651568",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Load Dataset (MNIST)\n",
    "\n",
    "This loads the vectorized version of MNIST and normalizes values from $[0,255]$ to the range $[0,1]$\n",
    "\n",
    "The datasets are saved in the experiment folders for convenience and checking whether the splits, etc. are actually the same."
   ],
   "id": "319858033c6a6d13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:26:21.306282Z",
     "start_time": "2025-01-13T11:26:13.444002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, y_train, X_test, y_test, X_val, y_val, X_whole, y_whole = load_MNIST(random_seed=RANDOM_SEED)\n",
    "save_file(os.path.join(\"../results\", dataset_name,  f\"exp{experiment}\", \"datasets.pkl\"), {\"X_train\": X_train, \"y_train\": y_train, \"X_test\": X_test, \"y_test\": y_test})"
   ],
   "id": "8981b010982ba151",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:26:21.312063Z",
     "start_time": "2025-01-13T11:26:21.306282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "experiment_parameters = {\"1\": {\"n_initial\" : 10},\n",
    "                         \"2\": {\"n_initial\" : int(len(X_train)*0.10)},\n",
    "                         \"3\": {\"n_initial\" : int(len(X_train)*0.5)}}\n",
    "n_query_instances = 5\n",
    "n_initial = experiment_parameters[experiment][\"n_initial\"]"
   ],
   "id": "de18d1472564317f",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check how balanced the dataset is",
   "id": "9d4baeb0f1e481c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check how often each digit appears in MNIST and whether the data for each class is balanced",
   "id": "f25b1ed32e6ccbf3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:26:21.322263Z",
     "start_time": "2025-01-13T11:26:21.312063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(10):\n",
    "    print(f\"Digit {i}: {np.count_nonzero(y_whole == i)} times\")"
   ],
   "id": "1d07dcd32f95410",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit 0: 6903 times\n",
      "Digit 1: 7877 times\n",
      "Digit 2: 6990 times\n",
      "Digit 3: 7141 times\n",
      "Digit 4: 6824 times\n",
      "Digit 5: 6313 times\n",
      "Digit 6: 6876 times\n",
      "Digit 7: 7293 times\n",
      "Digit 8: 6825 times\n",
      "Digit 9: 6958 times\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Helper methods",
   "id": "59dc5c4062507364"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Creating an initial labelled dataset from random datapoints and the unlabelled pool\n",
    "\n",
    "If n_initial is smaller than 20, the model cannot be initialized properly and will throw errors so exactly one sample from each class is picked from a random permutation as the initial training set. "
   ],
   "id": "e5e2e186d810f76e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:26:21.347153Z",
     "start_time": "2025-01-13T11:26:21.322263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if n_initial == 10:\n",
    "    initial_idx = []\n",
    "    for cls in np.arange(10):\n",
    "        cls_idxs = np.where(y_train == cls)[0]\n",
    "        initial_idx.append(np.random.choice(cls_idxs))\n",
    "    # construct the X and y initial with one item from each class from a random permutation. the initial idx should keep the original mnist index.\n",
    "    # This is done to ensure that the model has an initial train set where it has seen each class\n",
    "    # Sadly, otherwise it will throw errors\n",
    "else:\n",
    "    initial_idx = np.random.choice(range(len(X_train)), size=n_initial, replace=False) # Indices with which the initial train set is created with\n",
    "\n",
    "X_initial = X_train[initial_idx]\n",
    "y_initial = y_train[initial_idx]\n",
    "pool_idx = np.setdiff1d(range(len(X_train)), initial_idx)"
   ],
   "id": "e6f0eebb42b902b6",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:26:21.399559Z",
     "start_time": "2025-01-13T11:26:21.347153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets = {'dataset_name': dataset_name,\n",
    "            'X_initial': X_initial,\n",
    "            'y_initial': y_initial,\n",
    "            'X_train': X_train,\n",
    "            'y_train': y_train,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'pool_idx': pool_idx}"
   ],
   "id": "ac9f6cba8360d401",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train a Logistic Regressor on the whole train dataset\n",
    "Use multi_class='multinomial' solver: if it were 'ovr', each of the 10 output neurons would treat the corresponding number as a one-vs-rest szenario. So we would construct a Binary Distribution for each of the output neurons. But this doesn't take care of interdependencies between classes. \n",
    "In General: 'ovr' would train a separate classifier for each number and 'multinomial' does a softmax regression\n",
    "\n",
    "The train_full_model trains the model in a number of epochs. It was done this way to check if successively training a model for max_iter iterations for a number of epochs would provide the same results as training it once for max_iter*epoch iterations."
   ],
   "id": "ff515952001c52c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T10:36:34.422109Z",
     "start_time": "2025-01-13T10:36:30.342286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_full_model():\n",
    "    log_reg_full = create_log_reg_model(model_parameters, random_seed=RANDOM_SEED)\n",
    "    \n",
    "    metrics = {'train_loss': [], 'test_loss': [], 'test_acc': []}\n",
    "    \n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        log_reg_full.fit(X_train, y_train)\n",
    "        log_metrics((epoch+1) * model_parameters[\"max_iterations_per_epoch\"], log_reg_full, X_train, y_train, X_test, y_test, metrics)\n",
    "\n",
    "    y_hat = log_reg_full.predict(X_test)\n",
    "    accuracy_whole_dataset = accuracy_score(y_test, y_hat)\n",
    "    print(f\"Test accuracy with whole Test dataset: {accuracy_whole_dataset:.4f}\")\n",
    "    print(f\"Training time: {time.time() - start:.2f} seconds\")\n",
    "    \n",
    "    return log_reg_full, metrics\n",
    "\n",
    "log_reg_whole_data, log_reg_whole_data_metrics = train_full_model()\n",
    "save_model_and_metrics(experiment, dataset_name, \"whole_dataset\", log_reg_whole_data, log_reg_whole_data_metrics)"
   ],
   "id": "30d1698ed021029a",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 18\u001B[0m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining time: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime\u001B[38;5;241m.\u001B[39mtime()\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39mstart\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m log_reg_full, metrics\n\u001B[1;32m---> 18\u001B[0m log_reg_whole_data, log_reg_whole_data_metrics \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_full_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m save_model_and_metrics(experiment, dataset_name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhole_dataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, log_reg_whole_data, log_reg_whole_data_metrics)\n",
      "Cell \u001B[1;32mIn[38], line 8\u001B[0m, in \u001B[0;36mtrain_full_model\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m----> 8\u001B[0m     \u001B[43mlog_reg_full\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     log_metrics((epoch\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m model_parameters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_iterations_per_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m], log_reg_full, X_train, y_train, X_test, y_test, metrics)\n\u001B[0;32m     11\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m log_reg_full\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\sklearn\\base.py:1389\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1382\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1384\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1385\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1386\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1387\u001B[0m     )\n\u001B[0;32m   1388\u001B[0m ):\n\u001B[1;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1350\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1347\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1348\u001B[0m     n_threads \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1350\u001B[0m fold_coefs_ \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprefer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1352\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1353\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1354\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1355\u001B[0m \u001B[43m        \u001B[49m\u001B[43mCs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mC_\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1356\u001B[0m \u001B[43m        \u001B[49m\u001B[43ml1_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ml1_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1357\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_intercept\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_intercept\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1358\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1359\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1360\u001B[0m \u001B[43m        \u001B[49m\u001B[43msolver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1361\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1362\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1363\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1364\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1365\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1366\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoef\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwarm_start_coef_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1367\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpenalty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpenalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1368\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_squared_sum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_squared_sum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1369\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1370\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_threads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_threads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1371\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1372\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mclass_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarm_start_coef_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mclasses_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarm_start_coef\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1373\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1375\u001B[0m fold_coefs_, _, n_iter_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mfold_coefs_)\n\u001B[0;32m   1376\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_iter_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(n_iter_, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint32)[:, \u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     72\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     73\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     74\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     76\u001B[0m )\n\u001B[1;32m---> 77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\joblib\\parallel.py:1918\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1916\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_sequential_output(iterable)\n\u001B[0;32m   1917\u001B[0m     \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(output)\n\u001B[0;32m   1920\u001B[0m \u001B[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001B[39;00m\n\u001B[0;32m   1921\u001B[0m \u001B[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001B[39;00m\n\u001B[0;32m   1922\u001B[0m \u001B[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001B[39;00m\n\u001B[0;32m   1923\u001B[0m \u001B[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001B[39;00m\n\u001B[0;32m   1924\u001B[0m \u001B[38;5;66;03m# callback.\u001B[39;00m\n\u001B[0;32m   1925\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\joblib\\parallel.py:1847\u001B[0m, in \u001B[0;36mParallel._get_sequential_output\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1845\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_batches \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1846\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_dispatched_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 1847\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1848\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_completed_tasks \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1849\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_progress()\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    137\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 139\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:451\u001B[0m, in \u001B[0;36m_logistic_regression_path\u001B[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001B[0m\n\u001B[0;32m    447\u001B[0m l2_reg_strength \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m (C \u001B[38;5;241m*\u001B[39m sw_sum)\n\u001B[0;32m    448\u001B[0m iprint \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m50\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m101\u001B[39m][\n\u001B[0;32m    449\u001B[0m     np\u001B[38;5;241m.\u001B[39msearchsorted(np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m]), verbose)\n\u001B[0;32m    450\u001B[0m ]\n\u001B[1;32m--> 451\u001B[0m opt_res \u001B[38;5;241m=\u001B[39m \u001B[43moptimize\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[43m    \u001B[49m\u001B[43mw0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mL-BFGS-B\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ml2_reg_strength\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_threads\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaxiter\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaxls\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# default is 20\u001B[39;49;00m\n\u001B[0;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43miprint\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43miprint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgtol\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    462\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mftol\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfinfo\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    463\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    464\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    465\u001B[0m n_iter_i \u001B[38;5;241m=\u001B[39m _check_optimize_result(\n\u001B[0;32m    466\u001B[0m     solver,\n\u001B[0;32m    467\u001B[0m     opt_res,\n\u001B[0;32m    468\u001B[0m     max_iter,\n\u001B[0;32m    469\u001B[0m     extra_warning_msg\u001B[38;5;241m=\u001B[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001B[0;32m    470\u001B[0m )\n\u001B[0;32m    471\u001B[0m w0, loss \u001B[38;5;241m=\u001B[39m opt_res\u001B[38;5;241m.\u001B[39mx, opt_res\u001B[38;5;241m.\u001B[39mfun\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:731\u001B[0m, in \u001B[0;36mminimize\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[0;32m    728\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001B[0;32m    729\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    730\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml-bfgs-b\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 731\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43m_minimize_lbfgsb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    732\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    733\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtnc\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    734\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[0;32m    735\u001B[0m                         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:407\u001B[0m, in \u001B[0;36m_minimize_lbfgsb\u001B[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001B[0m\n\u001B[0;32m    401\u001B[0m task_str \u001B[38;5;241m=\u001B[39m task\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[0;32m    402\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFG\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    403\u001B[0m     \u001B[38;5;66;03m# The minimization routine wants f and g at the current x.\u001B[39;00m\n\u001B[0;32m    404\u001B[0m     \u001B[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001B[39;00m\n\u001B[0;32m    405\u001B[0m     \u001B[38;5;66;03m# until the completion of the current minimization iteration.\u001B[39;00m\n\u001B[0;32m    406\u001B[0m     \u001B[38;5;66;03m# Overwrite f and g:\u001B[39;00m\n\u001B[1;32m--> 407\u001B[0m     f, g \u001B[38;5;241m=\u001B[39m \u001B[43mfunc_and_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNEW_X\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    409\u001B[0m     \u001B[38;5;66;03m# new iteration\u001B[39;00m\n\u001B[0;32m    410\u001B[0m     n_iterations \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:343\u001B[0m, in \u001B[0;36mScalarFunction.fun_and_grad\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    341\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray_equal(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx):\n\u001B[0;32m    342\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_x(x)\n\u001B[1;32m--> 343\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_grad()\n\u001B[0;32m    345\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:294\u001B[0m, in \u001B[0;36mScalarFunction._update_fun\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    292\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_fun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated:\n\u001B[1;32m--> 294\u001B[0m         fx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wrapped_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    295\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m fx \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lowest_f:\n\u001B[0;32m    296\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lowest_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:20\u001B[0m, in \u001B[0;36m_wrapper_fun.<locals>.wrapped\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     16\u001B[0m ncalls[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Send a copy because the user may overwrite it.\u001B[39;00m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Overwriting results in undefined behaviour because\u001B[39;00m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m fx \u001B[38;5;241m=\u001B[39m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Make sure the function returns a true scalar\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misscalar(fx):\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:79\u001B[0m, in \u001B[0;36mMemoizeJac.__call__\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m     78\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" returns the function value \"\"\"\u001B[39;00m\n\u001B[1;32m---> 79\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_if_needed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     80\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:73\u001B[0m, in \u001B[0;36mMemoizeJac._compute_if_needed\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(x \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m---> 73\u001B[0m     fg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:338\u001B[0m, in \u001B[0;36mLinearModelLoss.loss_gradient\u001B[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001B[0m\n\u001B[0;32m    336\u001B[0m grad[:, :n_features] \u001B[38;5;241m=\u001B[39m grad_pointwise\u001B[38;5;241m.\u001B[39mT \u001B[38;5;241m@\u001B[39m X \u001B[38;5;241m+\u001B[39m l2_reg_strength \u001B[38;5;241m*\u001B[39m weights\n\u001B[0;32m    337\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_intercept:\n\u001B[1;32m--> 338\u001B[0m     grad[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mgrad_pointwise\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    339\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m coef\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    340\u001B[0m     grad \u001B[38;5;241m=\u001B[39m grad\u001B[38;5;241m.\u001B[39mravel(order\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\numpy\\_core\\_methods.py:50\u001B[0m, in \u001B[0;36m_sum\u001B[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_amin\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     47\u001B[0m           initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m umr_minimum(a, axis, \u001B[38;5;28;01mNone\u001B[39;00m, out, keepdims, initial, where)\n\u001B[1;32m---> 50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_sum\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     51\u001B[0m          initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_prod\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     55\u001B[0m           initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Active Learning\n",
    "\n",
    "---"
   ],
   "id": "ca339ac4a579fa91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train a Logistic Regressor on 100 data points without Active Learning\n",
    "\n",
    "This serves as a baseline to show how much can be learnt from n_initial data points. (This is expected to be low)"
   ],
   "id": "5029f71bc2e61288"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T10:11:02.855416Z",
     "start_time": "2025-01-13T10:11:00.218189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_initial_model():\n",
    "    initialize_random_number_generators(seed=RANDOM_SEED)\n",
    "    \n",
    "    log_reg_initial = create_log_reg_model(model_parameters, random_seed=RANDOM_SEED)\n",
    "    \n",
    "    metrics = {'train_loss': [], 'train_loss_current': [], 'test_loss': [], 'test_acc': []}\n",
    "    \n",
    "    start = time.time()\n",
    "    if len(X_initial) > 0:\n",
    "        log_reg_initial.fit(X_initial, y_initial)\n",
    "        print(f\"Train time: {time.time() - start:.2f} seconds\")\n",
    "    \n",
    "    y_pred = log_reg_initial.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "     \n",
    "    train_loss_current = log_loss(y_initial, log_reg_initial.predict_proba(X_initial))\n",
    "    metrics['train_loss_current'].append(train_loss_current)\n",
    "    \n",
    "    log_metrics(model_parameters[\"max_iterations_per_epoch\"], log_reg_initial, X_train, y_train, X_test, y_test, metrics)\n",
    "\n",
    "    print(f\"Test accuracy with whole Test dataset: {accuracy:.4f}\")\n",
    "    \n",
    "    return log_reg_initial, metrics\n",
    "\n",
    "log_reg_initial, log_reg_initial_metrics = train_initial_model()\n",
    "save_model_and_metrics(experiment, dataset_name, \"initial_active_model\", log_reg_initial, log_reg_initial_metrics)"
   ],
   "id": "f070945732a153f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time: 2.31 seconds\n",
      "Iteration 50: - Train Loss: 0.2821 - Test Loss: 0.2860 - Test Accuracy: 0.9163\n",
      "Test accuracy with whole Test dataset: 0.9163\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train a Classifier with Various Query Strategies",
   "id": "b0711f048f244356"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "From the documents and maybe worth trying: If you would like to start from scratch, you can use the .fit(X, y) method to make the learner forget everything it has seen and fit the model to the newly provided data.\n",
    "\n",
    "To train only on the newly acquired data, you should pass only_new=True to the .teach() method. "
   ],
   "id": "28e693b8576a43c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random Sampling",
   "id": "e0d16dd6c5dba075"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:27:24.107821Z",
     "start_time": "2025-01-13T11:27:20.566555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def random_sampling(classifier, X_pool, n_instances):\n",
    "    n_samples = len(X_pool)\n",
    "    query_idx = np.random.choice(range(n_samples), size=n_instances, replace=False)\n",
    "    return query_idx, X_pool[query_idx]\n",
    "\n",
    "learner, metrics = train_active_learner(model_params=model_parameters, query_strat=random_sampling, n_query_instances=n_query_instances, epochs=epochs, random_seed=RANDOM_SEED, datasets=datasets, create_model=create_log_reg_model)\n",
    "save_model_and_metrics(experiment, dataset_name, \"random_sampling\", learner, metrics)"
   ],
   "id": "c0f2252e8a37778e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: - Train Loss: 0.3397 - Test Loss: 0.3261 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2255    number of train samples: 4805\n",
      "Iteration 2: - Train Loss: 0.3397 - Test Loss: 0.3261 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2258    number of train samples: 4810\n",
      "Iteration 3: - Train Loss: 0.3397 - Test Loss: 0.3261 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2257    number of train samples: 4815\n",
      "Iteration 4: - Train Loss: 0.3390 - Test Loss: 0.3263 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2244    number of train samples: 4820\n",
      "Iteration 5: - Train Loss: 0.3390 - Test Loss: 0.3263 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2242    number of train samples: 4825\n",
      "Iteration 6: - Train Loss: 0.3390 - Test Loss: 0.3263 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2240    number of train samples: 4830\n",
      "Iteration 7: - Train Loss: 0.3390 - Test Loss: 0.3263 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2238    number of train samples: 4835\n",
      "Iteration 8: - Train Loss: 0.3390 - Test Loss: 0.3263 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2238    number of train samples: 4840\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m     query_idx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice(\u001B[38;5;28mrange\u001B[39m(n_samples), size\u001B[38;5;241m=\u001B[39mn_instances, replace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m query_idx, X_pool[query_idx]\n\u001B[1;32m----> 6\u001B[0m learner, metrics \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_active_learner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_parameters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_strat\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrandom_sampling\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_query_instances\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_query_instances\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mRANDOM_SEED\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdatasets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcreate_log_reg_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m save_model_and_metrics(experiment, dataset_name, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrandom_sampling\u001B[39m\u001B[38;5;124m\"\u001B[39m, learner, metrics)\n",
      "File \u001B[1;32m~\\Git Repositories\\NLP_II_Interactive_Learning\\code\\utils.py:227\u001B[0m, in \u001B[0;36mtrain_active_learner\u001B[1;34m(model_params, query_strat, n_query_instances, epochs, random_seed, datasets, create_model, device)\u001B[0m\n\u001B[0;32m    224\u001B[0m         train_loss_current \u001B[38;5;241m=\u001B[39m log_loss(learner\u001B[38;5;241m.\u001B[39my_training, learner\u001B[38;5;241m.\u001B[39mpredict_proba(learner\u001B[38;5;241m.\u001B[39mX_training))\n\u001B[0;32m    225\u001B[0m     metrics[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_loss_current\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(train_loss_current)\n\u001B[1;32m--> 227\u001B[0m     \u001B[43mlog_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_cnn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_cnn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m       Current train loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss_current\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m    number of train samples: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(learner\u001B[38;5;241m.\u001B[39mX_training)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    229\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining time: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime\u001B[38;5;241m.\u001B[39mtime()\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39mstart\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m seconds\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\Git Repositories\\NLP_II_Interactive_Learning\\code\\utils.py:96\u001B[0m, in \u001B[0;36mlog_metrics\u001B[1;34m(step, model, X_train, y_train, X_test, y_test, metrics, is_cnn, device)\u001B[0m\n\u001B[0;32m     94\u001B[0m     model\u001B[38;5;241m.\u001B[39mestimator\u001B[38;5;241m.\u001B[39mmodule_\u001B[38;5;241m.\u001B[39mtrain()  \u001B[38;5;66;03m# Restore training mode\u001B[39;00m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 96\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m log_loss(y_train, \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     97\u001B[0m     test_loss \u001B[38;5;241m=\u001B[39m log_loss(y_test, model\u001B[38;5;241m.\u001B[39mpredict_proba(X_test))\n\u001B[0;32m     98\u001B[0m     test_accuracy \u001B[38;5;241m=\u001B[39m accuracy_score(y_test, model\u001B[38;5;241m.\u001B[39mpredict(X_test))\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\modAL\\models\\base.py:153\u001B[0m, in \u001B[0;36mBaseLearner.predict_proba\u001B[1;34m(self, X, **predict_proba_kwargs)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_proba\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: modALinput, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpredict_proba_kwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m    143\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    144\u001B[0m \u001B[38;5;124;03m    Class probabilities if the predictor is a classifier. Interface with the predict_proba method of the classifier.\u001B[39;00m\n\u001B[0;32m    145\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;124;03m        Class probabilities for X.\u001B[39;00m\n\u001B[0;32m    152\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 153\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpredict_proba_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1430\u001B[0m, in \u001B[0;36mLogisticRegression.predict_proba\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m   1428\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m_predict_proba_lr(X)\n\u001B[0;32m   1429\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1430\u001B[0m     decision \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecision_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1431\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m decision\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1432\u001B[0m         \u001B[38;5;66;03m# Workaround for multi_class=\"multinomial\" and binary outcomes\u001B[39;00m\n\u001B[0;32m   1433\u001B[0m         \u001B[38;5;66;03m# which requires softmax prediction with only a 1D decision.\u001B[39;00m\n\u001B[0;32m   1434\u001B[0m         decision_2d \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mc_[\u001B[38;5;241m-\u001B[39mdecision, decision]\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:352\u001B[0m, in \u001B[0;36mLinearClassifierMixin.decision_function\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    349\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[0;32m    351\u001B[0m X \u001B[38;5;241m=\u001B[39m validate_data(\u001B[38;5;28mself\u001B[39m, X, accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m--> 352\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[43msafe_sparse_dot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcoef_\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdense_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_\n\u001B[0;32m    353\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m    354\u001B[0m     xp\u001B[38;5;241m.\u001B[39mreshape(scores, (\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,))\n\u001B[0;32m    355\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (scores\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m scores\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    356\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m scores\n\u001B[0;32m    357\u001B[0m )\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\sklearn\\utils\\extmath.py:206\u001B[0m, in \u001B[0;36msafe_sparse_dot\u001B[1;34m(a, b, dense_output)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    203\u001B[0m     ret \u001B[38;5;241m=\u001B[39m a \u001B[38;5;241m@\u001B[39m b\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m--> 206\u001B[0m     \u001B[43msparse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43missparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m sparse\u001B[38;5;241m.\u001B[39missparse(b)\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m dense_output\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(ret, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoarray\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    210\u001B[0m ):\n\u001B[0;32m    211\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\u001B[38;5;241m.\u001B[39mtoarray()\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[1;32m~\\nlp2\\Lib\\site-packages\\scipy\\sparse\\_base.py:1335\u001B[0m, in \u001B[0;36missparse\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   1329\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"A namespace class to separate sparray from spmatrix\"\"\"\u001B[39;00m\n\u001B[0;32m   1332\u001B[0m sparray\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__doc__\u001B[39m \u001B[38;5;241m=\u001B[39m _spbase\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__doc__\u001B[39m\n\u001B[1;32m-> 1335\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21missparse\u001B[39m(x):\n\u001B[0;32m   1336\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001B[39;00m\n\u001B[0;32m   1337\u001B[0m \n\u001B[0;32m   1338\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1359\u001B[0m \u001B[38;5;124;03m    False\u001B[39;00m\n\u001B[0;32m   1360\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   1361\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, _spbase)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Uncertainty based strategies",
   "id": "ffb2eb9af020267d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Uncertainty Sampling**: Samples where classifier is least sure are selected",
   "id": "36cf1785e4959be6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T11:39:34.238840Z",
     "start_time": "2025-01-13T11:27:27.574833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learner, metrics = train_active_learner(model_params=model_parameters, query_strat=uncertainty_sampling, n_query_instances=n_query_instances, epochs=epochs, random_seed=RANDOM_SEED, datasets=datasets, create_model=create_log_reg_model)\n",
    "save_model_and_metrics(experiment, dataset_name, \"uncertainty_sampling\", learner, metrics)"
   ],
   "id": "10fbdcdade2f050",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: - Train Loss: 0.3383 - Test Loss: 0.3263 - Test Accuracy: 0.9065\n",
      "       Current train loss: 0.2228    number of train samples: 4805\n",
      "Iteration 2: - Train Loss: 0.3379 - Test Loss: 0.3254 - Test Accuracy: 0.907\n",
      "       Current train loss: 0.2243    number of train samples: 4810\n",
      "Iteration 3: - Train Loss: 0.3379 - Test Loss: 0.3254 - Test Accuracy: 0.907\n",
      "       Current train loss: 0.2259    number of train samples: 4815\n",
      "Iteration 4: - Train Loss: 0.3379 - Test Loss: 0.3254 - Test Accuracy: 0.907\n",
      "       Current train loss: 0.2272    number of train samples: 4820\n",
      "Iteration 5: - Train Loss: 0.3380 - Test Loss: 0.3254 - Test Accuracy: 0.9071\n",
      "       Current train loss: 0.2278    number of train samples: 4825\n",
      "Iteration 6: - Train Loss: 0.3380 - Test Loss: 0.3254 - Test Accuracy: 0.9071\n",
      "       Current train loss: 0.2296    number of train samples: 4830\n",
      "Iteration 7: - Train Loss: 0.3380 - Test Loss: 0.3254 - Test Accuracy: 0.9071\n",
      "       Current train loss: 0.2311    number of train samples: 4835\n",
      "Iteration 8: - Train Loss: 0.3380 - Test Loss: 0.3254 - Test Accuracy: 0.9071\n",
      "       Current train loss: 0.2327    number of train samples: 4840\n",
      "Iteration 9: - Train Loss: 0.3380 - Test Loss: 0.3254 - Test Accuracy: 0.9071\n",
      "       Current train loss: 0.2341    number of train samples: 4845\n",
      "Iteration 10: - Train Loss: 0.3372 - Test Loss: 0.3247 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2318    number of train samples: 4850\n",
      "Iteration 11: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2327    number of train samples: 4855\n",
      "Iteration 12: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2341    number of train samples: 4860\n",
      "Iteration 13: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2355    number of train samples: 4865\n",
      "Iteration 14: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2368    number of train samples: 4870\n",
      "Iteration 15: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2383    number of train samples: 4875\n",
      "Iteration 16: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2397    number of train samples: 4880\n",
      "Iteration 17: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2417    number of train samples: 4885\n",
      "Iteration 18: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2428    number of train samples: 4890\n",
      "Iteration 19: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2443    number of train samples: 4895\n",
      "Iteration 20: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2459    number of train samples: 4900\n",
      "Iteration 21: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2491    number of train samples: 4905\n",
      "Iteration 22: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2504    number of train samples: 4910\n",
      "Iteration 23: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2514    number of train samples: 4915\n",
      "Iteration 24: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2527    number of train samples: 4920\n",
      "Iteration 25: - Train Loss: 0.3370 - Test Loss: 0.3244 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2542    number of train samples: 4925\n",
      "Iteration 26: - Train Loss: 0.3373 - Test Loss: 0.3247 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2511    number of train samples: 4930\n",
      "Iteration 27: - Train Loss: 0.3373 - Test Loss: 0.3247 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2535    number of train samples: 4935\n",
      "Iteration 28: - Train Loss: 0.3350 - Test Loss: 0.3225 - Test Accuracy: 0.9068\n",
      "       Current train loss: 0.2536    number of train samples: 4940\n",
      "Iteration 29: - Train Loss: 0.3350 - Test Loss: 0.3225 - Test Accuracy: 0.9068\n",
      "       Current train loss: 0.2547    number of train samples: 4945\n",
      "Iteration 30: - Train Loss: 0.3350 - Test Loss: 0.3225 - Test Accuracy: 0.9068\n",
      "       Current train loss: 0.2563    number of train samples: 4950\n",
      "Iteration 31: - Train Loss: 0.3350 - Test Loss: 0.3225 - Test Accuracy: 0.9068\n",
      "       Current train loss: 0.2586    number of train samples: 4955\n",
      "Iteration 32: - Train Loss: 0.3343 - Test Loss: 0.3222 - Test Accuracy: 0.9067\n",
      "       Current train loss: 0.2533    number of train samples: 4960\n",
      "Iteration 33: - Train Loss: 0.3343 - Test Loss: 0.3222 - Test Accuracy: 0.9067\n",
      "       Current train loss: 0.2547    number of train samples: 4965\n",
      "Iteration 34: - Train Loss: 0.3343 - Test Loss: 0.3222 - Test Accuracy: 0.9067\n",
      "       Current train loss: 0.2561    number of train samples: 4970\n",
      "Iteration 35: - Train Loss: 0.3343 - Test Loss: 0.3222 - Test Accuracy: 0.9067\n",
      "       Current train loss: 0.2572    number of train samples: 4975\n",
      "Iteration 36: - Train Loss: 0.3343 - Test Loss: 0.3222 - Test Accuracy: 0.9067\n",
      "       Current train loss: 0.2588    number of train samples: 4980\n",
      "Iteration 37: - Train Loss: 0.3343 - Test Loss: 0.3222 - Test Accuracy: 0.9067\n",
      "       Current train loss: 0.2599    number of train samples: 4985\n",
      "Iteration 38: - Train Loss: 0.3338 - Test Loss: 0.3213 - Test Accuracy: 0.907\n",
      "       Current train loss: 0.2603    number of train samples: 4990\n",
      "Iteration 39: - Train Loss: 0.3338 - Test Loss: 0.3213 - Test Accuracy: 0.907\n",
      "       Current train loss: 0.2614    number of train samples: 4995\n",
      "Iteration 40: - Train Loss: 0.3338 - Test Loss: 0.3213 - Test Accuracy: 0.907\n",
      "       Current train loss: 0.2627    number of train samples: 5000\n",
      "Iteration 41: - Train Loss: 0.3338 - Test Loss: 0.3213 - Test Accuracy: 0.907\n",
      "       Current train loss: 0.2638    number of train samples: 5005\n",
      "Iteration 42: - Train Loss: 0.3338 - Test Loss: 0.3213 - Test Accuracy: 0.907\n",
      "       Current train loss: 0.2654    number of train samples: 5010\n",
      "Iteration 43: - Train Loss: 0.3338 - Test Loss: 0.3213 - Test Accuracy: 0.907\n",
      "       Current train loss: 0.2668    number of train samples: 5015\n",
      "Iteration 44: - Train Loss: 0.3338 - Test Loss: 0.3213 - Test Accuracy: 0.907\n",
      "       Current train loss: 0.2685    number of train samples: 5020\n",
      "Iteration 45: - Train Loss: 0.3338 - Test Loss: 0.3213 - Test Accuracy: 0.907\n",
      "       Current train loss: 0.2694    number of train samples: 5025\n",
      "Iteration 46: - Train Loss: 0.3335 - Test Loss: 0.3212 - Test Accuracy: 0.9073\n",
      "       Current train loss: 0.2708    number of train samples: 5030\n",
      "Iteration 47: - Train Loss: 0.3334 - Test Loss: 0.3208 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2715    number of train samples: 5035\n",
      "Iteration 48: - Train Loss: 0.3334 - Test Loss: 0.3208 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2729    number of train samples: 5040\n",
      "Iteration 49: - Train Loss: 0.3337 - Test Loss: 0.3216 - Test Accuracy: 0.9069\n",
      "       Current train loss: 0.2709    number of train samples: 5045\n",
      "Iteration 50: - Train Loss: 0.3329 - Test Loss: 0.3204 - Test Accuracy: 0.908\n",
      "       Current train loss: 0.2718    number of train samples: 5050\n",
      "Iteration 51: - Train Loss: 0.3328 - Test Loss: 0.3206 - Test Accuracy: 0.9075\n",
      "       Current train loss: 0.2734    number of train samples: 5055\n",
      "Iteration 52: - Train Loss: 0.3328 - Test Loss: 0.3206 - Test Accuracy: 0.9075\n",
      "       Current train loss: 0.2743    number of train samples: 5060\n",
      "Iteration 53: - Train Loss: 0.3328 - Test Loss: 0.3206 - Test Accuracy: 0.9075\n",
      "       Current train loss: 0.2759    number of train samples: 5065\n",
      "Iteration 54: - Train Loss: 0.3328 - Test Loss: 0.3206 - Test Accuracy: 0.9075\n",
      "       Current train loss: 0.2773    number of train samples: 5070\n",
      "Iteration 55: - Train Loss: 0.3328 - Test Loss: 0.3206 - Test Accuracy: 0.9075\n",
      "       Current train loss: 0.2783    number of train samples: 5075\n",
      "Iteration 56: - Train Loss: 0.3328 - Test Loss: 0.3206 - Test Accuracy: 0.9075\n",
      "       Current train loss: 0.2795    number of train samples: 5080\n",
      "Iteration 57: - Train Loss: 0.3313 - Test Loss: 0.3212 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2741    number of train samples: 5085\n",
      "Iteration 58: - Train Loss: 0.3313 - Test Loss: 0.3212 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2753    number of train samples: 5090\n",
      "Iteration 59: - Train Loss: 0.3313 - Test Loss: 0.3212 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2764    number of train samples: 5095\n",
      "Iteration 60: - Train Loss: 0.3313 - Test Loss: 0.3212 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2775    number of train samples: 5100\n",
      "Iteration 61: - Train Loss: 0.3313 - Test Loss: 0.3212 - Test Accuracy: 0.9066\n",
      "       Current train loss: 0.2789    number of train samples: 5105\n",
      "Iteration 62: - Train Loss: 0.3308 - Test Loss: 0.3204 - Test Accuracy: 0.9071\n",
      "       Current train loss: 0.2797    number of train samples: 5110\n",
      "Iteration 63: - Train Loss: 0.3308 - Test Loss: 0.3204 - Test Accuracy: 0.9071\n",
      "       Current train loss: 0.2807    number of train samples: 5115\n",
      "Iteration 64: - Train Loss: 0.3308 - Test Loss: 0.3206 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2818    number of train samples: 5120\n",
      "Iteration 65: - Train Loss: 0.3308 - Test Loss: 0.3206 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2828    number of train samples: 5125\n",
      "Iteration 66: - Train Loss: 0.3308 - Test Loss: 0.3206 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2839    number of train samples: 5130\n",
      "Iteration 67: - Train Loss: 0.3308 - Test Loss: 0.3206 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2848    number of train samples: 5135\n",
      "Iteration 68: - Train Loss: 0.3308 - Test Loss: 0.3206 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2857    number of train samples: 5140\n",
      "Iteration 69: - Train Loss: 0.3308 - Test Loss: 0.3206 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2867    number of train samples: 5145\n",
      "Iteration 70: - Train Loss: 0.3308 - Test Loss: 0.3206 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2879    number of train samples: 5150\n",
      "Iteration 71: - Train Loss: 0.3308 - Test Loss: 0.3206 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2889    number of train samples: 5155\n",
      "Iteration 72: - Train Loss: 0.3308 - Test Loss: 0.3206 - Test Accuracy: 0.9072\n",
      "       Current train loss: 0.2899    number of train samples: 5160\n",
      "Iteration 73: - Train Loss: 0.3288 - Test Loss: 0.3179 - Test Accuracy: 0.908\n",
      "       Current train loss: 0.2878    number of train samples: 5165\n",
      "Iteration 74: - Train Loss: 0.3288 - Test Loss: 0.3179 - Test Accuracy: 0.908\n",
      "       Current train loss: 0.2887    number of train samples: 5170\n",
      "Iteration 75: - Train Loss: 0.3288 - Test Loss: 0.3180 - Test Accuracy: 0.9083\n",
      "       Current train loss: 0.2905    number of train samples: 5175\n",
      "Iteration 76: - Train Loss: 0.3288 - Test Loss: 0.3180 - Test Accuracy: 0.9083\n",
      "       Current train loss: 0.2914    number of train samples: 5180\n",
      "Iteration 77: - Train Loss: 0.3286 - Test Loss: 0.3176 - Test Accuracy: 0.9079\n",
      "       Current train loss: 0.2922    number of train samples: 5185\n",
      "Iteration 78: - Train Loss: 0.3286 - Test Loss: 0.3176 - Test Accuracy: 0.9079\n",
      "       Current train loss: 0.2933    number of train samples: 5190\n",
      "Iteration 79: - Train Loss: 0.3286 - Test Loss: 0.3176 - Test Accuracy: 0.9079\n",
      "       Current train loss: 0.2942    number of train samples: 5195\n",
      "Iteration 80: - Train Loss: 0.3286 - Test Loss: 0.3176 - Test Accuracy: 0.9079\n",
      "       Current train loss: 0.2957    number of train samples: 5200\n",
      "Iteration 81: - Train Loss: 0.3286 - Test Loss: 0.3176 - Test Accuracy: 0.9079\n",
      "       Current train loss: 0.2969    number of train samples: 5205\n",
      "Iteration 82: - Train Loss: 0.3286 - Test Loss: 0.3176 - Test Accuracy: 0.9079\n",
      "       Current train loss: 0.2979    number of train samples: 5210\n",
      "Iteration 83: - Train Loss: 0.3286 - Test Loss: 0.3176 - Test Accuracy: 0.9079\n",
      "       Current train loss: 0.2993    number of train samples: 5215\n",
      "Iteration 84: - Train Loss: 0.3286 - Test Loss: 0.3176 - Test Accuracy: 0.9079\n",
      "       Current train loss: 0.3003    number of train samples: 5220\n",
      "Iteration 85: - Train Loss: 0.3264 - Test Loss: 0.3172 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.2946    number of train samples: 5225\n",
      "Iteration 86: - Train Loss: 0.3264 - Test Loss: 0.3172 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.2958    number of train samples: 5230\n",
      "Iteration 87: - Train Loss: 0.3264 - Test Loss: 0.3172 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.2969    number of train samples: 5235\n",
      "Iteration 88: - Train Loss: 0.3264 - Test Loss: 0.3172 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.2979    number of train samples: 5240\n",
      "Iteration 89: - Train Loss: 0.3264 - Test Loss: 0.3172 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.2987    number of train samples: 5245\n",
      "Iteration 90: - Train Loss: 0.3264 - Test Loss: 0.3172 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.3006    number of train samples: 5250\n",
      "Iteration 91: - Train Loss: 0.3264 - Test Loss: 0.3172 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.3018    number of train samples: 5255\n",
      "Iteration 92: - Train Loss: 0.3264 - Test Loss: 0.3172 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.3030    number of train samples: 5260\n",
      "Iteration 93: - Train Loss: 0.3264 - Test Loss: 0.3172 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.3049    number of train samples: 5265\n",
      "Iteration 94: - Train Loss: 0.3264 - Test Loss: 0.3172 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.3063    number of train samples: 5270\n",
      "Iteration 95: - Train Loss: 0.3264 - Test Loss: 0.3172 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.3076    number of train samples: 5275\n",
      "Iteration 96: - Train Loss: 0.3257 - Test Loss: 0.3160 - Test Accuracy: 0.9083\n",
      "       Current train loss: 0.3068    number of train samples: 5280\n",
      "Iteration 97: - Train Loss: 0.3257 - Test Loss: 0.3160 - Test Accuracy: 0.9083\n",
      "       Current train loss: 0.3083    number of train samples: 5285\n",
      "Iteration 98: - Train Loss: 0.3257 - Test Loss: 0.3160 - Test Accuracy: 0.9083\n",
      "       Current train loss: 0.3093    number of train samples: 5290\n",
      "Iteration 99: - Train Loss: 0.3257 - Test Loss: 0.3160 - Test Accuracy: 0.9083\n",
      "       Current train loss: 0.3112    number of train samples: 5295\n",
      "Iteration 100: - Train Loss: 0.3257 - Test Loss: 0.3160 - Test Accuracy: 0.9083\n",
      "       Current train loss: 0.3124    number of train samples: 5300\n",
      "Iteration 101: - Train Loss: 0.3256 - Test Loss: 0.3163 - Test Accuracy: 0.909\n",
      "       Current train loss: 0.3131    number of train samples: 5305\n",
      "Iteration 102: - Train Loss: 0.3253 - Test Loss: 0.3158 - Test Accuracy: 0.9088\n",
      "       Current train loss: 0.3146    number of train samples: 5310\n",
      "Iteration 103: - Train Loss: 0.3253 - Test Loss: 0.3158 - Test Accuracy: 0.9088\n",
      "       Current train loss: 0.3156    number of train samples: 5315\n",
      "Iteration 104: - Train Loss: 0.3253 - Test Loss: 0.3158 - Test Accuracy: 0.9088\n",
      "       Current train loss: 0.3163    number of train samples: 5320\n",
      "Iteration 105: - Train Loss: 0.3253 - Test Loss: 0.3158 - Test Accuracy: 0.9088\n",
      "       Current train loss: 0.3176    number of train samples: 5325\n",
      "Iteration 106: - Train Loss: 0.3253 - Test Loss: 0.3158 - Test Accuracy: 0.9088\n",
      "       Current train loss: 0.3185    number of train samples: 5330\n",
      "Iteration 107: - Train Loss: 0.3253 - Test Loss: 0.3158 - Test Accuracy: 0.9088\n",
      "       Current train loss: 0.3204    number of train samples: 5335\n",
      "Iteration 108: - Train Loss: 0.3253 - Test Loss: 0.3158 - Test Accuracy: 0.9088\n",
      "       Current train loss: 0.3214    number of train samples: 5340\n",
      "Iteration 109: - Train Loss: 0.3253 - Test Loss: 0.3158 - Test Accuracy: 0.9088\n",
      "       Current train loss: 0.3224    number of train samples: 5345\n",
      "Iteration 110: - Train Loss: 0.3245 - Test Loss: 0.3165 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.3167    number of train samples: 5350\n",
      "Iteration 111: - Train Loss: 0.3245 - Test Loss: 0.3165 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.3179    number of train samples: 5355\n",
      "Iteration 112: - Train Loss: 0.3245 - Test Loss: 0.3165 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.3190    number of train samples: 5360\n",
      "Iteration 113: - Train Loss: 0.3245 - Test Loss: 0.3165 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.3206    number of train samples: 5365\n",
      "Iteration 114: - Train Loss: 0.3245 - Test Loss: 0.3165 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.3215    number of train samples: 5370\n",
      "Iteration 115: - Train Loss: 0.3245 - Test Loss: 0.3165 - Test Accuracy: 0.9091\n",
      "       Current train loss: 0.3235    number of train samples: 5375\n",
      "Iteration 116: - Train Loss: 0.3242 - Test Loss: 0.3168 - Test Accuracy: 0.909\n",
      "       Current train loss: 0.3237    number of train samples: 5380\n",
      "Iteration 117: - Train Loss: 0.3240 - Test Loss: 0.3165 - Test Accuracy: 0.9081\n",
      "       Current train loss: 0.3244    number of train samples: 5385\n",
      "Iteration 118: - Train Loss: 0.3240 - Test Loss: 0.3165 - Test Accuracy: 0.9081\n",
      "       Current train loss: 0.3252    number of train samples: 5390\n",
      "Iteration 119: - Train Loss: 0.3240 - Test Loss: 0.3165 - Test Accuracy: 0.9081\n",
      "       Current train loss: 0.3259    number of train samples: 5395\n",
      "Iteration 120: - Train Loss: 0.3240 - Test Loss: 0.3165 - Test Accuracy: 0.9081\n",
      "       Current train loss: 0.3269    number of train samples: 5400\n",
      "Iteration 121: - Train Loss: 0.3240 - Test Loss: 0.3165 - Test Accuracy: 0.9081\n",
      "       Current train loss: 0.3276    number of train samples: 5405\n",
      "Iteration 122: - Train Loss: 0.3240 - Test Loss: 0.3165 - Test Accuracy: 0.9081\n",
      "       Current train loss: 0.3288    number of train samples: 5410\n",
      "Iteration 123: - Train Loss: 0.3240 - Test Loss: 0.3165 - Test Accuracy: 0.9081\n",
      "       Current train loss: 0.3298    number of train samples: 5415\n",
      "Iteration 124: - Train Loss: 0.3233 - Test Loss: 0.3171 - Test Accuracy: 0.9097\n",
      "       Current train loss: 0.3284    number of train samples: 5420\n",
      "Iteration 125: - Train Loss: 0.3233 - Test Loss: 0.3171 - Test Accuracy: 0.9097\n",
      "       Current train loss: 0.3293    number of train samples: 5425\n",
      "Iteration 126: - Train Loss: 0.3233 - Test Loss: 0.3171 - Test Accuracy: 0.9097\n",
      "       Current train loss: 0.3301    number of train samples: 5430\n",
      "Iteration 127: - Train Loss: 0.3232 - Test Loss: 0.3171 - Test Accuracy: 0.9105\n",
      "       Current train loss: 0.3310    number of train samples: 5435\n",
      "Iteration 128: - Train Loss: 0.3232 - Test Loss: 0.3171 - Test Accuracy: 0.9105\n",
      "       Current train loss: 0.3317    number of train samples: 5440\n",
      "Iteration 129: - Train Loss: 0.3231 - Test Loss: 0.3170 - Test Accuracy: 0.9099\n",
      "       Current train loss: 0.3327    number of train samples: 5445\n",
      "Iteration 130: - Train Loss: 0.3231 - Test Loss: 0.3170 - Test Accuracy: 0.9099\n",
      "       Current train loss: 0.3338    number of train samples: 5450\n",
      "Iteration 131: - Train Loss: 0.3231 - Test Loss: 0.3170 - Test Accuracy: 0.9099\n",
      "       Current train loss: 0.3348    number of train samples: 5455\n",
      "Iteration 132: - Train Loss: 0.3230 - Test Loss: 0.3170 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.3356    number of train samples: 5460\n",
      "Iteration 133: - Train Loss: 0.3231 - Test Loss: 0.3171 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.3365    number of train samples: 5465\n",
      "Iteration 134: - Train Loss: 0.3231 - Test Loss: 0.3171 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.3373    number of train samples: 5470\n",
      "Iteration 135: - Train Loss: 0.3231 - Test Loss: 0.3171 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.3382    number of train samples: 5475\n",
      "Iteration 136: - Train Loss: 0.3231 - Test Loss: 0.3171 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.3400    number of train samples: 5480\n",
      "Iteration 137: - Train Loss: 0.3231 - Test Loss: 0.3171 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.3406    number of train samples: 5485\n",
      "Iteration 138: - Train Loss: 0.3230 - Test Loss: 0.3169 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.3413    number of train samples: 5490\n",
      "Iteration 139: - Train Loss: 0.3230 - Test Loss: 0.3169 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.3420    number of train samples: 5495\n",
      "Iteration 140: - Train Loss: 0.3230 - Test Loss: 0.3169 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.3431    number of train samples: 5500\n",
      "Iteration 141: - Train Loss: 0.3230 - Test Loss: 0.3169 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.3437    number of train samples: 5505\n",
      "Iteration 142: - Train Loss: 0.3230 - Test Loss: 0.3169 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.3448    number of train samples: 5510\n",
      "Iteration 143: - Train Loss: 0.3214 - Test Loss: 0.3155 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3372    number of train samples: 5515\n",
      "Iteration 144: - Train Loss: 0.3214 - Test Loss: 0.3155 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3388    number of train samples: 5520\n",
      "Iteration 145: - Train Loss: 0.3214 - Test Loss: 0.3155 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3396    number of train samples: 5525\n",
      "Iteration 146: - Train Loss: 0.3214 - Test Loss: 0.3155 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3408    number of train samples: 5530\n",
      "Iteration 147: - Train Loss: 0.3214 - Test Loss: 0.3155 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3415    number of train samples: 5535\n",
      "Iteration 148: - Train Loss: 0.3214 - Test Loss: 0.3155 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3422    number of train samples: 5540\n",
      "Iteration 149: - Train Loss: 0.3214 - Test Loss: 0.3155 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3437    number of train samples: 5545\n",
      "Iteration 150: - Train Loss: 0.3214 - Test Loss: 0.3155 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3449    number of train samples: 5550\n",
      "Iteration 151: - Train Loss: 0.3214 - Test Loss: 0.3155 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3464    number of train samples: 5555\n",
      "Iteration 152: - Train Loss: 0.3214 - Test Loss: 0.3155 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3472    number of train samples: 5560\n",
      "Iteration 153: - Train Loss: 0.3214 - Test Loss: 0.3155 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3489    number of train samples: 5565\n",
      "Iteration 154: - Train Loss: 0.3214 - Test Loss: 0.3155 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3497    number of train samples: 5570\n",
      "Iteration 155: - Train Loss: 0.3214 - Test Loss: 0.3155 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3504    number of train samples: 5575\n",
      "Iteration 156: - Train Loss: 0.3207 - Test Loss: 0.3169 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.3479    number of train samples: 5580\n",
      "Iteration 157: - Train Loss: 0.3207 - Test Loss: 0.3169 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.3488    number of train samples: 5585\n",
      "Iteration 158: - Train Loss: 0.3207 - Test Loss: 0.3169 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.3496    number of train samples: 5590\n",
      "Iteration 159: - Train Loss: 0.3207 - Test Loss: 0.3169 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.3505    number of train samples: 5595\n",
      "Iteration 160: - Train Loss: 0.3207 - Test Loss: 0.3169 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.3517    number of train samples: 5600\n",
      "Iteration 161: - Train Loss: 0.3207 - Test Loss: 0.3169 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.3525    number of train samples: 5605\n",
      "Iteration 162: - Train Loss: 0.3207 - Test Loss: 0.3169 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.3532    number of train samples: 5610\n",
      "Iteration 163: - Train Loss: 0.3207 - Test Loss: 0.3169 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.3540    number of train samples: 5615\n",
      "Iteration 164: - Train Loss: 0.3207 - Test Loss: 0.3169 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.3548    number of train samples: 5620\n",
      "Iteration 165: - Train Loss: 0.3202 - Test Loss: 0.3162 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.3553    number of train samples: 5625\n",
      "Iteration 166: - Train Loss: 0.3202 - Test Loss: 0.3162 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.3561    number of train samples: 5630\n",
      "Iteration 167: - Train Loss: 0.3202 - Test Loss: 0.3162 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.3573    number of train samples: 5635\n",
      "Iteration 168: - Train Loss: 0.3202 - Test Loss: 0.3162 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.3585    number of train samples: 5640\n",
      "Iteration 169: - Train Loss: 0.3202 - Test Loss: 0.3162 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.3603    number of train samples: 5645\n",
      "Iteration 170: - Train Loss: 0.3202 - Test Loss: 0.3162 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.3609    number of train samples: 5650\n",
      "Iteration 171: - Train Loss: 0.3178 - Test Loss: 0.3162 - Test Accuracy: 0.9109\n",
      "       Current train loss: 0.3522    number of train samples: 5655\n",
      "Iteration 172: - Train Loss: 0.3178 - Test Loss: 0.3162 - Test Accuracy: 0.9109\n",
      "       Current train loss: 0.3534    number of train samples: 5660\n",
      "Iteration 173: - Train Loss: 0.3178 - Test Loss: 0.3162 - Test Accuracy: 0.9109\n",
      "       Current train loss: 0.3541    number of train samples: 5665\n",
      "Iteration 174: - Train Loss: 0.3174 - Test Loss: 0.3157 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3540    number of train samples: 5670\n",
      "Iteration 175: - Train Loss: 0.3174 - Test Loss: 0.3157 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3548    number of train samples: 5675\n",
      "Iteration 176: - Train Loss: 0.3174 - Test Loss: 0.3157 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3563    number of train samples: 5680\n",
      "Iteration 177: - Train Loss: 0.3174 - Test Loss: 0.3157 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3574    number of train samples: 5685\n",
      "Iteration 178: - Train Loss: 0.3174 - Test Loss: 0.3157 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3583    number of train samples: 5690\n",
      "Iteration 179: - Train Loss: 0.3174 - Test Loss: 0.3157 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3599    number of train samples: 5695\n",
      "Iteration 180: - Train Loss: 0.3174 - Test Loss: 0.3157 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3608    number of train samples: 5700\n",
      "Iteration 181: - Train Loss: 0.3174 - Test Loss: 0.3157 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3621    number of train samples: 5705\n",
      "Iteration 182: - Train Loss: 0.3175 - Test Loss: 0.3157 - Test Accuracy: 0.911\n",
      "       Current train loss: 0.3641    number of train samples: 5710\n",
      "Iteration 183: - Train Loss: 0.3175 - Test Loss: 0.3157 - Test Accuracy: 0.911\n",
      "       Current train loss: 0.3647    number of train samples: 5715\n",
      "Iteration 184: - Train Loss: 0.3175 - Test Loss: 0.3157 - Test Accuracy: 0.911\n",
      "       Current train loss: 0.3657    number of train samples: 5720\n",
      "Iteration 185: - Train Loss: 0.3175 - Test Loss: 0.3157 - Test Accuracy: 0.911\n",
      "       Current train loss: 0.3666    number of train samples: 5725\n",
      "Iteration 186: - Train Loss: 0.3175 - Test Loss: 0.3157 - Test Accuracy: 0.911\n",
      "       Current train loss: 0.3672    number of train samples: 5730\n",
      "Iteration 187: - Train Loss: 0.3175 - Test Loss: 0.3157 - Test Accuracy: 0.911\n",
      "       Current train loss: 0.3678    number of train samples: 5735\n",
      "Iteration 188: - Train Loss: 0.3175 - Test Loss: 0.3157 - Test Accuracy: 0.911\n",
      "       Current train loss: 0.3688    number of train samples: 5740\n",
      "Iteration 189: - Train Loss: 0.3175 - Test Loss: 0.3157 - Test Accuracy: 0.911\n",
      "       Current train loss: 0.3696    number of train samples: 5745\n",
      "Iteration 190: - Train Loss: 0.3175 - Test Loss: 0.3157 - Test Accuracy: 0.911\n",
      "       Current train loss: 0.3703    number of train samples: 5750\n",
      "Iteration 191: - Train Loss: 0.3182 - Test Loss: 0.3164 - Test Accuracy: 0.91\n",
      "       Current train loss: 0.3686    number of train samples: 5755\n",
      "Iteration 192: - Train Loss: 0.3182 - Test Loss: 0.3164 - Test Accuracy: 0.91\n",
      "       Current train loss: 0.3695    number of train samples: 5760\n",
      "Iteration 193: - Train Loss: 0.3182 - Test Loss: 0.3164 - Test Accuracy: 0.91\n",
      "       Current train loss: 0.3702    number of train samples: 5765\n",
      "Iteration 194: - Train Loss: 0.3182 - Test Loss: 0.3164 - Test Accuracy: 0.91\n",
      "       Current train loss: 0.3711    number of train samples: 5770\n",
      "Iteration 195: - Train Loss: 0.3182 - Test Loss: 0.3164 - Test Accuracy: 0.91\n",
      "       Current train loss: 0.3719    number of train samples: 5775\n",
      "Iteration 196: - Train Loss: 0.3182 - Test Loss: 0.3164 - Test Accuracy: 0.91\n",
      "       Current train loss: 0.3727    number of train samples: 5780\n",
      "Iteration 197: - Train Loss: 0.3173 - Test Loss: 0.3156 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3719    number of train samples: 5785\n",
      "Iteration 198: - Train Loss: 0.3173 - Test Loss: 0.3156 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3726    number of train samples: 5790\n",
      "Iteration 199: - Train Loss: 0.3173 - Test Loss: 0.3156 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3735    number of train samples: 5795\n",
      "Iteration 200: - Train Loss: 0.3173 - Test Loss: 0.3156 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3745    number of train samples: 5800\n",
      "Iteration 201: - Train Loss: 0.3173 - Test Loss: 0.3156 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3755    number of train samples: 5805\n",
      "Iteration 202: - Train Loss: 0.3173 - Test Loss: 0.3156 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3763    number of train samples: 5810\n",
      "Iteration 203: - Train Loss: 0.3173 - Test Loss: 0.3156 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3768    number of train samples: 5815\n",
      "Iteration 204: - Train Loss: 0.3173 - Test Loss: 0.3156 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3775    number of train samples: 5820\n",
      "Iteration 205: - Train Loss: 0.3173 - Test Loss: 0.3156 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3783    number of train samples: 5825\n",
      "Iteration 206: - Train Loss: 0.3173 - Test Loss: 0.3156 - Test Accuracy: 0.9102\n",
      "       Current train loss: 0.3790    number of train samples: 5830\n",
      "Iteration 207: - Train Loss: 0.3175 - Test Loss: 0.3157 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.3800    number of train samples: 5835\n",
      "Iteration 208: - Train Loss: 0.3175 - Test Loss: 0.3157 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.3807    number of train samples: 5840\n",
      "Iteration 209: - Train Loss: 0.3175 - Test Loss: 0.3157 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.3816    number of train samples: 5845\n",
      "Iteration 210: - Train Loss: 0.3169 - Test Loss: 0.3152 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3828    number of train samples: 5850\n",
      "Iteration 211: - Train Loss: 0.3169 - Test Loss: 0.3152 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.3834    number of train samples: 5855\n",
      "Iteration 212: - Train Loss: 0.3171 - Test Loss: 0.3152 - Test Accuracy: 0.9108\n",
      "       Current train loss: 0.3851    number of train samples: 5860\n",
      "Iteration 213: - Train Loss: 0.3171 - Test Loss: 0.3152 - Test Accuracy: 0.9108\n",
      "       Current train loss: 0.3858    number of train samples: 5865\n",
      "Iteration 214: - Train Loss: 0.3171 - Test Loss: 0.3152 - Test Accuracy: 0.9108\n",
      "       Current train loss: 0.3863    number of train samples: 5870\n",
      "Iteration 215: - Train Loss: 0.3171 - Test Loss: 0.3152 - Test Accuracy: 0.9108\n",
      "       Current train loss: 0.3878    number of train samples: 5875\n",
      "Iteration 216: - Train Loss: 0.3171 - Test Loss: 0.3152 - Test Accuracy: 0.9108\n",
      "       Current train loss: 0.3895    number of train samples: 5880\n",
      "Iteration 217: - Train Loss: 0.3171 - Test Loss: 0.3154 - Test Accuracy: 0.911\n",
      "       Current train loss: 0.3899    number of train samples: 5885\n",
      "Iteration 218: - Train Loss: 0.3169 - Test Loss: 0.3151 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.3904    number of train samples: 5890\n",
      "Iteration 219: - Train Loss: 0.3169 - Test Loss: 0.3151 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.3911    number of train samples: 5895\n",
      "Iteration 220: - Train Loss: 0.3169 - Test Loss: 0.3151 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.3916    number of train samples: 5900\n",
      "Iteration 221: - Train Loss: 0.3172 - Test Loss: 0.3157 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.3887    number of train samples: 5905\n",
      "Iteration 222: - Train Loss: 0.3172 - Test Loss: 0.3157 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.3892    number of train samples: 5910\n",
      "Iteration 223: - Train Loss: 0.3172 - Test Loss: 0.3157 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.3905    number of train samples: 5915\n",
      "Iteration 224: - Train Loss: 0.3167 - Test Loss: 0.3155 - Test Accuracy: 0.9095\n",
      "       Current train loss: 0.3904    number of train samples: 5920\n",
      "Iteration 225: - Train Loss: 0.3167 - Test Loss: 0.3155 - Test Accuracy: 0.9095\n",
      "       Current train loss: 0.3916    number of train samples: 5925\n",
      "Iteration 226: - Train Loss: 0.3167 - Test Loss: 0.3155 - Test Accuracy: 0.9095\n",
      "       Current train loss: 0.3921    number of train samples: 5930\n",
      "Iteration 227: - Train Loss: 0.3167 - Test Loss: 0.3155 - Test Accuracy: 0.9095\n",
      "       Current train loss: 0.3933    number of train samples: 5935\n",
      "Iteration 228: - Train Loss: 0.3167 - Test Loss: 0.3155 - Test Accuracy: 0.9095\n",
      "       Current train loss: 0.3943    number of train samples: 5940\n",
      "Iteration 229: - Train Loss: 0.3167 - Test Loss: 0.3155 - Test Accuracy: 0.9095\n",
      "       Current train loss: 0.3949    number of train samples: 5945\n",
      "Iteration 230: - Train Loss: 0.3167 - Test Loss: 0.3155 - Test Accuracy: 0.9095\n",
      "       Current train loss: 0.3955    number of train samples: 5950\n",
      "Iteration 231: - Train Loss: 0.3167 - Test Loss: 0.3155 - Test Accuracy: 0.9095\n",
      "       Current train loss: 0.3962    number of train samples: 5955\n",
      "Iteration 232: - Train Loss: 0.3167 - Test Loss: 0.3155 - Test Accuracy: 0.9095\n",
      "       Current train loss: 0.3967    number of train samples: 5960\n",
      "Iteration 233: - Train Loss: 0.3167 - Test Loss: 0.3155 - Test Accuracy: 0.9095\n",
      "       Current train loss: 0.3977    number of train samples: 5965\n",
      "Iteration 234: - Train Loss: 0.3165 - Test Loss: 0.3151 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.3975    number of train samples: 5970\n",
      "Iteration 235: - Train Loss: 0.3165 - Test Loss: 0.3151 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.3983    number of train samples: 5975\n",
      "Iteration 236: - Train Loss: 0.3165 - Test Loss: 0.3151 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.3989    number of train samples: 5980\n",
      "Iteration 237: - Train Loss: 0.3165 - Test Loss: 0.3151 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.3998    number of train samples: 5985\n",
      "Iteration 238: - Train Loss: 0.3165 - Test Loss: 0.3151 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.4008    number of train samples: 5990\n",
      "Iteration 239: - Train Loss: 0.3165 - Test Loss: 0.3151 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.4014    number of train samples: 5995\n",
      "Iteration 240: - Train Loss: 0.3165 - Test Loss: 0.3151 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.4018    number of train samples: 6000\n",
      "Iteration 241: - Train Loss: 0.3165 - Test Loss: 0.3151 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.4027    number of train samples: 6005\n",
      "Iteration 242: - Train Loss: 0.3165 - Test Loss: 0.3151 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.4038    number of train samples: 6010\n",
      "Iteration 243: - Train Loss: 0.3165 - Test Loss: 0.3151 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.4047    number of train samples: 6015\n",
      "Iteration 244: - Train Loss: 0.3163 - Test Loss: 0.3143 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.3993    number of train samples: 6020\n",
      "Iteration 245: - Train Loss: 0.3163 - Test Loss: 0.3143 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4001    number of train samples: 6025\n",
      "Iteration 246: - Train Loss: 0.3163 - Test Loss: 0.3143 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4011    number of train samples: 6030\n",
      "Iteration 247: - Train Loss: 0.3163 - Test Loss: 0.3143 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4018    number of train samples: 6035\n",
      "Iteration 248: - Train Loss: 0.3152 - Test Loss: 0.3140 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4010    number of train samples: 6040\n",
      "Iteration 249: - Train Loss: 0.3152 - Test Loss: 0.3140 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4016    number of train samples: 6045\n",
      "Iteration 250: - Train Loss: 0.3152 - Test Loss: 0.3140 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4025    number of train samples: 6050\n",
      "Iteration 251: - Train Loss: 0.3152 - Test Loss: 0.3140 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4030    number of train samples: 6055\n",
      "Iteration 252: - Train Loss: 0.3152 - Test Loss: 0.3140 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4040    number of train samples: 6060\n",
      "Iteration 253: - Train Loss: 0.3152 - Test Loss: 0.3140 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4045    number of train samples: 6065\n",
      "Iteration 254: - Train Loss: 0.3152 - Test Loss: 0.3140 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4056    number of train samples: 6070\n",
      "Iteration 255: - Train Loss: 0.3152 - Test Loss: 0.3140 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4062    number of train samples: 6075\n",
      "Iteration 256: - Train Loss: 0.3152 - Test Loss: 0.3140 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4067    number of train samples: 6080\n",
      "Iteration 257: - Train Loss: 0.3152 - Test Loss: 0.3140 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4073    number of train samples: 6085\n",
      "Iteration 258: - Train Loss: 0.3152 - Test Loss: 0.3140 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4083    number of train samples: 6090\n",
      "Iteration 259: - Train Loss: 0.3152 - Test Loss: 0.3140 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4090    number of train samples: 6095\n",
      "Iteration 260: - Train Loss: 0.3150 - Test Loss: 0.3137 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4095    number of train samples: 6100\n",
      "Iteration 261: - Train Loss: 0.3150 - Test Loss: 0.3137 - Test Accuracy: 0.9101\n",
      "       Current train loss: 0.4101    number of train samples: 6105\n",
      "Iteration 262: - Train Loss: 0.3151 - Test Loss: 0.3139 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.4107    number of train samples: 6110\n",
      "Iteration 263: - Train Loss: 0.3151 - Test Loss: 0.3139 - Test Accuracy: 0.9093\n",
      "       Current train loss: 0.4112    number of train samples: 6115\n",
      "Iteration 264: - Train Loss: 0.3148 - Test Loss: 0.3136 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4114    number of train samples: 6120\n",
      "Iteration 265: - Train Loss: 0.3148 - Test Loss: 0.3136 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4121    number of train samples: 6125\n",
      "Iteration 266: - Train Loss: 0.3148 - Test Loss: 0.3136 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4126    number of train samples: 6130\n",
      "Iteration 267: - Train Loss: 0.3148 - Test Loss: 0.3136 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4140    number of train samples: 6135\n",
      "Iteration 268: - Train Loss: 0.3148 - Test Loss: 0.3136 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4150    number of train samples: 6140\n",
      "Iteration 269: - Train Loss: 0.3148 - Test Loss: 0.3136 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4155    number of train samples: 6145\n",
      "Iteration 270: - Train Loss: 0.3148 - Test Loss: 0.3136 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4160    number of train samples: 6150\n",
      "Iteration 271: - Train Loss: 0.3148 - Test Loss: 0.3136 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4165    number of train samples: 6155\n",
      "Iteration 272: - Train Loss: 0.3148 - Test Loss: 0.3136 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4174    number of train samples: 6160\n",
      "Iteration 273: - Train Loss: 0.3148 - Test Loss: 0.3136 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4182    number of train samples: 6165\n",
      "Iteration 274: - Train Loss: 0.3147 - Test Loss: 0.3137 - Test Accuracy: 0.9097\n",
      "       Current train loss: 0.4181    number of train samples: 6170\n",
      "Iteration 275: - Train Loss: 0.3147 - Test Loss: 0.3137 - Test Accuracy: 0.9097\n",
      "       Current train loss: 0.4191    number of train samples: 6175\n",
      "Iteration 276: - Train Loss: 0.3147 - Test Loss: 0.3137 - Test Accuracy: 0.9097\n",
      "       Current train loss: 0.4203    number of train samples: 6180\n",
      "Iteration 277: - Train Loss: 0.3147 - Test Loss: 0.3137 - Test Accuracy: 0.9097\n",
      "       Current train loss: 0.4207    number of train samples: 6185\n",
      "Iteration 278: - Train Loss: 0.3147 - Test Loss: 0.3137 - Test Accuracy: 0.9097\n",
      "       Current train loss: 0.4211    number of train samples: 6190\n",
      "Iteration 279: - Train Loss: 0.3146 - Test Loss: 0.3135 - Test Accuracy: 0.9097\n",
      "       Current train loss: 0.4217    number of train samples: 6195\n",
      "Iteration 280: - Train Loss: 0.3145 - Test Loss: 0.3134 - Test Accuracy: 0.9099\n",
      "       Current train loss: 0.4221    number of train samples: 6200\n",
      "Iteration 281: - Train Loss: 0.3138 - Test Loss: 0.3132 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4189    number of train samples: 6205\n",
      "Iteration 282: - Train Loss: 0.3138 - Test Loss: 0.3132 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4199    number of train samples: 6210\n",
      "Iteration 283: - Train Loss: 0.3138 - Test Loss: 0.3132 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4205    number of train samples: 6215\n",
      "Iteration 284: - Train Loss: 0.3138 - Test Loss: 0.3132 - Test Accuracy: 0.9096\n",
      "       Current train loss: 0.4209    number of train samples: 6220\n",
      "Iteration 285: - Train Loss: 0.3138 - Test Loss: 0.3136 - Test Accuracy: 0.9097\n",
      "       Current train loss: 0.4205    number of train samples: 6225\n",
      "Iteration 286: - Train Loss: 0.3138 - Test Loss: 0.3136 - Test Accuracy: 0.9097\n",
      "       Current train loss: 0.4216    number of train samples: 6230\n",
      "Iteration 287: - Train Loss: 0.3138 - Test Loss: 0.3136 - Test Accuracy: 0.9097\n",
      "       Current train loss: 0.4223    number of train samples: 6235\n",
      "Iteration 288: - Train Loss: 0.3137 - Test Loss: 0.3135 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.4233    number of train samples: 6240\n",
      "Iteration 289: - Train Loss: 0.3137 - Test Loss: 0.3135 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.4238    number of train samples: 6245\n",
      "Iteration 290: - Train Loss: 0.3137 - Test Loss: 0.3135 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.4242    number of train samples: 6250\n",
      "Iteration 291: - Train Loss: 0.3137 - Test Loss: 0.3135 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.4251    number of train samples: 6255\n",
      "Iteration 292: - Train Loss: 0.3137 - Test Loss: 0.3135 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.4254    number of train samples: 6260\n",
      "Iteration 293: - Train Loss: 0.3137 - Test Loss: 0.3135 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.4261    number of train samples: 6265\n",
      "Iteration 294: - Train Loss: 0.3137 - Test Loss: 0.3135 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.4265    number of train samples: 6270\n",
      "Iteration 295: - Train Loss: 0.3137 - Test Loss: 0.3135 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.4270    number of train samples: 6275\n",
      "Iteration 296: - Train Loss: 0.3137 - Test Loss: 0.3135 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.4275    number of train samples: 6280\n",
      "Iteration 297: - Train Loss: 0.3137 - Test Loss: 0.3135 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.4279    number of train samples: 6285\n",
      "Iteration 298: - Train Loss: 0.3137 - Test Loss: 0.3135 - Test Accuracy: 0.9098\n",
      "       Current train loss: 0.4285    number of train samples: 6290\n",
      "Iteration 299: - Train Loss: 0.3114 - Test Loss: 0.3124 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.4231    number of train samples: 6295\n",
      "Iteration 300: - Train Loss: 0.3114 - Test Loss: 0.3124 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.4237    number of train samples: 6300\n",
      "Iteration 301: - Train Loss: 0.3114 - Test Loss: 0.3124 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.4241    number of train samples: 6305\n",
      "Iteration 302: - Train Loss: 0.3114 - Test Loss: 0.3124 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.4245    number of train samples: 6310\n",
      "Iteration 303: - Train Loss: 0.3114 - Test Loss: 0.3124 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.4254    number of train samples: 6315\n",
      "Iteration 304: - Train Loss: 0.3114 - Test Loss: 0.3124 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.4260    number of train samples: 6320\n",
      "Iteration 305: - Train Loss: 0.3114 - Test Loss: 0.3124 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.4274    number of train samples: 6325\n",
      "Iteration 306: - Train Loss: 0.3114 - Test Loss: 0.3124 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.4286    number of train samples: 6330\n",
      "Iteration 307: - Train Loss: 0.3117 - Test Loss: 0.3127 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.4290    number of train samples: 6335\n",
      "Iteration 308: - Train Loss: 0.3117 - Test Loss: 0.3127 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.4295    number of train samples: 6340\n",
      "Iteration 309: - Train Loss: 0.3117 - Test Loss: 0.3127 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.4300    number of train samples: 6345\n",
      "Iteration 310: - Train Loss: 0.3117 - Test Loss: 0.3127 - Test Accuracy: 0.9106\n",
      "       Current train loss: 0.4304    number of train samples: 6350\n",
      "Iteration 311: - Train Loss: 0.3116 - Test Loss: 0.3127 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.4307    number of train samples: 6355\n",
      "Iteration 312: - Train Loss: 0.3116 - Test Loss: 0.3127 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.4323    number of train samples: 6360\n",
      "Iteration 313: - Train Loss: 0.3115 - Test Loss: 0.3124 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.4326    number of train samples: 6365\n",
      "Iteration 314: - Train Loss: 0.3115 - Test Loss: 0.3124 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.4333    number of train samples: 6370\n",
      "Iteration 315: - Train Loss: 0.3115 - Test Loss: 0.3124 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.4342    number of train samples: 6375\n",
      "Iteration 316: - Train Loss: 0.3115 - Test Loss: 0.3124 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.4346    number of train samples: 6380\n",
      "Iteration 317: - Train Loss: 0.3115 - Test Loss: 0.3124 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.4352    number of train samples: 6385\n",
      "Iteration 318: - Train Loss: 0.3115 - Test Loss: 0.3124 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.4355    number of train samples: 6390\n",
      "Iteration 319: - Train Loss: 0.3115 - Test Loss: 0.3124 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.4359    number of train samples: 6395\n",
      "Iteration 320: - Train Loss: 0.3115 - Test Loss: 0.3124 - Test Accuracy: 0.9104\n",
      "       Current train loss: 0.4364    number of train samples: 6400\n",
      "Iteration 321: - Train Loss: 0.3108 - Test Loss: 0.3123 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4325    number of train samples: 6405\n",
      "Iteration 322: - Train Loss: 0.3108 - Test Loss: 0.3123 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4333    number of train samples: 6410\n",
      "Iteration 323: - Train Loss: 0.3108 - Test Loss: 0.3123 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4339    number of train samples: 6415\n",
      "Iteration 324: - Train Loss: 0.3108 - Test Loss: 0.3123 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4344    number of train samples: 6420\n",
      "Iteration 325: - Train Loss: 0.3108 - Test Loss: 0.3123 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4352    number of train samples: 6425\n",
      "Iteration 326: - Train Loss: 0.3108 - Test Loss: 0.3123 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4358    number of train samples: 6430\n",
      "Iteration 327: - Train Loss: 0.3108 - Test Loss: 0.3123 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4362    number of train samples: 6435\n",
      "Iteration 328: - Train Loss: 0.3108 - Test Loss: 0.3123 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4370    number of train samples: 6440\n",
      "Iteration 329: - Train Loss: 0.3108 - Test Loss: 0.3123 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4374    number of train samples: 6445\n",
      "Iteration 330: - Train Loss: 0.3108 - Test Loss: 0.3123 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4378    number of train samples: 6450\n",
      "Iteration 331: - Train Loss: 0.3105 - Test Loss: 0.3120 - Test Accuracy: 0.911\n",
      "       Current train loss: 0.4381    number of train samples: 6455\n",
      "Iteration 332: - Train Loss: 0.3105 - Test Loss: 0.3120 - Test Accuracy: 0.911\n",
      "       Current train loss: 0.4387    number of train samples: 6460\n",
      "Iteration 333: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4375    number of train samples: 6465\n",
      "Iteration 334: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4381    number of train samples: 6470\n",
      "Iteration 335: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4386    number of train samples: 6475\n",
      "Iteration 336: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4391    number of train samples: 6480\n",
      "Iteration 337: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4400    number of train samples: 6485\n",
      "Iteration 338: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4403    number of train samples: 6490\n",
      "Iteration 339: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4407    number of train samples: 6495\n",
      "Iteration 340: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4414    number of train samples: 6500\n",
      "Iteration 341: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4418    number of train samples: 6505\n",
      "Iteration 342: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4423    number of train samples: 6510\n",
      "Iteration 343: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4429    number of train samples: 6515\n",
      "Iteration 344: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4444    number of train samples: 6520\n",
      "Iteration 345: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4451    number of train samples: 6525\n",
      "Iteration 346: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4456    number of train samples: 6530\n",
      "Iteration 347: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4458    number of train samples: 6535\n",
      "Iteration 348: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4467    number of train samples: 6540\n",
      "Iteration 349: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4471    number of train samples: 6545\n",
      "Iteration 350: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4474    number of train samples: 6550\n",
      "Iteration 351: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4477    number of train samples: 6555\n",
      "Iteration 352: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4485    number of train samples: 6560\n",
      "Iteration 353: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4491    number of train samples: 6565\n",
      "Iteration 354: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4497    number of train samples: 6570\n",
      "Iteration 355: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4503    number of train samples: 6575\n",
      "Iteration 356: - Train Loss: 0.3102 - Test Loss: 0.3119 - Test Accuracy: 0.9111\n",
      "       Current train loss: 0.4505    number of train samples: 6580\n",
      "Iteration 357: - Train Loss: 0.3088 - Test Loss: 0.3105 - Test Accuracy: 0.9119\n",
      "       Current train loss: 0.4493    number of train samples: 6585\n",
      "Iteration 358: - Train Loss: 0.3093 - Test Loss: 0.3112 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4498    number of train samples: 6590\n",
      "Iteration 359: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4504    number of train samples: 6595\n",
      "Iteration 360: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4508    number of train samples: 6600\n",
      "Iteration 361: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4517    number of train samples: 6605\n",
      "Iteration 362: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4522    number of train samples: 6610\n",
      "Iteration 363: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4525    number of train samples: 6615\n",
      "Iteration 364: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4529    number of train samples: 6620\n",
      "Iteration 365: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4534    number of train samples: 6625\n",
      "Iteration 366: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4540    number of train samples: 6630\n",
      "Iteration 367: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4543    number of train samples: 6635\n",
      "Iteration 368: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4548    number of train samples: 6640\n",
      "Iteration 369: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4555    number of train samples: 6645\n",
      "Iteration 370: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4558    number of train samples: 6650\n",
      "Iteration 371: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4562    number of train samples: 6655\n",
      "Iteration 372: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4570    number of train samples: 6660\n",
      "Iteration 373: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4579    number of train samples: 6665\n",
      "Iteration 374: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4582    number of train samples: 6670\n",
      "Iteration 375: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4584    number of train samples: 6675\n",
      "Iteration 376: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4588    number of train samples: 6680\n",
      "Iteration 377: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4592    number of train samples: 6685\n",
      "Iteration 378: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4600    number of train samples: 6690\n",
      "Iteration 379: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4604    number of train samples: 6695\n",
      "Iteration 380: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4610    number of train samples: 6700\n",
      "Iteration 381: - Train Loss: 0.3090 - Test Loss: 0.3110 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4613    number of train samples: 6705\n",
      "Iteration 382: - Train Loss: 0.3091 - Test Loss: 0.3111 - Test Accuracy: 0.9116\n",
      "       Current train loss: 0.4610    number of train samples: 6710\n",
      "Iteration 383: - Train Loss: 0.3091 - Test Loss: 0.3111 - Test Accuracy: 0.9116\n",
      "       Current train loss: 0.4614    number of train samples: 6715\n",
      "Iteration 384: - Train Loss: 0.3089 - Test Loss: 0.3110 - Test Accuracy: 0.9113\n",
      "       Current train loss: 0.4616    number of train samples: 6720\n",
      "Iteration 385: - Train Loss: 0.3089 - Test Loss: 0.3110 - Test Accuracy: 0.9113\n",
      "       Current train loss: 0.4619    number of train samples: 6725\n",
      "Iteration 386: - Train Loss: 0.3089 - Test Loss: 0.3110 - Test Accuracy: 0.9113\n",
      "       Current train loss: 0.4628    number of train samples: 6730\n",
      "Iteration 387: - Train Loss: 0.3082 - Test Loss: 0.3112 - Test Accuracy: 0.9107\n",
      "       Current train loss: 0.4590    number of train samples: 6735\n",
      "Iteration 388: - Train Loss: 0.3082 - Test Loss: 0.3112 - Test Accuracy: 0.9107\n",
      "       Current train loss: 0.4595    number of train samples: 6740\n",
      "Iteration 389: - Train Loss: 0.3082 - Test Loss: 0.3112 - Test Accuracy: 0.9107\n",
      "       Current train loss: 0.4603    number of train samples: 6745\n",
      "Iteration 390: - Train Loss: 0.3082 - Test Loss: 0.3112 - Test Accuracy: 0.9107\n",
      "       Current train loss: 0.4606    number of train samples: 6750\n",
      "Iteration 391: - Train Loss: 0.3082 - Test Loss: 0.3112 - Test Accuracy: 0.9107\n",
      "       Current train loss: 0.4611    number of train samples: 6755\n",
      "Iteration 392: - Train Loss: 0.3074 - Test Loss: 0.3105 - Test Accuracy: 0.9122\n",
      "       Current train loss: 0.4604    number of train samples: 6760\n",
      "Iteration 393: - Train Loss: 0.3074 - Test Loss: 0.3105 - Test Accuracy: 0.9122\n",
      "       Current train loss: 0.4608    number of train samples: 6765\n",
      "Iteration 394: - Train Loss: 0.3074 - Test Loss: 0.3105 - Test Accuracy: 0.9122\n",
      "       Current train loss: 0.4614    number of train samples: 6770\n",
      "Iteration 395: - Train Loss: 0.3074 - Test Loss: 0.3105 - Test Accuracy: 0.9122\n",
      "       Current train loss: 0.4620    number of train samples: 6775\n",
      "Iteration 396: - Train Loss: 0.3074 - Test Loss: 0.3105 - Test Accuracy: 0.9122\n",
      "       Current train loss: 0.4622    number of train samples: 6780\n",
      "Iteration 397: - Train Loss: 0.3074 - Test Loss: 0.3105 - Test Accuracy: 0.9122\n",
      "       Current train loss: 0.4625    number of train samples: 6785\n",
      "Iteration 398: - Train Loss: 0.3074 - Test Loss: 0.3105 - Test Accuracy: 0.9122\n",
      "       Current train loss: 0.4629    number of train samples: 6790\n",
      "Iteration 399: - Train Loss: 0.3074 - Test Loss: 0.3105 - Test Accuracy: 0.9122\n",
      "       Current train loss: 0.4631    number of train samples: 6795\n",
      "Iteration 400: - Train Loss: 0.3074 - Test Loss: 0.3105 - Test Accuracy: 0.9122\n",
      "       Current train loss: 0.4636    number of train samples: 6800\n",
      "Iteration 401: - Train Loss: 0.3070 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4630    number of train samples: 6805\n",
      "Iteration 402: - Train Loss: 0.3070 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4635    number of train samples: 6810\n",
      "Iteration 403: - Train Loss: 0.3070 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4637    number of train samples: 6815\n",
      "Iteration 404: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4640    number of train samples: 6820\n",
      "Iteration 405: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4643    number of train samples: 6825\n",
      "Iteration 406: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4647    number of train samples: 6830\n",
      "Iteration 407: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4651    number of train samples: 6835\n",
      "Iteration 408: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4654    number of train samples: 6840\n",
      "Iteration 409: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4660    number of train samples: 6845\n",
      "Iteration 410: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4663    number of train samples: 6850\n",
      "Iteration 411: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4668    number of train samples: 6855\n",
      "Iteration 412: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4670    number of train samples: 6860\n",
      "Iteration 413: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4673    number of train samples: 6865\n",
      "Iteration 414: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4686    number of train samples: 6870\n",
      "Iteration 415: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4703    number of train samples: 6875\n",
      "Iteration 416: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4709    number of train samples: 6880\n",
      "Iteration 417: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4712    number of train samples: 6885\n",
      "Iteration 418: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4716    number of train samples: 6890\n",
      "Iteration 419: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4718    number of train samples: 6895\n",
      "Iteration 420: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4723    number of train samples: 6900\n",
      "Iteration 421: - Train Loss: 0.3069 - Test Loss: 0.3092 - Test Accuracy: 0.9112\n",
      "       Current train loss: 0.4728    number of train samples: 6905\n",
      "Iteration 422: - Train Loss: 0.3069 - Test Loss: 0.3091 - Test Accuracy: 0.9117\n",
      "       Current train loss: 0.4729    number of train samples: 6910\n",
      "Iteration 423: - Train Loss: 0.3069 - Test Loss: 0.3091 - Test Accuracy: 0.9117\n",
      "       Current train loss: 0.4738    number of train samples: 6915\n",
      "Iteration 424: - Train Loss: 0.3069 - Test Loss: 0.3091 - Test Accuracy: 0.9117\n",
      "       Current train loss: 0.4741    number of train samples: 6920\n",
      "Iteration 425: - Train Loss: 0.3067 - Test Loss: 0.3091 - Test Accuracy: 0.9116\n",
      "       Current train loss: 0.4745    number of train samples: 6925\n",
      "Iteration 426: - Train Loss: 0.3057 - Test Loss: 0.3083 - Test Accuracy: 0.9133\n",
      "       Current train loss: 0.4681    number of train samples: 6930\n",
      "Iteration 427: - Train Loss: 0.3057 - Test Loss: 0.3083 - Test Accuracy: 0.9133\n",
      "       Current train loss: 0.4689    number of train samples: 6935\n",
      "Iteration 428: - Train Loss: 0.3057 - Test Loss: 0.3083 - Test Accuracy: 0.9133\n",
      "       Current train loss: 0.4697    number of train samples: 6940\n",
      "Iteration 429: - Train Loss: 0.3060 - Test Loss: 0.3089 - Test Accuracy: 0.9127\n",
      "       Current train loss: 0.4701    number of train samples: 6945\n",
      "Iteration 430: - Train Loss: 0.3060 - Test Loss: 0.3089 - Test Accuracy: 0.9127\n",
      "       Current train loss: 0.4711    number of train samples: 6950\n",
      "Iteration 431: - Train Loss: 0.3060 - Test Loss: 0.3089 - Test Accuracy: 0.9127\n",
      "       Current train loss: 0.4716    number of train samples: 6955\n",
      "Iteration 432: - Train Loss: 0.3060 - Test Loss: 0.3089 - Test Accuracy: 0.9127\n",
      "       Current train loss: 0.4725    number of train samples: 6960\n",
      "Iteration 433: - Train Loss: 0.3060 - Test Loss: 0.3089 - Test Accuracy: 0.9127\n",
      "       Current train loss: 0.4732    number of train samples: 6965\n",
      "Iteration 434: - Train Loss: 0.3056 - Test Loss: 0.3084 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4735    number of train samples: 6970\n",
      "Iteration 435: - Train Loss: 0.3056 - Test Loss: 0.3084 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4741    number of train samples: 6975\n",
      "Iteration 436: - Train Loss: 0.3056 - Test Loss: 0.3084 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4744    number of train samples: 6980\n",
      "Iteration 437: - Train Loss: 0.3056 - Test Loss: 0.3084 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4748    number of train samples: 6985\n",
      "Iteration 438: - Train Loss: 0.3056 - Test Loss: 0.3084 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4751    number of train samples: 6990\n",
      "Iteration 439: - Train Loss: 0.3056 - Test Loss: 0.3084 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4760    number of train samples: 6995\n",
      "Iteration 440: - Train Loss: 0.3056 - Test Loss: 0.3084 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4763    number of train samples: 7000\n",
      "Iteration 441: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4763    number of train samples: 7005\n",
      "Iteration 442: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4765    number of train samples: 7010\n",
      "Iteration 443: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4770    number of train samples: 7015\n",
      "Iteration 444: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4773    number of train samples: 7020\n",
      "Iteration 445: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4776    number of train samples: 7025\n",
      "Iteration 446: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4781    number of train samples: 7030\n",
      "Iteration 447: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4783    number of train samples: 7035\n",
      "Iteration 448: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4787    number of train samples: 7040\n",
      "Iteration 449: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4792    number of train samples: 7045\n",
      "Iteration 450: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4797    number of train samples: 7050\n",
      "Iteration 451: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4799    number of train samples: 7055\n",
      "Iteration 452: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4801    number of train samples: 7060\n",
      "Iteration 453: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4803    number of train samples: 7065\n",
      "Iteration 454: - Train Loss: 0.3058 - Test Loss: 0.3088 - Test Accuracy: 0.913\n",
      "       Current train loss: 0.4806    number of train samples: 7070\n",
      "Iteration 455: - Train Loss: 0.3048 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4788    number of train samples: 7075\n",
      "Iteration 456: - Train Loss: 0.3048 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4793    number of train samples: 7080\n",
      "Iteration 457: - Train Loss: 0.3048 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4796    number of train samples: 7085\n",
      "Iteration 458: - Train Loss: 0.3048 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4798    number of train samples: 7090\n",
      "Iteration 459: - Train Loss: 0.3048 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4802    number of train samples: 7095\n",
      "Iteration 460: - Train Loss: 0.3048 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4815    number of train samples: 7100\n",
      "Iteration 461: - Train Loss: 0.3048 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4819    number of train samples: 7105\n",
      "Iteration 462: - Train Loss: 0.3048 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4821    number of train samples: 7110\n",
      "Iteration 463: - Train Loss: 0.3048 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4828    number of train samples: 7115\n",
      "Iteration 464: - Train Loss: 0.3048 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4830    number of train samples: 7120\n",
      "Iteration 465: - Train Loss: 0.3048 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4834    number of train samples: 7125\n",
      "Iteration 466: - Train Loss: 0.3048 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4841    number of train samples: 7130\n",
      "Iteration 467: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4835    number of train samples: 7135\n",
      "Iteration 468: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4843    number of train samples: 7140\n",
      "Iteration 469: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4847    number of train samples: 7145\n",
      "Iteration 470: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4850    number of train samples: 7150\n",
      "Iteration 471: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4852    number of train samples: 7155\n",
      "Iteration 472: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4854    number of train samples: 7160\n",
      "Iteration 473: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4857    number of train samples: 7165\n",
      "Iteration 474: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4859    number of train samples: 7170\n",
      "Iteration 475: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4861    number of train samples: 7175\n",
      "Iteration 476: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4864    number of train samples: 7180\n",
      "Iteration 477: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4867    number of train samples: 7185\n",
      "Iteration 478: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4868    number of train samples: 7190\n",
      "Iteration 479: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4870    number of train samples: 7195\n",
      "Iteration 480: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4872    number of train samples: 7200\n",
      "Iteration 481: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4875    number of train samples: 7205\n",
      "Iteration 482: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4882    number of train samples: 7210\n",
      "Iteration 483: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4886    number of train samples: 7215\n",
      "Iteration 484: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4905    number of train samples: 7220\n",
      "Iteration 485: - Train Loss: 0.3044 - Test Loss: 0.3074 - Test Accuracy: 0.9134\n",
      "       Current train loss: 0.4909    number of train samples: 7225\n",
      "Iteration 486: - Train Loss: 0.3042 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4908    number of train samples: 7230\n",
      "Iteration 487: - Train Loss: 0.3042 - Test Loss: 0.3074 - Test Accuracy: 0.9138\n",
      "       Current train loss: 0.4910    number of train samples: 7235\n",
      "Iteration 488: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4911    number of train samples: 7240\n",
      "Iteration 489: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4913    number of train samples: 7245\n",
      "Iteration 490: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4914    number of train samples: 7250\n",
      "Iteration 491: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4916    number of train samples: 7255\n",
      "Iteration 492: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4918    number of train samples: 7260\n",
      "Iteration 493: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4923    number of train samples: 7265\n",
      "Iteration 494: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4928    number of train samples: 7270\n",
      "Iteration 495: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4933    number of train samples: 7275\n",
      "Iteration 496: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4937    number of train samples: 7280\n",
      "Iteration 497: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4939    number of train samples: 7285\n",
      "Iteration 498: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4941    number of train samples: 7290\n",
      "Iteration 499: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4943    number of train samples: 7295\n",
      "Iteration 500: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4949    number of train samples: 7300\n",
      "Iteration 501: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4950    number of train samples: 7305\n",
      "Iteration 502: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4952    number of train samples: 7310\n",
      "Iteration 503: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4954    number of train samples: 7315\n",
      "Iteration 504: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4955    number of train samples: 7320\n",
      "Iteration 505: - Train Loss: 0.3040 - Test Loss: 0.3072 - Test Accuracy: 0.914\n",
      "       Current train loss: 0.4966    number of train samples: 7325\n",
      "Iteration 506: - Train Loss: 0.3014 - Test Loss: 0.3053 - Test Accuracy: 0.9148\n",
      "       Current train loss: 0.4917    number of train samples: 7330\n",
      "Iteration 507: - Train Loss: 0.3014 - Test Loss: 0.3053 - Test Accuracy: 0.9148\n",
      "       Current train loss: 0.4922    number of train samples: 7335\n",
      "Iteration 508: - Train Loss: 0.3014 - Test Loss: 0.3053 - Test Accuracy: 0.9148\n",
      "       Current train loss: 0.4924    number of train samples: 7340\n",
      "Iteration 509: - Train Loss: 0.3014 - Test Loss: 0.3053 - Test Accuracy: 0.9148\n",
      "       Current train loss: 0.4930    number of train samples: 7345\n",
      "Iteration 510: - Train Loss: 0.3012 - Test Loss: 0.3056 - Test Accuracy: 0.9152\n",
      "       Current train loss: 0.4930    number of train samples: 7350\n",
      "Iteration 511: - Train Loss: 0.3011 - Test Loss: 0.3054 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4933    number of train samples: 7355\n",
      "Iteration 512: - Train Loss: 0.3011 - Test Loss: 0.3054 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4937    number of train samples: 7360\n",
      "Iteration 513: - Train Loss: 0.3011 - Test Loss: 0.3054 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4939    number of train samples: 7365\n",
      "Iteration 514: - Train Loss: 0.3011 - Test Loss: 0.3054 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4947    number of train samples: 7370\n",
      "Iteration 515: - Train Loss: 0.3011 - Test Loss: 0.3054 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4950    number of train samples: 7375\n",
      "Iteration 516: - Train Loss: 0.3012 - Test Loss: 0.3056 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4951    number of train samples: 7380\n",
      "Iteration 517: - Train Loss: 0.3012 - Test Loss: 0.3056 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4953    number of train samples: 7385\n",
      "Iteration 518: - Train Loss: 0.3012 - Test Loss: 0.3056 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4956    number of train samples: 7390\n",
      "Iteration 519: - Train Loss: 0.3012 - Test Loss: 0.3056 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4958    number of train samples: 7395\n",
      "Iteration 520: - Train Loss: 0.3012 - Test Loss: 0.3056 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4960    number of train samples: 7400\n",
      "Iteration 521: - Train Loss: 0.3012 - Test Loss: 0.3056 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4964    number of train samples: 7405\n",
      "Iteration 522: - Train Loss: 0.3012 - Test Loss: 0.3056 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4972    number of train samples: 7410\n",
      "Iteration 523: - Train Loss: 0.3012 - Test Loss: 0.3056 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4974    number of train samples: 7415\n",
      "Iteration 524: - Train Loss: 0.3012 - Test Loss: 0.3056 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4976    number of train samples: 7420\n",
      "Iteration 525: - Train Loss: 0.3012 - Test Loss: 0.3056 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4979    number of train samples: 7425\n",
      "Iteration 526: - Train Loss: 0.3012 - Test Loss: 0.3056 - Test Accuracy: 0.9151\n",
      "       Current train loss: 0.4981    number of train samples: 7430\n",
      "Iteration 527: - Train Loss: 0.3011 - Test Loss: 0.3055 - Test Accuracy: 0.9152\n",
      "       Current train loss: 0.4979    number of train samples: 7435\n",
      "Iteration 528: - Train Loss: 0.3011 - Test Loss: 0.3055 - Test Accuracy: 0.9152\n",
      "       Current train loss: 0.4987    number of train samples: 7440\n",
      "Iteration 529: - Train Loss: 0.3011 - Test Loss: 0.3055 - Test Accuracy: 0.9152\n",
      "       Current train loss: 0.4990    number of train samples: 7445\n",
      "Iteration 530: - Train Loss: 0.3009 - Test Loss: 0.3054 - Test Accuracy: 0.915\n",
      "       Current train loss: 0.4991    number of train samples: 7450\n",
      "Iteration 531: - Train Loss: 0.3009 - Test Loss: 0.3054 - Test Accuracy: 0.915\n",
      "       Current train loss: 0.4997    number of train samples: 7455\n",
      "Iteration 532: - Train Loss: 0.3009 - Test Loss: 0.3054 - Test Accuracy: 0.915\n",
      "       Current train loss: 0.4999    number of train samples: 7460\n",
      "Iteration 533: - Train Loss: 0.3009 - Test Loss: 0.3054 - Test Accuracy: 0.915\n",
      "       Current train loss: 0.5002    number of train samples: 7465\n",
      "Iteration 534: - Train Loss: 0.3009 - Test Loss: 0.3054 - Test Accuracy: 0.915\n",
      "       Current train loss: 0.5003    number of train samples: 7470\n",
      "Iteration 535: - Train Loss: 0.3009 - Test Loss: 0.3054 - Test Accuracy: 0.915\n",
      "       Current train loss: 0.5007    number of train samples: 7475\n",
      "Iteration 536: - Train Loss: 0.3009 - Test Loss: 0.3054 - Test Accuracy: 0.915\n",
      "       Current train loss: 0.5019    number of train samples: 7480\n",
      "Iteration 537: - Train Loss: 0.3007 - Test Loss: 0.3051 - Test Accuracy: 0.9146\n",
      "       Current train loss: 0.5024    number of train samples: 7485\n",
      "Iteration 538: - Train Loss: 0.3007 - Test Loss: 0.3051 - Test Accuracy: 0.9146\n",
      "       Current train loss: 0.5025    number of train samples: 7490\n",
      "Iteration 539: - Train Loss: 0.3007 - Test Loss: 0.3051 - Test Accuracy: 0.9146\n",
      "       Current train loss: 0.5026    number of train samples: 7495\n",
      "Iteration 540: - Train Loss: 0.3007 - Test Loss: 0.3051 - Test Accuracy: 0.9146\n",
      "       Current train loss: 0.5028    number of train samples: 7500\n",
      "Iteration 541: - Train Loss: 0.3007 - Test Loss: 0.3051 - Test Accuracy: 0.9146\n",
      "       Current train loss: 0.5030    number of train samples: 7505\n",
      "Iteration 542: - Train Loss: 0.3007 - Test Loss: 0.3051 - Test Accuracy: 0.9146\n",
      "       Current train loss: 0.5036    number of train samples: 7510\n",
      "Iteration 543: - Train Loss: 0.3007 - Test Loss: 0.3051 - Test Accuracy: 0.9146\n",
      "       Current train loss: 0.5039    number of train samples: 7515\n",
      "Iteration 544: - Train Loss: 0.3008 - Test Loss: 0.3053 - Test Accuracy: 0.9148\n",
      "       Current train loss: 0.5042    number of train samples: 7520\n",
      "Iteration 545: - Train Loss: 0.3008 - Test Loss: 0.3053 - Test Accuracy: 0.9148\n",
      "       Current train loss: 0.5043    number of train samples: 7525\n",
      "Iteration 546: - Train Loss: 0.3008 - Test Loss: 0.3053 - Test Accuracy: 0.9148\n",
      "       Current train loss: 0.5044    number of train samples: 7530\n",
      "Iteration 547: - Train Loss: 0.3008 - Test Loss: 0.3053 - Test Accuracy: 0.9148\n",
      "       Current train loss: 0.5046    number of train samples: 7535\n",
      "Iteration 548: - Train Loss: 0.3004 - Test Loss: 0.3048 - Test Accuracy: 0.9147\n",
      "       Current train loss: 0.5045    number of train samples: 7540\n",
      "Iteration 549: - Train Loss: 0.3004 - Test Loss: 0.3048 - Test Accuracy: 0.9147\n",
      "       Current train loss: 0.5049    number of train samples: 7545\n",
      "Iteration 550: - Train Loss: 0.3004 - Test Loss: 0.3048 - Test Accuracy: 0.9147\n",
      "       Current train loss: 0.5050    number of train samples: 7550\n",
      "Iteration 551: - Train Loss: 0.3004 - Test Loss: 0.3048 - Test Accuracy: 0.9147\n",
      "       Current train loss: 0.5056    number of train samples: 7555\n",
      "Iteration 552: - Train Loss: 0.3004 - Test Loss: 0.3048 - Test Accuracy: 0.9147\n",
      "       Current train loss: 0.5061    number of train samples: 7560\n",
      "Iteration 553: - Train Loss: 0.3004 - Test Loss: 0.3048 - Test Accuracy: 0.9147\n",
      "       Current train loss: 0.5065    number of train samples: 7565\n",
      "Iteration 554: - Train Loss: 0.2989 - Test Loss: 0.3035 - Test Accuracy: 0.9165\n",
      "       Current train loss: 0.5039    number of train samples: 7570\n",
      "Iteration 555: - Train Loss: 0.2989 - Test Loss: 0.3035 - Test Accuracy: 0.9165\n",
      "       Current train loss: 0.5043    number of train samples: 7575\n",
      "Iteration 556: - Train Loss: 0.2989 - Test Loss: 0.3035 - Test Accuracy: 0.9165\n",
      "       Current train loss: 0.5047    number of train samples: 7580\n",
      "Iteration 557: - Train Loss: 0.2989 - Test Loss: 0.3035 - Test Accuracy: 0.9165\n",
      "       Current train loss: 0.5051    number of train samples: 7585\n",
      "Iteration 558: - Train Loss: 0.2989 - Test Loss: 0.3035 - Test Accuracy: 0.9165\n",
      "       Current train loss: 0.5053    number of train samples: 7590\n",
      "Iteration 559: - Train Loss: 0.2989 - Test Loss: 0.3035 - Test Accuracy: 0.9165\n",
      "       Current train loss: 0.5058    number of train samples: 7595\n",
      "Iteration 560: - Train Loss: 0.2989 - Test Loss: 0.3035 - Test Accuracy: 0.9165\n",
      "       Current train loss: 0.5063    number of train samples: 7600\n",
      "Iteration 561: - Train Loss: 0.2989 - Test Loss: 0.3035 - Test Accuracy: 0.9165\n",
      "       Current train loss: 0.5072    number of train samples: 7605\n",
      "Iteration 562: - Train Loss: 0.2989 - Test Loss: 0.3035 - Test Accuracy: 0.9165\n",
      "       Current train loss: 0.5074    number of train samples: 7610\n",
      "Iteration 563: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5068    number of train samples: 7615\n",
      "Iteration 564: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5073    number of train samples: 7620\n",
      "Iteration 565: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5074    number of train samples: 7625\n",
      "Iteration 566: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5076    number of train samples: 7630\n",
      "Iteration 567: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5083    number of train samples: 7635\n",
      "Iteration 568: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5088    number of train samples: 7640\n",
      "Iteration 569: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5090    number of train samples: 7645\n",
      "Iteration 570: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5094    number of train samples: 7650\n",
      "Iteration 571: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5097    number of train samples: 7655\n",
      "Iteration 572: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5099    number of train samples: 7660\n",
      "Iteration 573: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5103    number of train samples: 7665\n",
      "Iteration 574: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5108    number of train samples: 7670\n",
      "Iteration 575: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5110    number of train samples: 7675\n",
      "Iteration 576: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5111    number of train samples: 7680\n",
      "Iteration 577: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5122    number of train samples: 7685\n",
      "Iteration 578: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5128    number of train samples: 7690\n",
      "Iteration 579: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5129    number of train samples: 7695\n",
      "Iteration 580: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5131    number of train samples: 7700\n",
      "Iteration 581: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5132    number of train samples: 7705\n",
      "Iteration 582: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5137    number of train samples: 7710\n",
      "Iteration 583: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5139    number of train samples: 7715\n",
      "Iteration 584: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5141    number of train samples: 7720\n",
      "Iteration 585: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5144    number of train samples: 7725\n",
      "Iteration 586: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5148    number of train samples: 7730\n",
      "Iteration 587: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5152    number of train samples: 7735\n",
      "Iteration 588: - Train Loss: 0.2986 - Test Loss: 0.3033 - Test Accuracy: 0.9157\n",
      "       Current train loss: 0.5157    number of train samples: 7740\n",
      "Iteration 589: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5150    number of train samples: 7745\n",
      "Iteration 590: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5162    number of train samples: 7750\n",
      "Iteration 591: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5170    number of train samples: 7755\n",
      "Iteration 592: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5176    number of train samples: 7760\n",
      "Iteration 593: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5178    number of train samples: 7765\n",
      "Iteration 594: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5179    number of train samples: 7770\n",
      "Iteration 595: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5191    number of train samples: 7775\n",
      "Iteration 596: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5193    number of train samples: 7780\n",
      "Iteration 597: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5194    number of train samples: 7785\n",
      "Iteration 598: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5200    number of train samples: 7790\n",
      "Iteration 599: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5202    number of train samples: 7795\n",
      "Iteration 600: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5204    number of train samples: 7800\n",
      "Iteration 601: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5208    number of train samples: 7805\n",
      "Iteration 602: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5209    number of train samples: 7810\n",
      "Iteration 603: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5211    number of train samples: 7815\n",
      "Iteration 604: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5213    number of train samples: 7820\n",
      "Iteration 605: - Train Loss: 0.2984 - Test Loss: 0.3034 - Test Accuracy: 0.9171\n",
      "       Current train loss: 0.5218    number of train samples: 7825\n",
      "Iteration 606: - Train Loss: 0.2979 - Test Loss: 0.3027 - Test Accuracy: 0.9173\n",
      "       Current train loss: 0.5219    number of train samples: 7830\n",
      "Iteration 607: - Train Loss: 0.2979 - Test Loss: 0.3027 - Test Accuracy: 0.9173\n",
      "       Current train loss: 0.5221    number of train samples: 7835\n",
      "Iteration 608: - Train Loss: 0.2979 - Test Loss: 0.3027 - Test Accuracy: 0.9173\n",
      "       Current train loss: 0.5222    number of train samples: 7840\n",
      "Iteration 609: - Train Loss: 0.2979 - Test Loss: 0.3027 - Test Accuracy: 0.9173\n",
      "       Current train loss: 0.5225    number of train samples: 7845\n",
      "Iteration 610: - Train Loss: 0.2979 - Test Loss: 0.3027 - Test Accuracy: 0.9173\n",
      "       Current train loss: 0.5230    number of train samples: 7850\n",
      "Iteration 611: - Train Loss: 0.2979 - Test Loss: 0.3027 - Test Accuracy: 0.9173\n",
      "       Current train loss: 0.5232    number of train samples: 7855\n",
      "Iteration 612: - Train Loss: 0.2979 - Test Loss: 0.3027 - Test Accuracy: 0.9173\n",
      "       Current train loss: 0.5235    number of train samples: 7860\n",
      "Iteration 613: - Train Loss: 0.2979 - Test Loss: 0.3027 - Test Accuracy: 0.9173\n",
      "       Current train loss: 0.5236    number of train samples: 7865\n",
      "Iteration 614: - Train Loss: 0.2979 - Test Loss: 0.3027 - Test Accuracy: 0.9173\n",
      "       Current train loss: 0.5243    number of train samples: 7870\n",
      "Iteration 615: - Train Loss: 0.2978 - Test Loss: 0.3027 - Test Accuracy: 0.9174\n",
      "       Current train loss: 0.5244    number of train samples: 7875\n",
      "Iteration 616: - Train Loss: 0.2978 - Test Loss: 0.3027 - Test Accuracy: 0.9174\n",
      "       Current train loss: 0.5246    number of train samples: 7880\n",
      "Iteration 617: - Train Loss: 0.2978 - Test Loss: 0.3027 - Test Accuracy: 0.9174\n",
      "       Current train loss: 0.5247    number of train samples: 7885\n",
      "Iteration 618: - Train Loss: 0.2956 - Test Loss: 0.3015 - Test Accuracy: 0.9183\n",
      "       Current train loss: 0.5178    number of train samples: 7890\n",
      "Iteration 619: - Train Loss: 0.2956 - Test Loss: 0.3015 - Test Accuracy: 0.9183\n",
      "       Current train loss: 0.5183    number of train samples: 7895\n",
      "Iteration 620: - Train Loss: 0.2956 - Test Loss: 0.3015 - Test Accuracy: 0.9183\n",
      "       Current train loss: 0.5187    number of train samples: 7900\n",
      "Iteration 621: - Train Loss: 0.2949 - Test Loss: 0.3009 - Test Accuracy: 0.9184\n",
      "       Current train loss: 0.5179    number of train samples: 7905\n",
      "Iteration 622: - Train Loss: 0.2949 - Test Loss: 0.3009 - Test Accuracy: 0.9184\n",
      "       Current train loss: 0.5187    number of train samples: 7910\n",
      "Iteration 623: - Train Loss: 0.2949 - Test Loss: 0.3009 - Test Accuracy: 0.9184\n",
      "       Current train loss: 0.5189    number of train samples: 7915\n",
      "Iteration 624: - Train Loss: 0.2949 - Test Loss: 0.3009 - Test Accuracy: 0.9184\n",
      "       Current train loss: 0.5192    number of train samples: 7920\n",
      "Iteration 625: - Train Loss: 0.2949 - Test Loss: 0.3009 - Test Accuracy: 0.9184\n",
      "       Current train loss: 0.5197    number of train samples: 7925\n",
      "Iteration 626: - Train Loss: 0.2949 - Test Loss: 0.3009 - Test Accuracy: 0.9184\n",
      "       Current train loss: 0.5202    number of train samples: 7930\n",
      "Iteration 627: - Train Loss: 0.2949 - Test Loss: 0.3009 - Test Accuracy: 0.9184\n",
      "       Current train loss: 0.5204    number of train samples: 7935\n",
      "Iteration 628: - Train Loss: 0.2949 - Test Loss: 0.3009 - Test Accuracy: 0.9184\n",
      "       Current train loss: 0.5209    number of train samples: 7940\n",
      "Iteration 629: - Train Loss: 0.2949 - Test Loss: 0.3010 - Test Accuracy: 0.9191\n",
      "       Current train loss: 0.5212    number of train samples: 7945\n",
      "Iteration 630: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5212    number of train samples: 7950\n",
      "Iteration 631: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5214    number of train samples: 7955\n",
      "Iteration 632: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5221    number of train samples: 7960\n",
      "Iteration 633: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5225    number of train samples: 7965\n",
      "Iteration 634: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5227    number of train samples: 7970\n",
      "Iteration 635: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5234    number of train samples: 7975\n",
      "Iteration 636: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5236    number of train samples: 7980\n",
      "Iteration 637: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5238    number of train samples: 7985\n",
      "Iteration 638: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5243    number of train samples: 7990\n",
      "Iteration 639: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5244    number of train samples: 7995\n",
      "Iteration 640: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5246    number of train samples: 8000\n",
      "Iteration 641: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5251    number of train samples: 8005\n",
      "Iteration 642: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5254    number of train samples: 8010\n",
      "Iteration 643: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5264    number of train samples: 8015\n",
      "Iteration 644: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5267    number of train samples: 8020\n",
      "Iteration 645: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5268    number of train samples: 8025\n",
      "Iteration 646: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5270    number of train samples: 8030\n",
      "Iteration 647: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5271    number of train samples: 8035\n",
      "Iteration 648: - Train Loss: 0.2947 - Test Loss: 0.3008 - Test Accuracy: 0.9193\n",
      "       Current train loss: 0.5273    number of train samples: 8040\n",
      "Iteration 649: - Train Loss: 0.2943 - Test Loss: 0.3009 - Test Accuracy: 0.9198\n",
      "       Current train loss: 0.5260    number of train samples: 8045\n",
      "Iteration 650: - Train Loss: 0.2943 - Test Loss: 0.3009 - Test Accuracy: 0.9198\n",
      "       Current train loss: 0.5269    number of train samples: 8050\n",
      "Iteration 651: - Train Loss: 0.2943 - Test Loss: 0.3009 - Test Accuracy: 0.9198\n",
      "       Current train loss: 0.5273    number of train samples: 8055\n",
      "Iteration 652: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5271    number of train samples: 8060\n",
      "Iteration 653: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5273    number of train samples: 8065\n",
      "Iteration 654: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5274    number of train samples: 8070\n",
      "Iteration 655: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5276    number of train samples: 8075\n",
      "Iteration 656: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5279    number of train samples: 8080\n",
      "Iteration 657: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5281    number of train samples: 8085\n",
      "Iteration 658: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5282    number of train samples: 8090\n",
      "Iteration 659: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5290    number of train samples: 8095\n",
      "Iteration 660: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5293    number of train samples: 8100\n",
      "Iteration 661: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5296    number of train samples: 8105\n",
      "Iteration 662: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5297    number of train samples: 8110\n",
      "Iteration 663: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5299    number of train samples: 8115\n",
      "Iteration 664: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5300    number of train samples: 8120\n",
      "Iteration 665: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5302    number of train samples: 8125\n",
      "Iteration 666: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5303    number of train samples: 8130\n",
      "Iteration 667: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5305    number of train samples: 8135\n",
      "Iteration 668: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5307    number of train samples: 8140\n",
      "Iteration 669: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5309    number of train samples: 8145\n",
      "Iteration 670: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5310    number of train samples: 8150\n",
      "Iteration 671: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5311    number of train samples: 8155\n",
      "Iteration 672: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5312    number of train samples: 8160\n",
      "Iteration 673: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5314    number of train samples: 8165\n",
      "Iteration 674: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5317    number of train samples: 8170\n",
      "Iteration 675: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5318    number of train samples: 8175\n",
      "Iteration 676: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5320    number of train samples: 8180\n",
      "Iteration 677: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5324    number of train samples: 8185\n",
      "Iteration 678: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5330    number of train samples: 8190\n",
      "Iteration 679: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5336    number of train samples: 8195\n",
      "Iteration 680: - Train Loss: 0.2942 - Test Loss: 0.3005 - Test Accuracy: 0.92\n",
      "       Current train loss: 0.5341    number of train samples: 8200\n",
      "Iteration 681: - Train Loss: 0.2941 - Test Loss: 0.3004 - Test Accuracy: 0.9204\n",
      "       Current train loss: 0.5342    number of train samples: 8205\n",
      "Iteration 682: - Train Loss: 0.2941 - Test Loss: 0.3004 - Test Accuracy: 0.9204\n",
      "       Current train loss: 0.5344    number of train samples: 8210\n",
      "Iteration 683: - Train Loss: 0.2941 - Test Loss: 0.3004 - Test Accuracy: 0.9204\n",
      "       Current train loss: 0.5345    number of train samples: 8215\n",
      "Iteration 684: - Train Loss: 0.2939 - Test Loss: 0.3002 - Test Accuracy: 0.9204\n",
      "       Current train loss: 0.5348    number of train samples: 8220\n",
      "Iteration 685: - Train Loss: 0.2936 - Test Loss: 0.2998 - Test Accuracy: 0.9202\n",
      "       Current train loss: 0.5347    number of train samples: 8225\n",
      "Iteration 686: - Train Loss: 0.2936 - Test Loss: 0.2998 - Test Accuracy: 0.9202\n",
      "       Current train loss: 0.5351    number of train samples: 8230\n",
      "Iteration 687: - Train Loss: 0.2936 - Test Loss: 0.2998 - Test Accuracy: 0.9202\n",
      "       Current train loss: 0.5355    number of train samples: 8235\n",
      "Iteration 688: - Train Loss: 0.2936 - Test Loss: 0.2998 - Test Accuracy: 0.9202\n",
      "       Current train loss: 0.5358    number of train samples: 8240\n",
      "Iteration 689: - Train Loss: 0.2936 - Test Loss: 0.2998 - Test Accuracy: 0.9202\n",
      "       Current train loss: 0.5359    number of train samples: 8245\n",
      "Iteration 690: - Train Loss: 0.2936 - Test Loss: 0.2998 - Test Accuracy: 0.9202\n",
      "       Current train loss: 0.5362    number of train samples: 8250\n",
      "Iteration 691: - Train Loss: 0.2936 - Test Loss: 0.2998 - Test Accuracy: 0.9202\n",
      "       Current train loss: 0.5369    number of train samples: 8255\n",
      "Iteration 692: - Train Loss: 0.2936 - Test Loss: 0.2998 - Test Accuracy: 0.9202\n",
      "       Current train loss: 0.5370    number of train samples: 8260\n",
      "Iteration 693: - Train Loss: 0.2936 - Test Loss: 0.2998 - Test Accuracy: 0.9202\n",
      "       Current train loss: 0.5374    number of train samples: 8265\n",
      "Iteration 694: - Train Loss: 0.2936 - Test Loss: 0.2998 - Test Accuracy: 0.9202\n",
      "       Current train loss: 0.5377    number of train samples: 8270\n",
      "Iteration 695: - Train Loss: 0.2936 - Test Loss: 0.2998 - Test Accuracy: 0.9202\n",
      "       Current train loss: 0.5380    number of train samples: 8275\n",
      "Iteration 696: - Train Loss: 0.2936 - Test Loss: 0.2999 - Test Accuracy: 0.9206\n",
      "       Current train loss: 0.5381    number of train samples: 8280\n",
      "Iteration 697: - Train Loss: 0.2936 - Test Loss: 0.2999 - Test Accuracy: 0.9206\n",
      "       Current train loss: 0.5383    number of train samples: 8285\n",
      "Iteration 698: - Train Loss: 0.2936 - Test Loss: 0.2999 - Test Accuracy: 0.9206\n",
      "       Current train loss: 0.5386    number of train samples: 8290\n",
      "Iteration 699: - Train Loss: 0.2936 - Test Loss: 0.2999 - Test Accuracy: 0.9206\n",
      "       Current train loss: 0.5387    number of train samples: 8295\n",
      "Iteration 700: - Train Loss: 0.2936 - Test Loss: 0.2999 - Test Accuracy: 0.9206\n",
      "       Current train loss: 0.5389    number of train samples: 8300\n",
      "Iteration 701: - Train Loss: 0.2936 - Test Loss: 0.2999 - Test Accuracy: 0.9206\n",
      "       Current train loss: 0.5389    number of train samples: 8305\n",
      "Iteration 702: - Train Loss: 0.2936 - Test Loss: 0.2999 - Test Accuracy: 0.9206\n",
      "       Current train loss: 0.5393    number of train samples: 8310\n",
      "Iteration 703: - Train Loss: 0.2936 - Test Loss: 0.2999 - Test Accuracy: 0.9206\n",
      "       Current train loss: 0.5393    number of train samples: 8315\n",
      "Iteration 704: - Train Loss: 0.2936 - Test Loss: 0.2999 - Test Accuracy: 0.9206\n",
      "       Current train loss: 0.5395    number of train samples: 8320\n",
      "Iteration 705: - Train Loss: 0.2936 - Test Loss: 0.2999 - Test Accuracy: 0.9206\n",
      "       Current train loss: 0.5398    number of train samples: 8325\n",
      "Iteration 706: - Train Loss: 0.2936 - Test Loss: 0.2999 - Test Accuracy: 0.9206\n",
      "       Current train loss: 0.5400    number of train samples: 8330\n",
      "Iteration 707: - Train Loss: 0.2936 - Test Loss: 0.2999 - Test Accuracy: 0.9206\n",
      "       Current train loss: 0.5402    number of train samples: 8335\n",
      "Iteration 708: - Train Loss: 0.2936 - Test Loss: 0.2999 - Test Accuracy: 0.9206\n",
      "       Current train loss: 0.5403    number of train samples: 8340\n",
      "Iteration 709: - Train Loss: 0.2896 - Test Loss: 0.2956 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5281    number of train samples: 8345\n",
      "Iteration 710: - Train Loss: 0.2896 - Test Loss: 0.2956 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5286    number of train samples: 8350\n",
      "Iteration 711: - Train Loss: 0.2896 - Test Loss: 0.2956 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5290    number of train samples: 8355\n",
      "Iteration 712: - Train Loss: 0.2896 - Test Loss: 0.2956 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5293    number of train samples: 8360\n",
      "Iteration 713: - Train Loss: 0.2896 - Test Loss: 0.2956 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5298    number of train samples: 8365\n",
      "Iteration 714: - Train Loss: 0.2897 - Test Loss: 0.2957 - Test Accuracy: 0.9209\n",
      "       Current train loss: 0.5301    number of train samples: 8370\n",
      "Iteration 715: - Train Loss: 0.2897 - Test Loss: 0.2957 - Test Accuracy: 0.9209\n",
      "       Current train loss: 0.5302    number of train samples: 8375\n",
      "Iteration 716: - Train Loss: 0.2897 - Test Loss: 0.2957 - Test Accuracy: 0.9209\n",
      "       Current train loss: 0.5305    number of train samples: 8380\n",
      "Iteration 717: - Train Loss: 0.2897 - Test Loss: 0.2957 - Test Accuracy: 0.9209\n",
      "       Current train loss: 0.5307    number of train samples: 8385\n",
      "Iteration 718: - Train Loss: 0.2895 - Test Loss: 0.2955 - Test Accuracy: 0.9211\n",
      "       Current train loss: 0.5307    number of train samples: 8390\n",
      "Iteration 719: - Train Loss: 0.2895 - Test Loss: 0.2955 - Test Accuracy: 0.9211\n",
      "       Current train loss: 0.5314    number of train samples: 8395\n",
      "Iteration 720: - Train Loss: 0.2895 - Test Loss: 0.2955 - Test Accuracy: 0.9211\n",
      "       Current train loss: 0.5315    number of train samples: 8400\n",
      "Iteration 721: - Train Loss: 0.2895 - Test Loss: 0.2955 - Test Accuracy: 0.9211\n",
      "       Current train loss: 0.5316    number of train samples: 8405\n",
      "Iteration 722: - Train Loss: 0.2895 - Test Loss: 0.2955 - Test Accuracy: 0.9211\n",
      "       Current train loss: 0.5321    number of train samples: 8410\n",
      "Iteration 723: - Train Loss: 0.2895 - Test Loss: 0.2955 - Test Accuracy: 0.9211\n",
      "       Current train loss: 0.5325    number of train samples: 8415\n",
      "Iteration 724: - Train Loss: 0.2895 - Test Loss: 0.2955 - Test Accuracy: 0.9211\n",
      "       Current train loss: 0.5327    number of train samples: 8420\n",
      "Iteration 725: - Train Loss: 0.2895 - Test Loss: 0.2955 - Test Accuracy: 0.9211\n",
      "       Current train loss: 0.5328    number of train samples: 8425\n",
      "Iteration 726: - Train Loss: 0.2895 - Test Loss: 0.2955 - Test Accuracy: 0.9211\n",
      "       Current train loss: 0.5333    number of train samples: 8430\n",
      "Iteration 727: - Train Loss: 0.2895 - Test Loss: 0.2955 - Test Accuracy: 0.9211\n",
      "       Current train loss: 0.5334    number of train samples: 8435\n",
      "Iteration 728: - Train Loss: 0.2895 - Test Loss: 0.2955 - Test Accuracy: 0.9211\n",
      "       Current train loss: 0.5340    number of train samples: 8440\n",
      "Iteration 729: - Train Loss: 0.2895 - Test Loss: 0.2955 - Test Accuracy: 0.9211\n",
      "       Current train loss: 0.5341    number of train samples: 8445\n",
      "Iteration 730: - Train Loss: 0.2895 - Test Loss: 0.2955 - Test Accuracy: 0.9211\n",
      "       Current train loss: 0.5345    number of train samples: 8450\n",
      "Iteration 731: - Train Loss: 0.2894 - Test Loss: 0.2957 - Test Accuracy: 0.9215\n",
      "       Current train loss: 0.5336    number of train samples: 8455\n",
      "Iteration 732: - Train Loss: 0.2894 - Test Loss: 0.2957 - Test Accuracy: 0.9215\n",
      "       Current train loss: 0.5337    number of train samples: 8460\n",
      "Iteration 733: - Train Loss: 0.2894 - Test Loss: 0.2957 - Test Accuracy: 0.9215\n",
      "       Current train loss: 0.5338    number of train samples: 8465\n",
      "Iteration 734: - Train Loss: 0.2894 - Test Loss: 0.2957 - Test Accuracy: 0.9215\n",
      "       Current train loss: 0.5339    number of train samples: 8470\n",
      "Iteration 735: - Train Loss: 0.2894 - Test Loss: 0.2957 - Test Accuracy: 0.9215\n",
      "       Current train loss: 0.5342    number of train samples: 8475\n",
      "Iteration 736: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5345    number of train samples: 8480\n",
      "Iteration 737: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5348    number of train samples: 8485\n",
      "Iteration 738: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5349    number of train samples: 8490\n",
      "Iteration 739: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5350    number of train samples: 8495\n",
      "Iteration 740: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5351    number of train samples: 8500\n",
      "Iteration 741: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5361    number of train samples: 8505\n",
      "Iteration 742: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5366    number of train samples: 8510\n",
      "Iteration 743: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5367    number of train samples: 8515\n",
      "Iteration 744: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5370    number of train samples: 8520\n",
      "Iteration 745: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5371    number of train samples: 8525\n",
      "Iteration 746: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5372    number of train samples: 8530\n",
      "Iteration 747: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5376    number of train samples: 8535\n",
      "Iteration 748: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5376    number of train samples: 8540\n",
      "Iteration 749: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5378    number of train samples: 8545\n",
      "Iteration 750: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5379    number of train samples: 8550\n",
      "Iteration 751: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5383    number of train samples: 8555\n",
      "Iteration 752: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5384    number of train samples: 8560\n",
      "Iteration 753: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5394    number of train samples: 8565\n",
      "Iteration 754: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5396    number of train samples: 8570\n",
      "Iteration 755: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5397    number of train samples: 8575\n",
      "Iteration 756: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5398    number of train samples: 8580\n",
      "Iteration 757: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5401    number of train samples: 8585\n",
      "Iteration 758: - Train Loss: 0.2891 - Test Loss: 0.2955 - Test Accuracy: 0.921\n",
      "       Current train loss: 0.5404    number of train samples: 8590\n",
      "Iteration 759: - Train Loss: 0.2883 - Test Loss: 0.2945 - Test Accuracy: 0.9215\n",
      "       Current train loss: 0.5399    number of train samples: 8595\n",
      "Iteration 760: - Train Loss: 0.2883 - Test Loss: 0.2945 - Test Accuracy: 0.9215\n",
      "       Current train loss: 0.5401    number of train samples: 8600\n",
      "Iteration 761: - Train Loss: 0.2883 - Test Loss: 0.2945 - Test Accuracy: 0.9215\n",
      "       Current train loss: 0.5408    number of train samples: 8605\n",
      "Iteration 762: - Train Loss: 0.2883 - Test Loss: 0.2945 - Test Accuracy: 0.9215\n",
      "       Current train loss: 0.5411    number of train samples: 8610\n",
      "Iteration 763: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5412    number of train samples: 8615\n",
      "Iteration 764: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5415    number of train samples: 8620\n",
      "Iteration 765: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5417    number of train samples: 8625\n",
      "Iteration 766: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5421    number of train samples: 8630\n",
      "Iteration 767: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5423    number of train samples: 8635\n",
      "Iteration 768: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5425    number of train samples: 8640\n",
      "Iteration 769: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5427    number of train samples: 8645\n",
      "Iteration 770: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5430    number of train samples: 8650\n",
      "Iteration 771: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5430    number of train samples: 8655\n",
      "Iteration 772: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5431    number of train samples: 8660\n",
      "Iteration 773: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5434    number of train samples: 8665\n",
      "Iteration 774: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5436    number of train samples: 8670\n",
      "Iteration 775: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5436    number of train samples: 8675\n",
      "Iteration 776: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5440    number of train samples: 8680\n",
      "Iteration 777: - Train Loss: 0.2883 - Test Loss: 0.2947 - Test Accuracy: 0.9214\n",
      "       Current train loss: 0.5441    number of train samples: 8685\n",
      "Iteration 778: - Train Loss: 0.2884 - Test Loss: 0.2947 - Test Accuracy: 0.9216\n",
      "       Current train loss: 0.5440    number of train samples: 8690\n",
      "Iteration 779: - Train Loss: 0.2884 - Test Loss: 0.2947 - Test Accuracy: 0.9216\n",
      "       Current train loss: 0.5443    number of train samples: 8695\n",
      "Iteration 780: - Train Loss: 0.2884 - Test Loss: 0.2947 - Test Accuracy: 0.9216\n",
      "       Current train loss: 0.5445    number of train samples: 8700\n",
      "Iteration 781: - Train Loss: 0.2884 - Test Loss: 0.2947 - Test Accuracy: 0.9216\n",
      "       Current train loss: 0.5446    number of train samples: 8705\n",
      "Iteration 782: - Train Loss: 0.2884 - Test Loss: 0.2947 - Test Accuracy: 0.9216\n",
      "       Current train loss: 0.5448    number of train samples: 8710\n",
      "Iteration 783: - Train Loss: 0.2884 - Test Loss: 0.2947 - Test Accuracy: 0.9216\n",
      "       Current train loss: 0.5448    number of train samples: 8715\n",
      "Iteration 784: - Train Loss: 0.2884 - Test Loss: 0.2947 - Test Accuracy: 0.9216\n",
      "       Current train loss: 0.5449    number of train samples: 8720\n",
      "Iteration 785: - Train Loss: 0.2884 - Test Loss: 0.2947 - Test Accuracy: 0.9216\n",
      "       Current train loss: 0.5451    number of train samples: 8725\n",
      "Iteration 786: - Train Loss: 0.2883 - Test Loss: 0.2948 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5452    number of train samples: 8730\n",
      "Iteration 787: - Train Loss: 0.2883 - Test Loss: 0.2948 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5453    number of train samples: 8735\n",
      "Iteration 788: - Train Loss: 0.2883 - Test Loss: 0.2948 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5454    number of train samples: 8740\n",
      "Iteration 789: - Train Loss: 0.2883 - Test Loss: 0.2948 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5456    number of train samples: 8745\n",
      "Iteration 790: - Train Loss: 0.2883 - Test Loss: 0.2948 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5459    number of train samples: 8750\n",
      "Iteration 791: - Train Loss: 0.2883 - Test Loss: 0.2948 - Test Accuracy: 0.9218\n",
      "       Current train loss: 0.5462    number of train samples: 8755\n",
      "Iteration 792: - Train Loss: 0.2883 - Test Loss: 0.2948 - Test Accuracy: 0.9218\n",
      "       Current train loss: 0.5463    number of train samples: 8760\n",
      "Iteration 793: - Train Loss: 0.2883 - Test Loss: 0.2948 - Test Accuracy: 0.9218\n",
      "       Current train loss: 0.5464    number of train samples: 8765\n",
      "Iteration 794: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5466    number of train samples: 8770\n",
      "Iteration 795: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5467    number of train samples: 8775\n",
      "Iteration 796: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5468    number of train samples: 8780\n",
      "Iteration 797: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5471    number of train samples: 8785\n",
      "Iteration 798: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5473    number of train samples: 8790\n",
      "Iteration 799: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5475    number of train samples: 8795\n",
      "Iteration 800: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5476    number of train samples: 8800\n",
      "Iteration 801: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5477    number of train samples: 8805\n",
      "Iteration 802: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5481    number of train samples: 8810\n",
      "Iteration 803: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5482    number of train samples: 8815\n",
      "Iteration 804: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5485    number of train samples: 8820\n",
      "Iteration 805: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5486    number of train samples: 8825\n",
      "Iteration 806: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5486    number of train samples: 8830\n",
      "Iteration 807: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5486    number of train samples: 8835\n",
      "Iteration 808: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5494    number of train samples: 8840\n",
      "Iteration 809: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5494    number of train samples: 8845\n",
      "Iteration 810: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5495    number of train samples: 8850\n",
      "Iteration 811: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5495    number of train samples: 8855\n",
      "Iteration 812: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5496    number of train samples: 8860\n",
      "Iteration 813: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5499    number of train samples: 8865\n",
      "Iteration 814: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5502    number of train samples: 8870\n",
      "Iteration 815: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5508    number of train samples: 8875\n",
      "Iteration 816: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5512    number of train samples: 8880\n",
      "Iteration 817: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5512    number of train samples: 8885\n",
      "Iteration 818: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5514    number of train samples: 8890\n",
      "Iteration 819: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5517    number of train samples: 8895\n",
      "Iteration 820: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5522    number of train samples: 8900\n",
      "Iteration 821: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5524    number of train samples: 8905\n",
      "Iteration 822: - Train Loss: 0.2882 - Test Loss: 0.2947 - Test Accuracy: 0.9217\n",
      "       Current train loss: 0.5526    number of train samples: 8910\n",
      "Iteration 823: - Train Loss: 0.2864 - Test Loss: 0.2935 - Test Accuracy: 0.9221\n",
      "       Current train loss: 0.5504    number of train samples: 8915\n",
      "Iteration 824: - Train Loss: 0.2864 - Test Loss: 0.2935 - Test Accuracy: 0.9221\n",
      "       Current train loss: 0.5506    number of train samples: 8920\n",
      "Iteration 825: - Train Loss: 0.2864 - Test Loss: 0.2935 - Test Accuracy: 0.9221\n",
      "       Current train loss: 0.5507    number of train samples: 8925\n",
      "Iteration 826: - Train Loss: 0.2864 - Test Loss: 0.2935 - Test Accuracy: 0.9221\n",
      "       Current train loss: 0.5513    number of train samples: 8930\n",
      "Iteration 827: - Train Loss: 0.2864 - Test Loss: 0.2935 - Test Accuracy: 0.9221\n",
      "       Current train loss: 0.5516    number of train samples: 8935\n",
      "Iteration 828: - Train Loss: 0.2864 - Test Loss: 0.2935 - Test Accuracy: 0.9221\n",
      "       Current train loss: 0.5518    number of train samples: 8940\n",
      "Iteration 829: - Train Loss: 0.2864 - Test Loss: 0.2935 - Test Accuracy: 0.9221\n",
      "       Current train loss: 0.5519    number of train samples: 8945\n",
      "Iteration 830: - Train Loss: 0.2864 - Test Loss: 0.2935 - Test Accuracy: 0.9221\n",
      "       Current train loss: 0.5526    number of train samples: 8950\n",
      "Iteration 831: - Train Loss: 0.2864 - Test Loss: 0.2935 - Test Accuracy: 0.9221\n",
      "       Current train loss: 0.5527    number of train samples: 8955\n",
      "Iteration 832: - Train Loss: 0.2864 - Test Loss: 0.2935 - Test Accuracy: 0.9221\n",
      "       Current train loss: 0.5529    number of train samples: 8960\n",
      "Iteration 833: - Train Loss: 0.2864 - Test Loss: 0.2935 - Test Accuracy: 0.9221\n",
      "       Current train loss: 0.5529    number of train samples: 8965\n",
      "Iteration 834: - Train Loss: 0.2864 - Test Loss: 0.2935 - Test Accuracy: 0.9221\n",
      "       Current train loss: 0.5530    number of train samples: 8970\n",
      "Iteration 835: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5518    number of train samples: 8975\n",
      "Iteration 836: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5519    number of train samples: 8980\n",
      "Iteration 837: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5521    number of train samples: 8985\n",
      "Iteration 838: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5526    number of train samples: 8990\n",
      "Iteration 839: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5527    number of train samples: 8995\n",
      "Iteration 840: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5530    number of train samples: 9000\n",
      "Iteration 841: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5538    number of train samples: 9005\n",
      "Iteration 842: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5553    number of train samples: 9010\n",
      "Iteration 843: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5556    number of train samples: 9015\n",
      "Iteration 844: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5557    number of train samples: 9020\n",
      "Iteration 845: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5558    number of train samples: 9025\n",
      "Iteration 846: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5561    number of train samples: 9030\n",
      "Iteration 847: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5562    number of train samples: 9035\n",
      "Iteration 848: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5563    number of train samples: 9040\n",
      "Iteration 849: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5574    number of train samples: 9045\n",
      "Iteration 850: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5575    number of train samples: 9050\n",
      "Iteration 851: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5578    number of train samples: 9055\n",
      "Iteration 852: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5586    number of train samples: 9060\n",
      "Iteration 853: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5587    number of train samples: 9065\n",
      "Iteration 854: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5589    number of train samples: 9070\n",
      "Iteration 855: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5590    number of train samples: 9075\n",
      "Iteration 856: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5592    number of train samples: 9080\n",
      "Iteration 857: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5592    number of train samples: 9085\n",
      "Iteration 858: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5592    number of train samples: 9090\n",
      "Iteration 859: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5605    number of train samples: 9095\n",
      "Iteration 860: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5605    number of train samples: 9100\n",
      "Iteration 861: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5607    number of train samples: 9105\n",
      "Iteration 862: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5609    number of train samples: 9110\n",
      "Iteration 863: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5610    number of train samples: 9115\n",
      "Iteration 864: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5610    number of train samples: 9120\n",
      "Iteration 865: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5613    number of train samples: 9125\n",
      "Iteration 866: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5616    number of train samples: 9130\n",
      "Iteration 867: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5620    number of train samples: 9135\n",
      "Iteration 868: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5624    number of train samples: 9140\n",
      "Iteration 869: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5627    number of train samples: 9145\n",
      "Iteration 870: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5629    number of train samples: 9150\n",
      "Iteration 871: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5633    number of train samples: 9155\n",
      "Iteration 872: - Train Loss: 0.2860 - Test Loss: 0.2931 - Test Accuracy: 0.9226\n",
      "       Current train loss: 0.5639    number of train samples: 9160\n",
      "Iteration 873: - Train Loss: 0.2857 - Test Loss: 0.2932 - Test Accuracy: 0.9229\n",
      "       Current train loss: 0.5629    number of train samples: 9165\n",
      "Iteration 874: - Train Loss: 0.2857 - Test Loss: 0.2932 - Test Accuracy: 0.9229\n",
      "       Current train loss: 0.5635    number of train samples: 9170\n",
      "Iteration 875: - Train Loss: 0.2857 - Test Loss: 0.2932 - Test Accuracy: 0.9229\n",
      "       Current train loss: 0.5636    number of train samples: 9175\n",
      "Iteration 876: - Train Loss: 0.2857 - Test Loss: 0.2932 - Test Accuracy: 0.9229\n",
      "       Current train loss: 0.5637    number of train samples: 9180\n",
      "Iteration 877: - Train Loss: 0.2857 - Test Loss: 0.2932 - Test Accuracy: 0.9229\n",
      "       Current train loss: 0.5638    number of train samples: 9185\n",
      "Iteration 878: - Train Loss: 0.2857 - Test Loss: 0.2932 - Test Accuracy: 0.9229\n",
      "       Current train loss: 0.5639    number of train samples: 9190\n",
      "Iteration 879: - Train Loss: 0.2857 - Test Loss: 0.2932 - Test Accuracy: 0.9229\n",
      "       Current train loss: 0.5641    number of train samples: 9195\n",
      "Iteration 880: - Train Loss: 0.2857 - Test Loss: 0.2932 - Test Accuracy: 0.9229\n",
      "       Current train loss: 0.5643    number of train samples: 9200\n",
      "Iteration 881: - Train Loss: 0.2857 - Test Loss: 0.2932 - Test Accuracy: 0.9229\n",
      "       Current train loss: 0.5644    number of train samples: 9205\n",
      "Iteration 882: - Train Loss: 0.2857 - Test Loss: 0.2932 - Test Accuracy: 0.9229\n",
      "       Current train loss: 0.5647    number of train samples: 9210\n",
      "Iteration 883: - Train Loss: 0.2857 - Test Loss: 0.2932 - Test Accuracy: 0.9229\n",
      "       Current train loss: 0.5649    number of train samples: 9215\n",
      "Iteration 884: - Train Loss: 0.2856 - Test Loss: 0.2932 - Test Accuracy: 0.9227\n",
      "       Current train loss: 0.5644    number of train samples: 9220\n",
      "Iteration 885: - Train Loss: 0.2856 - Test Loss: 0.2932 - Test Accuracy: 0.9227\n",
      "       Current train loss: 0.5649    number of train samples: 9225\n",
      "Iteration 886: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5647    number of train samples: 9230\n",
      "Iteration 887: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5649    number of train samples: 9235\n",
      "Iteration 888: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5652    number of train samples: 9240\n",
      "Iteration 889: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5653    number of train samples: 9245\n",
      "Iteration 890: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5654    number of train samples: 9250\n",
      "Iteration 891: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5656    number of train samples: 9255\n",
      "Iteration 892: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5658    number of train samples: 9260\n",
      "Iteration 893: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5658    number of train samples: 9265\n",
      "Iteration 894: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5660    number of train samples: 9270\n",
      "Iteration 895: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5662    number of train samples: 9275\n",
      "Iteration 896: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5662    number of train samples: 9280\n",
      "Iteration 897: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5664    number of train samples: 9285\n",
      "Iteration 898: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5668    number of train samples: 9290\n",
      "Iteration 899: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5669    number of train samples: 9295\n",
      "Iteration 900: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5671    number of train samples: 9300\n",
      "Iteration 901: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5672    number of train samples: 9305\n",
      "Iteration 902: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5672    number of train samples: 9310\n",
      "Iteration 903: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5677    number of train samples: 9315\n",
      "Iteration 904: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5677    number of train samples: 9320\n",
      "Iteration 905: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5680    number of train samples: 9325\n",
      "Iteration 906: - Train Loss: 0.2853 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5679    number of train samples: 9330\n",
      "Iteration 907: - Train Loss: 0.2853 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5682    number of train samples: 9335\n",
      "Iteration 908: - Train Loss: 0.2853 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5685    number of train samples: 9340\n",
      "Iteration 909: - Train Loss: 0.2853 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5685    number of train samples: 9345\n",
      "Iteration 910: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5686    number of train samples: 9350\n",
      "Iteration 911: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5690    number of train samples: 9355\n",
      "Iteration 912: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5691    number of train samples: 9360\n",
      "Iteration 913: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5691    number of train samples: 9365\n",
      "Iteration 914: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5693    number of train samples: 9370\n",
      "Iteration 915: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5693    number of train samples: 9375\n",
      "Iteration 916: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5694    number of train samples: 9380\n",
      "Iteration 917: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5694    number of train samples: 9385\n",
      "Iteration 918: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5695    number of train samples: 9390\n",
      "Iteration 919: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5696    number of train samples: 9395\n",
      "Iteration 920: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5698    number of train samples: 9400\n",
      "Iteration 921: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5703    number of train samples: 9405\n",
      "Iteration 922: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5703    number of train samples: 9410\n",
      "Iteration 923: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5706    number of train samples: 9415\n",
      "Iteration 924: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5712    number of train samples: 9420\n",
      "Iteration 925: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5713    number of train samples: 9425\n",
      "Iteration 926: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5713    number of train samples: 9430\n",
      "Iteration 927: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5713    number of train samples: 9435\n",
      "Iteration 928: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5715    number of train samples: 9440\n",
      "Iteration 929: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5717    number of train samples: 9445\n",
      "Iteration 930: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5723    number of train samples: 9450\n",
      "Iteration 931: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5723    number of train samples: 9455\n",
      "Iteration 932: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5724    number of train samples: 9460\n",
      "Iteration 933: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5729    number of train samples: 9465\n",
      "Iteration 934: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5729    number of train samples: 9470\n",
      "Iteration 935: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5729    number of train samples: 9475\n",
      "Iteration 936: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5736    number of train samples: 9480\n",
      "Iteration 937: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5737    number of train samples: 9485\n",
      "Iteration 938: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5741    number of train samples: 9490\n",
      "Iteration 939: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5741    number of train samples: 9495\n",
      "Iteration 940: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5742    number of train samples: 9500\n",
      "Iteration 941: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5742    number of train samples: 9505\n",
      "Iteration 942: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5746    number of train samples: 9510\n",
      "Iteration 943: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5750    number of train samples: 9515\n",
      "Iteration 944: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5752    number of train samples: 9520\n",
      "Iteration 945: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5759    number of train samples: 9525\n",
      "Iteration 946: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5759    number of train samples: 9530\n",
      "Iteration 947: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5761    number of train samples: 9535\n",
      "Iteration 948: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5762    number of train samples: 9540\n",
      "Iteration 949: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5765    number of train samples: 9545\n",
      "Iteration 950: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5771    number of train samples: 9550\n",
      "Iteration 951: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5771    number of train samples: 9555\n",
      "Iteration 952: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5771    number of train samples: 9560\n",
      "Iteration 953: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5772    number of train samples: 9565\n",
      "Iteration 954: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5771    number of train samples: 9570\n",
      "Iteration 955: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5771    number of train samples: 9575\n",
      "Iteration 956: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5770    number of train samples: 9580\n",
      "Iteration 957: - Train Loss: 0.2852 - Test Loss: 0.2928 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5779    number of train samples: 9585\n",
      "Iteration 958: - Train Loss: 0.2826 - Test Loss: 0.2913 - Test Accuracy: 0.9219\n",
      "       Current train loss: 0.5723    number of train samples: 9590\n",
      "Iteration 959: - Train Loss: 0.2826 - Test Loss: 0.2913 - Test Accuracy: 0.9219\n",
      "       Current train loss: 0.5729    number of train samples: 9595\n",
      "Iteration 960: - Train Loss: 0.2826 - Test Loss: 0.2913 - Test Accuracy: 0.9219\n",
      "       Current train loss: 0.5738    number of train samples: 9600\n",
      "Iteration 961: - Train Loss: 0.2827 - Test Loss: 0.2912 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5732    number of train samples: 9605\n",
      "Iteration 962: - Train Loss: 0.2827 - Test Loss: 0.2912 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5733    number of train samples: 9610\n",
      "Iteration 963: - Train Loss: 0.2827 - Test Loss: 0.2912 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5742    number of train samples: 9615\n",
      "Iteration 964: - Train Loss: 0.2827 - Test Loss: 0.2912 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5746    number of train samples: 9620\n",
      "Iteration 965: - Train Loss: 0.2827 - Test Loss: 0.2912 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5747    number of train samples: 9625\n",
      "Iteration 966: - Train Loss: 0.2827 - Test Loss: 0.2912 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5748    number of train samples: 9630\n",
      "Iteration 967: - Train Loss: 0.2827 - Test Loss: 0.2912 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5748    number of train samples: 9635\n",
      "Iteration 968: - Train Loss: 0.2827 - Test Loss: 0.2912 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5751    number of train samples: 9640\n",
      "Iteration 969: - Train Loss: 0.2827 - Test Loss: 0.2912 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5751    number of train samples: 9645\n",
      "Iteration 970: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5754    number of train samples: 9650\n",
      "Iteration 971: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5755    number of train samples: 9655\n",
      "Iteration 972: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5757    number of train samples: 9660\n",
      "Iteration 973: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5758    number of train samples: 9665\n",
      "Iteration 974: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5759    number of train samples: 9670\n",
      "Iteration 975: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5761    number of train samples: 9675\n",
      "Iteration 976: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5760    number of train samples: 9680\n",
      "Iteration 977: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5760    number of train samples: 9685\n",
      "Iteration 978: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5763    number of train samples: 9690\n",
      "Iteration 979: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5766    number of train samples: 9695\n",
      "Iteration 980: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5766    number of train samples: 9700\n",
      "Iteration 981: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5774    number of train samples: 9705\n",
      "Iteration 982: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5776    number of train samples: 9710\n",
      "Iteration 983: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5777    number of train samples: 9715\n",
      "Iteration 984: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5781    number of train samples: 9720\n",
      "Iteration 985: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5783    number of train samples: 9725\n",
      "Iteration 986: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5786    number of train samples: 9730\n",
      "Iteration 987: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5787    number of train samples: 9735\n",
      "Iteration 988: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5787    number of train samples: 9740\n",
      "Iteration 989: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5788    number of train samples: 9745\n",
      "Iteration 990: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5789    number of train samples: 9750\n",
      "Iteration 991: - Train Loss: 0.2825 - Test Loss: 0.2911 - Test Accuracy: 0.9231\n",
      "       Current train loss: 0.5789    number of train samples: 9755\n",
      "Iteration 992: - Train Loss: 0.2822 - Test Loss: 0.2905 - Test Accuracy: 0.9233\n",
      "       Current train loss: 0.5778    number of train samples: 9760\n",
      "Iteration 993: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5773    number of train samples: 9765\n",
      "Iteration 994: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5775    number of train samples: 9770\n",
      "Iteration 995: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5776    number of train samples: 9775\n",
      "Iteration 996: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5778    number of train samples: 9780\n",
      "Iteration 997: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5779    number of train samples: 9785\n",
      "Iteration 998: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5781    number of train samples: 9790\n",
      "Iteration 999: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5785    number of train samples: 9795\n",
      "Iteration 1000: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5786    number of train samples: 9800\n",
      "Iteration 1001: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5790    number of train samples: 9805\n",
      "Iteration 1002: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5795    number of train samples: 9810\n",
      "Iteration 1003: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5797    number of train samples: 9815\n",
      "Iteration 1004: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5796    number of train samples: 9820\n",
      "Iteration 1005: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5796    number of train samples: 9825\n",
      "Iteration 1006: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5798    number of train samples: 9830\n",
      "Iteration 1007: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5798    number of train samples: 9835\n",
      "Iteration 1008: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5805    number of train samples: 9840\n",
      "Iteration 1009: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5805    number of train samples: 9845\n",
      "Iteration 1010: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5810    number of train samples: 9850\n",
      "Iteration 1011: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5811    number of train samples: 9855\n",
      "Iteration 1012: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5815    number of train samples: 9860\n",
      "Iteration 1013: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5819    number of train samples: 9865\n",
      "Iteration 1014: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5818    number of train samples: 9870\n",
      "Iteration 1015: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5819    number of train samples: 9875\n",
      "Iteration 1016: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5819    number of train samples: 9880\n",
      "Iteration 1017: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5819    number of train samples: 9885\n",
      "Iteration 1018: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5821    number of train samples: 9890\n",
      "Iteration 1019: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5821    number of train samples: 9895\n",
      "Iteration 1020: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5821    number of train samples: 9900\n",
      "Iteration 1021: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5821    number of train samples: 9905\n",
      "Iteration 1022: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5827    number of train samples: 9910\n",
      "Iteration 1023: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5827    number of train samples: 9915\n",
      "Iteration 1024: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5827    number of train samples: 9920\n",
      "Iteration 1025: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5828    number of train samples: 9925\n",
      "Iteration 1026: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5829    number of train samples: 9930\n",
      "Iteration 1027: - Train Loss: 0.2820 - Test Loss: 0.2903 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5829    number of train samples: 9935\n",
      "Iteration 1028: - Train Loss: 0.2818 - Test Loss: 0.2901 - Test Accuracy: 0.9244\n",
      "       Current train loss: 0.5829    number of train samples: 9940\n",
      "Iteration 1029: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5828    number of train samples: 9945\n",
      "Iteration 1030: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5834    number of train samples: 9950\n",
      "Iteration 1031: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5834    number of train samples: 9955\n",
      "Iteration 1032: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5833    number of train samples: 9960\n",
      "Iteration 1033: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5833    number of train samples: 9965\n",
      "Iteration 1034: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5837    number of train samples: 9970\n",
      "Iteration 1035: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5838    number of train samples: 9975\n",
      "Iteration 1036: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5838    number of train samples: 9980\n",
      "Iteration 1037: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5840    number of train samples: 9985\n",
      "Iteration 1038: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5843    number of train samples: 9990\n",
      "Iteration 1039: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5842    number of train samples: 9995\n",
      "Iteration 1040: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5842    number of train samples: 10000\n",
      "Iteration 1041: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5844    number of train samples: 10005\n",
      "Iteration 1042: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5844    number of train samples: 10010\n",
      "Iteration 1043: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5844    number of train samples: 10015\n",
      "Iteration 1044: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5845    number of train samples: 10020\n",
      "Iteration 1045: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5845    number of train samples: 10025\n",
      "Iteration 1046: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5851    number of train samples: 10030\n",
      "Iteration 1047: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5853    number of train samples: 10035\n",
      "Iteration 1048: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5855    number of train samples: 10040\n",
      "Iteration 1049: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5854    number of train samples: 10045\n",
      "Iteration 1050: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5855    number of train samples: 10050\n",
      "Iteration 1051: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5854    number of train samples: 10055\n",
      "Iteration 1052: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5853    number of train samples: 10060\n",
      "Iteration 1053: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5853    number of train samples: 10065\n",
      "Iteration 1054: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5852    number of train samples: 10070\n",
      "Iteration 1055: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5853    number of train samples: 10075\n",
      "Iteration 1056: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5857    number of train samples: 10080\n",
      "Iteration 1057: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5861    number of train samples: 10085\n",
      "Iteration 1058: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5862    number of train samples: 10090\n",
      "Iteration 1059: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5864    number of train samples: 10095\n",
      "Iteration 1060: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5865    number of train samples: 10100\n",
      "Iteration 1061: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5872    number of train samples: 10105\n",
      "Iteration 1062: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5872    number of train samples: 10110\n",
      "Iteration 1063: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5878    number of train samples: 10115\n",
      "Iteration 1064: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5879    number of train samples: 10120\n",
      "Iteration 1065: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5879    number of train samples: 10125\n",
      "Iteration 1066: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5879    number of train samples: 10130\n",
      "Iteration 1067: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5878    number of train samples: 10135\n",
      "Iteration 1068: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5877    number of train samples: 10140\n",
      "Iteration 1069: - Train Loss: 0.2819 - Test Loss: 0.2902 - Test Accuracy: 0.9245\n",
      "       Current train loss: 0.5877    number of train samples: 10145\n",
      "Iteration 1070: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5836    number of train samples: 10150\n",
      "Iteration 1071: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5837    number of train samples: 10155\n",
      "Iteration 1072: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5838    number of train samples: 10160\n",
      "Iteration 1073: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5840    number of train samples: 10165\n",
      "Iteration 1074: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5847    number of train samples: 10170\n",
      "Iteration 1075: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5853    number of train samples: 10175\n",
      "Iteration 1076: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5853    number of train samples: 10180\n",
      "Iteration 1077: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5853    number of train samples: 10185\n",
      "Iteration 1078: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5854    number of train samples: 10190\n",
      "Iteration 1079: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5857    number of train samples: 10195\n",
      "Iteration 1080: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5859    number of train samples: 10200\n",
      "Iteration 1081: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5864    number of train samples: 10205\n",
      "Iteration 1082: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5863    number of train samples: 10210\n",
      "Iteration 1083: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5864    number of train samples: 10215\n",
      "Iteration 1084: - Train Loss: 0.2793 - Test Loss: 0.2882 - Test Accuracy: 0.9237\n",
      "       Current train loss: 0.5872    number of train samples: 10220\n",
      "Iteration 1085: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5866    number of train samples: 10225\n",
      "Iteration 1086: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5874    number of train samples: 10230\n",
      "Iteration 1087: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5874    number of train samples: 10235\n",
      "Iteration 1088: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5882    number of train samples: 10240\n",
      "Iteration 1089: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5888    number of train samples: 10245\n",
      "Iteration 1090: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5888    number of train samples: 10250\n",
      "Iteration 1091: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5891    number of train samples: 10255\n",
      "Iteration 1092: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5890    number of train samples: 10260\n",
      "Iteration 1093: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5891    number of train samples: 10265\n",
      "Iteration 1094: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5890    number of train samples: 10270\n",
      "Iteration 1095: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5890    number of train samples: 10275\n",
      "Iteration 1096: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5890    number of train samples: 10280\n",
      "Iteration 1097: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5891    number of train samples: 10285\n",
      "Iteration 1098: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5892    number of train samples: 10290\n",
      "Iteration 1099: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5894    number of train samples: 10295\n",
      "Iteration 1100: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5895    number of train samples: 10300\n",
      "Iteration 1101: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5897    number of train samples: 10305\n",
      "Iteration 1102: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5898    number of train samples: 10310\n",
      "Iteration 1103: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5899    number of train samples: 10315\n",
      "Iteration 1104: - Train Loss: 0.2790 - Test Loss: 0.2878 - Test Accuracy: 0.9238\n",
      "       Current train loss: 0.5899    number of train samples: 10320\n",
      "Iteration 1105: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5898    number of train samples: 10325\n",
      "Iteration 1106: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5899    number of train samples: 10330\n",
      "Iteration 1107: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5900    number of train samples: 10335\n",
      "Iteration 1108: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5899    number of train samples: 10340\n",
      "Iteration 1109: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5903    number of train samples: 10345\n",
      "Iteration 1110: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5905    number of train samples: 10350\n",
      "Iteration 1111: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5906    number of train samples: 10355\n",
      "Iteration 1112: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5909    number of train samples: 10360\n",
      "Iteration 1113: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5909    number of train samples: 10365\n",
      "Iteration 1114: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5910    number of train samples: 10370\n",
      "Iteration 1115: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5911    number of train samples: 10375\n",
      "Iteration 1116: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5911    number of train samples: 10380\n",
      "Iteration 1117: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5912    number of train samples: 10385\n",
      "Iteration 1118: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5911    number of train samples: 10390\n",
      "Iteration 1119: - Train Loss: 0.2793 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5914    number of train samples: 10395\n",
      "Iteration 1120: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5912    number of train samples: 10400\n",
      "Iteration 1121: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5913    number of train samples: 10405\n",
      "Iteration 1122: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5912    number of train samples: 10410\n",
      "Iteration 1123: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5912    number of train samples: 10415\n",
      "Iteration 1124: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5911    number of train samples: 10420\n",
      "Iteration 1125: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5911    number of train samples: 10425\n",
      "Iteration 1126: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5912    number of train samples: 10430\n",
      "Iteration 1127: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5913    number of train samples: 10435\n",
      "Iteration 1128: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5915    number of train samples: 10440\n",
      "Iteration 1129: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5916    number of train samples: 10445\n",
      "Iteration 1130: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5915    number of train samples: 10450\n",
      "Iteration 1131: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5914    number of train samples: 10455\n",
      "Iteration 1132: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5917    number of train samples: 10460\n",
      "Iteration 1133: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5921    number of train samples: 10465\n",
      "Iteration 1134: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5924    number of train samples: 10470\n",
      "Iteration 1135: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5923    number of train samples: 10475\n",
      "Iteration 1136: - Train Loss: 0.2791 - Test Loss: 0.2879 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5923    number of train samples: 10480\n",
      "Iteration 1137: - Train Loss: 0.2792 - Test Loss: 0.2880 - Test Accuracy: 0.9241\n",
      "       Current train loss: 0.5928    number of train samples: 10485\n",
      "Iteration 1138: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5927    number of train samples: 10490\n",
      "Iteration 1139: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5926    number of train samples: 10495\n",
      "Iteration 1140: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5927    number of train samples: 10500\n",
      "Iteration 1141: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5927    number of train samples: 10505\n",
      "Iteration 1142: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5931    number of train samples: 10510\n",
      "Iteration 1143: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5930    number of train samples: 10515\n",
      "Iteration 1144: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5930    number of train samples: 10520\n",
      "Iteration 1145: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5929    number of train samples: 10525\n",
      "Iteration 1146: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5932    number of train samples: 10530\n",
      "Iteration 1147: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5932    number of train samples: 10535\n",
      "Iteration 1148: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5933    number of train samples: 10540\n",
      "Iteration 1149: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5935    number of train samples: 10545\n",
      "Iteration 1150: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5936    number of train samples: 10550\n",
      "Iteration 1151: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5936    number of train samples: 10555\n",
      "Iteration 1152: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5936    number of train samples: 10560\n",
      "Iteration 1153: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5935    number of train samples: 10565\n",
      "Iteration 1154: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5934    number of train samples: 10570\n",
      "Iteration 1155: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5934    number of train samples: 10575\n",
      "Iteration 1156: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5934    number of train samples: 10580\n",
      "Iteration 1157: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5940    number of train samples: 10585\n",
      "Iteration 1158: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5939    number of train samples: 10590\n",
      "Iteration 1159: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5941    number of train samples: 10595\n",
      "Iteration 1160: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5946    number of train samples: 10600\n",
      "Iteration 1161: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5946    number of train samples: 10605\n",
      "Iteration 1162: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5945    number of train samples: 10610\n",
      "Iteration 1163: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5948    number of train samples: 10615\n",
      "Iteration 1164: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5948    number of train samples: 10620\n",
      "Iteration 1165: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5952    number of train samples: 10625\n",
      "Iteration 1166: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5954    number of train samples: 10630\n",
      "Iteration 1167: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5957    number of train samples: 10635\n",
      "Iteration 1168: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5956    number of train samples: 10640\n",
      "Iteration 1169: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5961    number of train samples: 10645\n",
      "Iteration 1170: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5964    number of train samples: 10650\n",
      "Iteration 1171: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5963    number of train samples: 10655\n",
      "Iteration 1172: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5963    number of train samples: 10660\n",
      "Iteration 1173: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5965    number of train samples: 10665\n",
      "Iteration 1174: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5965    number of train samples: 10670\n",
      "Iteration 1175: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5965    number of train samples: 10675\n",
      "Iteration 1176: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5966    number of train samples: 10680\n",
      "Iteration 1177: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5965    number of train samples: 10685\n",
      "Iteration 1178: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5965    number of train samples: 10690\n",
      "Iteration 1179: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5965    number of train samples: 10695\n",
      "Iteration 1180: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5964    number of train samples: 10700\n",
      "Iteration 1181: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5963    number of train samples: 10705\n",
      "Iteration 1182: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5962    number of train samples: 10710\n",
      "Iteration 1183: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5963    number of train samples: 10715\n",
      "Iteration 1184: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5966    number of train samples: 10720\n",
      "Iteration 1185: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5965    number of train samples: 10725\n",
      "Iteration 1186: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5964    number of train samples: 10730\n",
      "Iteration 1187: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5965    number of train samples: 10735\n",
      "Iteration 1188: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5970    number of train samples: 10740\n",
      "Iteration 1189: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5971    number of train samples: 10745\n",
      "Iteration 1190: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5971    number of train samples: 10750\n",
      "Iteration 1191: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5972    number of train samples: 10755\n",
      "Iteration 1192: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5971    number of train samples: 10760\n",
      "Iteration 1193: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5971    number of train samples: 10765\n",
      "Iteration 1194: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5971    number of train samples: 10770\n",
      "Iteration 1195: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5970    number of train samples: 10775\n",
      "Iteration 1196: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5973    number of train samples: 10780\n",
      "Iteration 1197: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5975    number of train samples: 10785\n",
      "Iteration 1198: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5975    number of train samples: 10790\n",
      "Iteration 1199: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5975    number of train samples: 10795\n",
      "Iteration 1200: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5974    number of train samples: 10800\n",
      "Iteration 1201: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5975    number of train samples: 10805\n",
      "Iteration 1202: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5974    number of train samples: 10810\n",
      "Iteration 1203: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5977    number of train samples: 10815\n",
      "Iteration 1204: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5976    number of train samples: 10820\n",
      "Iteration 1205: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5976    number of train samples: 10825\n",
      "Iteration 1206: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5977    number of train samples: 10830\n",
      "Iteration 1207: - Train Loss: 0.2791 - Test Loss: 0.2878 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5980    number of train samples: 10835\n",
      "Iteration 1208: - Train Loss: 0.2777 - Test Loss: 0.2869 - Test Accuracy: 0.9247\n",
      "       Current train loss: 0.5953    number of train samples: 10840\n",
      "Iteration 1209: - Train Loss: 0.2777 - Test Loss: 0.2869 - Test Accuracy: 0.9247\n",
      "       Current train loss: 0.5953    number of train samples: 10845\n",
      "Iteration 1210: - Train Loss: 0.2777 - Test Loss: 0.2869 - Test Accuracy: 0.9247\n",
      "       Current train loss: 0.5954    number of train samples: 10850\n",
      "Iteration 1211: - Train Loss: 0.2777 - Test Loss: 0.2869 - Test Accuracy: 0.9247\n",
      "       Current train loss: 0.5954    number of train samples: 10855\n",
      "Iteration 1212: - Train Loss: 0.2777 - Test Loss: 0.2869 - Test Accuracy: 0.9247\n",
      "       Current train loss: 0.5954    number of train samples: 10860\n",
      "Iteration 1213: - Train Loss: 0.2777 - Test Loss: 0.2869 - Test Accuracy: 0.9247\n",
      "       Current train loss: 0.5956    number of train samples: 10865\n",
      "Iteration 1214: - Train Loss: 0.2777 - Test Loss: 0.2869 - Test Accuracy: 0.9247\n",
      "       Current train loss: 0.5958    number of train samples: 10870\n",
      "Iteration 1215: - Train Loss: 0.2777 - Test Loss: 0.2869 - Test Accuracy: 0.9247\n",
      "       Current train loss: 0.5958    number of train samples: 10875\n",
      "Iteration 1216: - Train Loss: 0.2777 - Test Loss: 0.2869 - Test Accuracy: 0.9247\n",
      "       Current train loss: 0.5959    number of train samples: 10880\n",
      "Iteration 1217: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5948    number of train samples: 10885\n",
      "Iteration 1218: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5953    number of train samples: 10890\n",
      "Iteration 1219: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5953    number of train samples: 10895\n",
      "Iteration 1220: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5953    number of train samples: 10900\n",
      "Iteration 1221: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5956    number of train samples: 10905\n",
      "Iteration 1222: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5959    number of train samples: 10910\n",
      "Iteration 1223: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5958    number of train samples: 10915\n",
      "Iteration 1224: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5961    number of train samples: 10920\n",
      "Iteration 1225: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5961    number of train samples: 10925\n",
      "Iteration 1226: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5961    number of train samples: 10930\n",
      "Iteration 1227: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5966    number of train samples: 10935\n",
      "Iteration 1228: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5966    number of train samples: 10940\n",
      "Iteration 1229: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5966    number of train samples: 10945\n",
      "Iteration 1230: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5965    number of train samples: 10950\n",
      "Iteration 1231: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5969    number of train samples: 10955\n",
      "Iteration 1232: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5969    number of train samples: 10960\n",
      "Iteration 1233: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5971    number of train samples: 10965\n",
      "Iteration 1234: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5972    number of train samples: 10970\n",
      "Iteration 1235: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5972    number of train samples: 10975\n",
      "Iteration 1236: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5975    number of train samples: 10980\n",
      "Iteration 1237: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5975    number of train samples: 10985\n",
      "Iteration 1238: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5977    number of train samples: 10990\n",
      "Iteration 1239: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5979    number of train samples: 10995\n",
      "Iteration 1240: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5979    number of train samples: 11000\n",
      "Iteration 1241: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5979    number of train samples: 11005\n",
      "Iteration 1242: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5979    number of train samples: 11010\n",
      "Iteration 1243: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5979    number of train samples: 11015\n",
      "Iteration 1244: - Train Loss: 0.2775 - Test Loss: 0.2866 - Test Accuracy: 0.9249\n",
      "       Current train loss: 0.5981    number of train samples: 11020\n",
      "Iteration 1245: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5977    number of train samples: 11025\n",
      "Iteration 1246: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5977    number of train samples: 11030\n",
      "Iteration 1247: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5976    number of train samples: 11035\n",
      "Iteration 1248: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5975    number of train samples: 11040\n",
      "Iteration 1249: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5974    number of train samples: 11045\n",
      "Iteration 1250: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5979    number of train samples: 11050\n",
      "Iteration 1251: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5979    number of train samples: 11055\n",
      "Iteration 1252: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5978    number of train samples: 11060\n",
      "Iteration 1253: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5977    number of train samples: 11065\n",
      "Iteration 1254: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5976    number of train samples: 11070\n",
      "Iteration 1255: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5976    number of train samples: 11075\n",
      "Iteration 1256: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5976    number of train samples: 11080\n",
      "Iteration 1257: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5975    number of train samples: 11085\n",
      "Iteration 1258: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5976    number of train samples: 11090\n",
      "Iteration 1259: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5977    number of train samples: 11095\n",
      "Iteration 1260: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5977    number of train samples: 11100\n",
      "Iteration 1261: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5977    number of train samples: 11105\n",
      "Iteration 1262: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5977    number of train samples: 11110\n",
      "Iteration 1263: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5978    number of train samples: 11115\n",
      "Iteration 1264: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5983    number of train samples: 11120\n",
      "Iteration 1265: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5982    number of train samples: 11125\n",
      "Iteration 1266: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5985    number of train samples: 11130\n",
      "Iteration 1267: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5986    number of train samples: 11135\n",
      "Iteration 1268: - Train Loss: 0.2773 - Test Loss: 0.2866 - Test Accuracy: 0.9246\n",
      "       Current train loss: 0.5985    number of train samples: 11140\n",
      "Iteration 1269: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5992    number of train samples: 11145\n",
      "Iteration 1270: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5993    number of train samples: 11150\n",
      "Iteration 1271: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5993    number of train samples: 11155\n",
      "Iteration 1272: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5998    number of train samples: 11160\n",
      "Iteration 1273: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5998    number of train samples: 11165\n",
      "Iteration 1274: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5997    number of train samples: 11170\n",
      "Iteration 1275: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6001    number of train samples: 11175\n",
      "Iteration 1276: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6001    number of train samples: 11180\n",
      "Iteration 1277: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6000    number of train samples: 11185\n",
      "Iteration 1278: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6001    number of train samples: 11190\n",
      "Iteration 1279: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6001    number of train samples: 11195\n",
      "Iteration 1280: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6000    number of train samples: 11200\n",
      "Iteration 1281: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5999    number of train samples: 11205\n",
      "Iteration 1282: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5998    number of train samples: 11210\n",
      "Iteration 1283: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5997    number of train samples: 11215\n",
      "Iteration 1284: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5997    number of train samples: 11220\n",
      "Iteration 1285: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5997    number of train samples: 11225\n",
      "Iteration 1286: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5997    number of train samples: 11230\n",
      "Iteration 1287: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5996    number of train samples: 11235\n",
      "Iteration 1288: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6002    number of train samples: 11240\n",
      "Iteration 1289: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6001    number of train samples: 11245\n",
      "Iteration 1290: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6000    number of train samples: 11250\n",
      "Iteration 1291: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.5999    number of train samples: 11255\n",
      "Iteration 1292: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6005    number of train samples: 11260\n",
      "Iteration 1293: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6004    number of train samples: 11265\n",
      "Iteration 1294: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6003    number of train samples: 11270\n",
      "Iteration 1295: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6006    number of train samples: 11275\n",
      "Iteration 1296: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6007    number of train samples: 11280\n",
      "Iteration 1297: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6009    number of train samples: 11285\n",
      "Iteration 1298: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6009    number of train samples: 11290\n",
      "Iteration 1299: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6008    number of train samples: 11295\n",
      "Iteration 1300: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6007    number of train samples: 11300\n",
      "Iteration 1301: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6005    number of train samples: 11305\n",
      "Iteration 1302: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6009    number of train samples: 11310\n",
      "Iteration 1303: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6012    number of train samples: 11315\n",
      "Iteration 1304: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6016    number of train samples: 11320\n",
      "Iteration 1305: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6016    number of train samples: 11325\n",
      "Iteration 1306: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6016    number of train samples: 11330\n",
      "Iteration 1307: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6016    number of train samples: 11335\n",
      "Iteration 1308: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6016    number of train samples: 11340\n",
      "Iteration 1309: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6020    number of train samples: 11345\n",
      "Iteration 1310: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6019    number of train samples: 11350\n",
      "Iteration 1311: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6021    number of train samples: 11355\n",
      "Iteration 1312: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6020    number of train samples: 11360\n",
      "Iteration 1313: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6019    number of train samples: 11365\n",
      "Iteration 1314: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6030    number of train samples: 11370\n",
      "Iteration 1315: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6029    number of train samples: 11375\n",
      "Iteration 1316: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6030    number of train samples: 11380\n",
      "Iteration 1317: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6031    number of train samples: 11385\n",
      "Iteration 1318: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6038    number of train samples: 11390\n",
      "Iteration 1319: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6042    number of train samples: 11395\n",
      "Iteration 1320: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6040    number of train samples: 11400\n",
      "Iteration 1321: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6042    number of train samples: 11405\n",
      "Iteration 1322: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6046    number of train samples: 11410\n",
      "Iteration 1323: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6044    number of train samples: 11415\n",
      "Iteration 1324: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6045    number of train samples: 11420\n",
      "Iteration 1325: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6046    number of train samples: 11425\n",
      "Iteration 1326: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6045    number of train samples: 11430\n",
      "Iteration 1327: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6043    number of train samples: 11435\n",
      "Iteration 1328: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6045    number of train samples: 11440\n",
      "Iteration 1329: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6043    number of train samples: 11445\n",
      "Iteration 1330: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6050    number of train samples: 11450\n",
      "Iteration 1331: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6050    number of train samples: 11455\n",
      "Iteration 1332: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6049    number of train samples: 11460\n",
      "Iteration 1333: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6050    number of train samples: 11465\n",
      "Iteration 1334: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6048    number of train samples: 11470\n",
      "Iteration 1335: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6047    number of train samples: 11475\n",
      "Iteration 1336: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6048    number of train samples: 11480\n",
      "Iteration 1337: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6049    number of train samples: 11485\n",
      "Iteration 1338: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6048    number of train samples: 11490\n",
      "Iteration 1339: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6046    number of train samples: 11495\n",
      "Iteration 1340: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6048    number of train samples: 11500\n",
      "Iteration 1341: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6047    number of train samples: 11505\n",
      "Iteration 1342: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6048    number of train samples: 11510\n",
      "Iteration 1343: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6048    number of train samples: 11515\n",
      "Iteration 1344: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6051    number of train samples: 11520\n",
      "Iteration 1345: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6050    number of train samples: 11525\n",
      "Iteration 1346: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6049    number of train samples: 11530\n",
      "Iteration 1347: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6049    number of train samples: 11535\n",
      "Iteration 1348: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6049    number of train samples: 11540\n",
      "Iteration 1349: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6050    number of train samples: 11545\n",
      "Iteration 1350: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6052    number of train samples: 11550\n",
      "Iteration 1351: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6051    number of train samples: 11555\n",
      "Iteration 1352: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6052    number of train samples: 11560\n",
      "Iteration 1353: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6056    number of train samples: 11565\n",
      "Iteration 1354: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6055    number of train samples: 11570\n",
      "Iteration 1355: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6053    number of train samples: 11575\n",
      "Iteration 1356: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6052    number of train samples: 11580\n",
      "Iteration 1357: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6051    number of train samples: 11585\n",
      "Iteration 1358: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6050    number of train samples: 11590\n",
      "Iteration 1359: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6051    number of train samples: 11595\n",
      "Iteration 1360: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6053    number of train samples: 11600\n",
      "Iteration 1361: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6053    number of train samples: 11605\n",
      "Iteration 1362: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6052    number of train samples: 11610\n",
      "Iteration 1363: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6052    number of train samples: 11615\n",
      "Iteration 1364: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6051    number of train samples: 11620\n",
      "Iteration 1365: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6055    number of train samples: 11625\n",
      "Iteration 1366: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6054    number of train samples: 11630\n",
      "Iteration 1367: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6053    number of train samples: 11635\n",
      "Iteration 1368: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6052    number of train samples: 11640\n",
      "Iteration 1369: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6051    number of train samples: 11645\n",
      "Iteration 1370: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6050    number of train samples: 11650\n",
      "Iteration 1371: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6050    number of train samples: 11655\n",
      "Iteration 1372: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6049    number of train samples: 11660\n",
      "Iteration 1373: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6048    number of train samples: 11665\n",
      "Iteration 1374: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6049    number of train samples: 11670\n",
      "Iteration 1375: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6049    number of train samples: 11675\n",
      "Iteration 1376: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6049    number of train samples: 11680\n",
      "Iteration 1377: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6049    number of train samples: 11685\n",
      "Iteration 1378: - Train Loss: 0.2769 - Test Loss: 0.2859 - Test Accuracy: 0.9251\n",
      "       Current train loss: 0.6050    number of train samples: 11690\n",
      "Iteration 1379: - Train Loss: 0.2735 - Test Loss: 0.2835 - Test Accuracy: 0.9236\n",
      "       Current train loss: 0.5985    number of train samples: 11695\n",
      "Iteration 1380: - Train Loss: 0.2735 - Test Loss: 0.2835 - Test Accuracy: 0.9236\n",
      "       Current train loss: 0.5984    number of train samples: 11700\n",
      "Iteration 1381: - Train Loss: 0.2730 - Test Loss: 0.2828 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5978    number of train samples: 11705\n",
      "Iteration 1382: - Train Loss: 0.2730 - Test Loss: 0.2828 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5979    number of train samples: 11710\n",
      "Iteration 1383: - Train Loss: 0.2730 - Test Loss: 0.2828 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5979    number of train samples: 11715\n",
      "Iteration 1384: - Train Loss: 0.2730 - Test Loss: 0.2828 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5981    number of train samples: 11720\n",
      "Iteration 1385: - Train Loss: 0.2730 - Test Loss: 0.2828 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5989    number of train samples: 11725\n",
      "Iteration 1386: - Train Loss: 0.2730 - Test Loss: 0.2828 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5989    number of train samples: 11730\n",
      "Iteration 1387: - Train Loss: 0.2730 - Test Loss: 0.2828 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5989    number of train samples: 11735\n",
      "Iteration 1388: - Train Loss: 0.2730 - Test Loss: 0.2828 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5991    number of train samples: 11740\n",
      "Iteration 1389: - Train Loss: 0.2730 - Test Loss: 0.2828 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5991    number of train samples: 11745\n",
      "Iteration 1390: - Train Loss: 0.2730 - Test Loss: 0.2828 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5995    number of train samples: 11750\n",
      "Iteration 1391: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.5993    number of train samples: 11755\n",
      "Iteration 1392: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.5997    number of train samples: 11760\n",
      "Iteration 1393: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.5997    number of train samples: 11765\n",
      "Iteration 1394: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.5996    number of train samples: 11770\n",
      "Iteration 1395: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.5996    number of train samples: 11775\n",
      "Iteration 1396: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.6000    number of train samples: 11780\n",
      "Iteration 1397: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.6000    number of train samples: 11785\n",
      "Iteration 1398: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.5999    number of train samples: 11790\n",
      "Iteration 1399: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.6003    number of train samples: 11795\n",
      "Iteration 1400: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.6002    number of train samples: 11800\n",
      "Iteration 1401: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.6001    number of train samples: 11805\n",
      "Iteration 1402: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.6001    number of train samples: 11810\n",
      "Iteration 1403: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.6000    number of train samples: 11815\n",
      "Iteration 1404: - Train Loss: 0.2732 - Test Loss: 0.2831 - Test Accuracy: 0.9239\n",
      "       Current train loss: 0.6000    number of train samples: 11820\n",
      "Iteration 1405: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6001    number of train samples: 11825\n",
      "Iteration 1406: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6000    number of train samples: 11830\n",
      "Iteration 1407: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5999    number of train samples: 11835\n",
      "Iteration 1408: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5999    number of train samples: 11840\n",
      "Iteration 1409: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.5999    number of train samples: 11845\n",
      "Iteration 1410: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6003    number of train samples: 11850\n",
      "Iteration 1411: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6004    number of train samples: 11855\n",
      "Iteration 1412: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6006    number of train samples: 11860\n",
      "Iteration 1413: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6007    number of train samples: 11865\n",
      "Iteration 1414: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6007    number of train samples: 11870\n",
      "Iteration 1415: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6008    number of train samples: 11875\n",
      "Iteration 1416: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6008    number of train samples: 11880\n",
      "Iteration 1417: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6009    number of train samples: 11885\n",
      "Iteration 1418: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6010    number of train samples: 11890\n",
      "Iteration 1419: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6011    number of train samples: 11895\n",
      "Iteration 1420: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6009    number of train samples: 11900\n",
      "Iteration 1421: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6008    number of train samples: 11905\n",
      "Iteration 1422: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6007    number of train samples: 11910\n",
      "Iteration 1423: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6006    number of train samples: 11915\n",
      "Iteration 1424: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6007    number of train samples: 11920\n",
      "Iteration 1425: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6007    number of train samples: 11925\n",
      "Iteration 1426: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6006    number of train samples: 11930\n",
      "Iteration 1427: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6009    number of train samples: 11935\n",
      "Iteration 1428: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6007    number of train samples: 11940\n",
      "Iteration 1429: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6006    number of train samples: 11945\n",
      "Iteration 1430: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6005    number of train samples: 11950\n",
      "Iteration 1431: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6008    number of train samples: 11955\n",
      "Iteration 1432: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6007    number of train samples: 11960\n",
      "Iteration 1433: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6008    number of train samples: 11965\n",
      "Iteration 1434: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6009    number of train samples: 11970\n",
      "Iteration 1435: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6011    number of train samples: 11975\n",
      "Iteration 1436: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6010    number of train samples: 11980\n",
      "Iteration 1437: - Train Loss: 0.2731 - Test Loss: 0.2830 - Test Accuracy: 0.924\n",
      "       Current train loss: 0.6009    number of train samples: 11985\n",
      "Iteration 1438: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.5990    number of train samples: 11990\n",
      "Iteration 1439: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.5990    number of train samples: 11995\n",
      "Iteration 1440: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.5993    number of train samples: 12000\n",
      "Iteration 1441: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.5997    number of train samples: 12005\n",
      "Iteration 1442: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.5999    number of train samples: 12010\n",
      "Iteration 1443: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.5998    number of train samples: 12015\n",
      "Iteration 1444: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.5997    number of train samples: 12020\n",
      "Iteration 1445: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.5996    number of train samples: 12025\n",
      "Iteration 1446: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.5998    number of train samples: 12030\n",
      "Iteration 1447: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6002    number of train samples: 12035\n",
      "Iteration 1448: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6001    number of train samples: 12040\n",
      "Iteration 1449: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6005    number of train samples: 12045\n",
      "Iteration 1450: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6006    number of train samples: 12050\n",
      "Iteration 1451: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6006    number of train samples: 12055\n",
      "Iteration 1452: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6005    number of train samples: 12060\n",
      "Iteration 1453: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6010    number of train samples: 12065\n",
      "Iteration 1454: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6010    number of train samples: 12070\n",
      "Iteration 1455: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6013    number of train samples: 12075\n",
      "Iteration 1456: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6015    number of train samples: 12080\n",
      "Iteration 1457: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6014    number of train samples: 12085\n",
      "Iteration 1458: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6016    number of train samples: 12090\n",
      "Iteration 1459: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6015    number of train samples: 12095\n",
      "Iteration 1460: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6015    number of train samples: 12100\n",
      "Iteration 1461: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6016    number of train samples: 12105\n",
      "Iteration 1462: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6017    number of train samples: 12110\n",
      "Iteration 1463: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6019    number of train samples: 12115\n",
      "Iteration 1464: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6018    number of train samples: 12120\n",
      "Iteration 1465: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6017    number of train samples: 12125\n",
      "Iteration 1466: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6019    number of train samples: 12130\n",
      "Iteration 1467: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6018    number of train samples: 12135\n",
      "Iteration 1468: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6017    number of train samples: 12140\n",
      "Iteration 1469: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6016    number of train samples: 12145\n",
      "Iteration 1470: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6020    number of train samples: 12150\n",
      "Iteration 1471: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6019    number of train samples: 12155\n",
      "Iteration 1472: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6023    number of train samples: 12160\n",
      "Iteration 1473: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6024    number of train samples: 12165\n",
      "Iteration 1474: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6026    number of train samples: 12170\n",
      "Iteration 1475: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6025    number of train samples: 12175\n",
      "Iteration 1476: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6024    number of train samples: 12180\n",
      "Iteration 1477: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6026    number of train samples: 12185\n",
      "Iteration 1478: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6025    number of train samples: 12190\n",
      "Iteration 1479: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6030    number of train samples: 12195\n",
      "Iteration 1480: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6031    number of train samples: 12200\n",
      "Iteration 1481: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6031    number of train samples: 12205\n",
      "Iteration 1482: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6030    number of train samples: 12210\n",
      "Iteration 1483: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6029    number of train samples: 12215\n",
      "Iteration 1484: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6027    number of train samples: 12220\n",
      "Iteration 1485: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6026    number of train samples: 12225\n",
      "Iteration 1486: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6027    number of train samples: 12230\n",
      "Iteration 1487: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6026    number of train samples: 12235\n",
      "Iteration 1488: - Train Loss: 0.2727 - Test Loss: 0.2825 - Test Accuracy: 0.9258\n",
      "       Current train loss: 0.6026    number of train samples: 12240\n",
      "Iteration 1489: - Train Loss: 0.2724 - Test Loss: 0.2825 - Test Accuracy: 0.9255\n",
      "       Current train loss: 0.6021    number of train samples: 12245\n",
      "Iteration 1490: - Train Loss: 0.2724 - Test Loss: 0.2825 - Test Accuracy: 0.9255\n",
      "       Current train loss: 0.6022    number of train samples: 12250\n",
      "Iteration 1491: - Train Loss: 0.2724 - Test Loss: 0.2825 - Test Accuracy: 0.9255\n",
      "       Current train loss: 0.6022    number of train samples: 12255\n",
      "Iteration 1492: - Train Loss: 0.2724 - Test Loss: 0.2825 - Test Accuracy: 0.9255\n",
      "       Current train loss: 0.6022    number of train samples: 12260\n",
      "Iteration 1493: - Train Loss: 0.2724 - Test Loss: 0.2825 - Test Accuracy: 0.9255\n",
      "       Current train loss: 0.6023    number of train samples: 12265\n",
      "Iteration 1494: - Train Loss: 0.2724 - Test Loss: 0.2825 - Test Accuracy: 0.9255\n",
      "       Current train loss: 0.6022    number of train samples: 12270\n",
      "Iteration 1495: - Train Loss: 0.2724 - Test Loss: 0.2825 - Test Accuracy: 0.9255\n",
      "       Current train loss: 0.6021    number of train samples: 12275\n",
      "Iteration 1496: - Train Loss: 0.2724 - Test Loss: 0.2825 - Test Accuracy: 0.9255\n",
      "       Current train loss: 0.6024    number of train samples: 12280\n",
      "Iteration 1497: - Train Loss: 0.2724 - Test Loss: 0.2825 - Test Accuracy: 0.9255\n",
      "       Current train loss: 0.6029    number of train samples: 12285\n",
      "Iteration 1498: - Train Loss: 0.2724 - Test Loss: 0.2825 - Test Accuracy: 0.9255\n",
      "       Current train loss: 0.6028    number of train samples: 12290\n",
      "Iteration 1499: - Train Loss: 0.2724 - Test Loss: 0.2825 - Test Accuracy: 0.9255\n",
      "       Current train loss: 0.6026    number of train samples: 12295\n",
      "Iteration 1500: - Train Loss: 0.2724 - Test Loss: 0.2825 - Test Accuracy: 0.9255\n",
      "       Current train loss: 0.6025    number of train samples: 12300\n",
      "Training time: 726.20 seconds\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Entropy Sampling**: Samples where class probability has the largest Entropy",
   "id": "b2433d3fb21e7422"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "learner, metrics = train_active_learner(model_params=model_parameters, query_strat=entropy_sampling, n_query_instances=n_query_instances, epochs=epochs, random_seed=RANDOM_SEED, datasets=datasets, create_model=create_log_reg_model)\n",
    "save_model_and_metrics(experiment, dataset_name, \"uncertainty_entropy_sampling\", learner, metrics)"
   ],
   "id": "bb318d73efbbd6a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Margin Sampling**: Selects instances where difference between first most likely and second most likely classes are the smallest",
   "id": "31e16b8e2de5c8cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "learner, metrics = train_active_learner(model_params=model_parameters, query_strat=margin_sampling, n_query_instances=n_query_instances, epochs=epochs, random_seed=RANDOM_SEED, pool_idx=pool_idx, X_initial=X_initial, y_initial=y_initial)\n",
    "save_model_and_metrics(experiment, dataset_name, \"uncertainty_margin_sampling\", learner, metrics)"
   ],
   "id": "842e3ccea720b828",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "afffb41bb387ae43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Ranked Batch-Mode Sampling\n",
    "\n",
    "$$score=\\alpha\\left(1-\\Phi\\left(x, X_{\\text {labeled }}\\right)\\right)+(1-\\alpha) U(x)$$\n",
    "where $\\alpha=\\frac{\\left|X_{\\text {unlabeled }}\\right|}{\\left|X_{\\text {unlabeled }}\\right|+\\left|X_{\\text {labeled }}\\right|}, X_{\\text {labeled }}$ is the labeled dataset, $U(x)$ is the uncertainty of predictions for $x$, and $\\Phi$ is a so-called similarity function, for instance cosine similarity. This latter function measures how well the feature space is explored near $x$. (The lower the better.)\n",
    "\n",
    "According to the modAL docs: This strategy differs from uncertainty_sampling() because, although it is supported, traditional active learning query strategies suffer from sub-optimal record selection when passing n_instances > 1. This sampling strategy extends the interactive uncertainty query sampling by allowing for batch-mode uncertainty query sampling. Furthermore, it also enforces a ranking – that is, which records among the batch are most important for labeling?"
   ],
   "id": "fe351425d5454487"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "learner, metrics = train_active_learner(model_params=model_parameters, query_strat=uncertainty_batch_sampling, n_query_instances=n_query_instances, epochs=epochs, random_seed=RANDOM_SEED, datasets=datasets, create_model=create_log_reg_model)\n",
    "save_model_and_metrics(experiment, dataset_name, \"ranked_batch_mode\", learner, metrics)"
   ],
   "id": "c29ca5f79c9fd0e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Custom combination between uncertainty of the data point(s) in X and diversity between X and parts of the train dataset",
   "id": "ce39ffdbd8b31fc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "alpha_uc_dv = 0.5\n",
    "def ranked_uc_and_dv_score(learner, X):\n",
    "    uncertainty = classifier_uncertainty(learner, X)\n",
    "    diversity = np.min(pairwise_distances(X, learner.X_training), axis=1)\n",
    "    combined_scores = alpha_uc_dv * uncertainty + (1 - alpha_uc_dv) * diversity\n",
    "    return combined_scores\n",
    "\n",
    "def ranked_uc_and_dv_query(learner, X, n_instances=1):\n",
    "    uc_dv_scores = ranked_uc_and_dv_score(learner, X)\n",
    "    # Sort them in descending order\n",
    "    ranked_indices = np.argsort(uc_dv_scores)[::-1]\n",
    "    selected_indices = ranked_indices[:n_instances]\n",
    "    selected_instances = X[selected_indices]\n",
    "    \n",
    "    return selected_indices, selected_instances\n",
    "\n",
    "for a, a_str in [(0.2, \"0_2\"), (0.5, \"0_5\"), (0.8, \"0_8\")]:\n",
    "    alpha_uc_dv = a\n",
    "    learner, metrics = train_active_learner(model_params=model_parameters, query_strat=ranked_uc_and_dv_query, n_query_instances=n_query_instances, epochs=epochs, random_seed=RANDOM_SEED, datasets=datasets, create_model=create_log_reg_model)\n",
    "    save_model_and_metrics(experiment, dataset_name, f\"ranked_uc_and_dv_{a_str}\", learner, metrics)"
   ],
   "id": "81e38f74bc551cca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Stream-Based sampling",
   "id": "9313d3b94cbcc787"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "with Uncertainty Sampling/ Classifier uncertainty as it's query score method",
   "id": "23207125e2c1d2fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for uncertainty_threshold, uncertainty_threshold_str in [(0.2, \"0_2\"), (0.5, \"0_5\"), (0.8, \"0_8\")]:\n",
    "    learner, metrics = train_active_learner_stream(model_params=model_parameters, query_score_fn=classifier_uncertainty, query_score_threshold=uncertainty_threshold, n_query_instances=n_query_instances, epochs=epochs, random_seed=RANDOM_SEED, X_stream=X_train, y_stream=y_train, X_initial=X_initial, y_initial=y_initial)\n",
    "    save_model_and_metrics(experiment, dataset_name, f\"stream_classifier_uncertainty_th_{uncertainty_threshold_str}\", learner, metrics)"
   ],
   "id": "f6f5e127aa6f12f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "with Classification margin uncertainty as it's query score method",
   "id": "c25eff2e9e5241c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "learner, metrics = train_active_learner_stream(model_params=model_parameters, query_score_fn=classifier_margin, query_score_threshold=0.5, n_query_instances=n_query_instances, epochs=epochs, random_seed=RANDOM_SEED, X_stream=X_train, y_stream=y_train, X_initial=X_initial, y_initial=y_initial)\n",
    "save_model_and_metrics(experiment, dataset_name, \"stream_classifier_margin\", learner, metrics)"
   ],
   "id": "76a83a3c69453ec5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "with Entropy margin uncertainty as it's query score method",
   "id": "1b8491fcd52e92a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "learner, metrics = train_active_learner_stream(model_params=model_parameters, query_score_fn=classifier_entropy, query_score_threshold=0.5, n_query_instances=n_query_instances, epochs=epochs, random_seed=RANDOM_SEED, X_stream=X_train, y_stream=y_train, X_initial=X_initial, y_initial=y_initial)\n",
    "save_model_and_metrics(experiment, dataset_name, \"stream_entropy\", learner, metrics)"
   ],
   "id": "68c1a37d0246eb96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "with the custom measurement of uncertainty and diversity of the already seen datapoints",
   "id": "c1168161a537716"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for uncertainty_threshold, uncertainty_threshold_str in [(0.2, \"0_2\"), (0.5, \"0_5\"), (0.8, \"0_8\")]:\n",
    "    for a, a_str in [(0.1, \"0_2\"), (0.2, \"0_2\"), (0.5, \"0_5\"), (0.8, \"0_8\")]:\n",
    "        alpha_uc_dv = a # this is used by the ranked_uc_and_dv_score method. \n",
    "        learner, metrics = train_active_learner_stream(\n",
    "            model_params=model_parameters, \n",
    "            query_score_fn=ranked_uc_and_dv_score, \n",
    "            query_score_threshold=uncertainty_threshold, \n",
    "            n_query_instances=n_query_instances, \n",
    "            epochs=epochs, random_seed=RANDOM_SEED,\n",
    "            datasets=datasets, create_model=create_log_reg_model)\n",
    "        save_model_and_metrics(experiment, dataset_name, \n",
    "                               f\"stream_classifier_ranked_uc_and_dv_{a_str}_th_{uncertainty_threshold_str}\", \n",
    "                               learner, metrics)"
   ],
   "id": "d0b1004d79d9f7f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Disagreement Sampling (for classifiers) (uses a committee, so I should theoretically do every train run again for each methodwith a committee!)",
   "id": "4229e26196ee7f82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5f60ad2552bc169d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "# Methods that sadly don't work \n",
    "\n",
    "---"
   ],
   "id": "6e0181a457ba1a9e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Expected error reduction (doesn't work on my pc due to time complexity)",
   "id": "64cc96ce3b0ea18b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# learner, metrics = train_active_learner(model_params=model_parameters, query_strat=expected_error_reduction, epochs=epochs, random_seed=RANDOM_SEED, pool_idx=pool_idx, X_initial=X_initial, y_initial=y_initial)",
   "id": "cdc036fb6be26710",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Information Density (doesn't work on my pc due to time complexity)\n",
    "\n",
    "$$I(x)=\\frac{1}{\\left|X_u\\right|} \\sum_{x^{\\prime} \\in X} \\operatorname{sim}\\left(x, x^{\\prime}\\right)$$\n",
    "\n",
    "where $\\operatorname{sim}\\left(x, x^{\\prime}\\right)$ is a similarity function such as cosine similarity or Euclidean similarity, which is the reciprocal of Euclidean distance. The higher the information density, the more similar the given instance is to the rest of the data.\n",
    "\n",
    "\n",
    "According to the modAL docs: When using uncertainty sampling (or other similar strategies), we are unable to take the structure of the data into account which can lead to suboptimal queries.\n",
    "\n",
    "This could very well be used in combination with another strategy"
   ],
   "id": "724ccd53be1e214f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# def inf_density(classifier, X_pool):\n",
    "#     return information_density(X_pool, metric='euclidean')\n",
    "# \n",
    "# learner, metrics = train_active_learner(model_params=model_parameters, query_strat=inf_density,  epochs=epochs, random_seed=RANDOM_SEED, pool_idx=pool_idx, X_initial=X_initial, y_initial=y_initial)"
   ],
   "id": "c75a65b997a22566",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "This is for using it with a Committee (for multiple classes) so it's not optimal for comparing the query strategies themselves maybe?"
   ],
   "id": "ea2db7db79104728"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "Acquisition Functions might not be usable due to the fact that they require a BayesianOptimizer, not an ActiveLearner"
   ],
   "id": "f2cbbd3fbf405c5c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Acquisition Functions",
   "id": "f872cf1438ff1a5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Probability of improvement**: \n",
    "$$PI(x)=\\psi\\left(\\frac{\\mu(x) - f\\left(x^+\\right) - \\xi}{\\sigma(x)}\\right)$$\n",
    "where $\\mu(x)$ and $\\sigma(x)$ are mean and variance of regressor at $x$, $f$ is the model to be optimized with estimated maximum at $x^+$. $\\xi$ is a parameter controlling the degree of exploration and $\\psi(x)$ denotes cumulative distribution function of a standard Gaussian Distribution\n",
    "\n",
    "[Example from the ModAL Docs](https://modal-python.readthedocs.io/en/latest/_images/bo-PI.png)\n"
   ],
   "id": "ef26dec36c690061"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# learner, metrics = train_active_learner(model_params=model_parameters, query_strat=max_PI, epochs=epochs, random_seed=RANDOM_SEED, pool_idx=pool_idx, X_initial=X_initial, y_initial=y_initial)",
   "id": "b77668772d478e5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**[Expected Improvement (from the ModAL Docs)](https://modal-python.readthedocs.io/en/latest/content/query_strategies/Acquisition-functions.html#expected-improvement)**: \n",
    "$$\n",
    "EI(x) = \n",
    "\\left( \\mu(x) - f(x^+) - \\xi \\right) \\cdot \\psi \\left( \\frac{\\mu(x) - f(x^+) - \\xi}{\\sigma(x)} \\right)\n",
    "+ \\sigma(x) \\phi \\left( \\frac{\\mu(x) - f(x^+) - \\xi}{\\sigma(x)} \\right),\n",
    "$$\n",
    "\n",
    "where $\\mu(x)$ and $\\sigma(x)$ are the mean and variance of the regressor at $x$, $f$ is the function to be optimized with estimated maximum at $x$, $\\xi$ is a parameter controlling the degree of exploration, and $\\psi(z), \\phi(z)$ denote the cumulative distribution function and density function of a standard Gaussian distribution."
   ],
   "id": "571c93bd34cf6a53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Upper Confidence Bound**:\n",
    "$$ UCB(x) = \\mu(x) + \\beta \\sigma(x)$$\n",
    "where $\\mu(x)$ and $\\sigma(x)$ are mean and variance of the regressor and $\\beta$ is a parameter controlling the degree of exploration\n",
    "\n",
    "[Example from the ModAL Docs](https://modal-python.readthedocs.io/en/latest/_images/bo-UCB.png)"
   ],
   "id": "e8ebdeda7bf2d25e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
