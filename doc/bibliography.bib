@InProceedings{uncertainty_sampling,
	author="Lewis, David D.
	and Gale, William A.",
	editor="Croft, Bruce W.
	and van Rijsbergen, C. J.",
	title="A Sequential Algorithm for Training Text Classifiers",
	booktitle="SIGIR '94",
	year="1994",
	publisher="Springer London",
	address="London",
	pages="3--12",
	abstract="The ability to cheaply train text classifiers is critical to their use in information retrieval, content analysis, natural language processing, and other tasks involving data which is partly or fully textual. An algorithm for sequential sampling during machine learning of statistical classifiers was developed and tested on a newswire text categorization task. This method, which we call uncertainty sampling, reduced by as much as 500-fold the amount of training data that would have to be manually classified to achieve a given level of effectiveness.",
	isbn="978-1-4471-2099-5"
}

@article{danka_modalmodularactivelearning,
	title={modAL: A modular active learning framework for Python}, 
	author={Tivadar Danka and Peter Horvath},
	year={2018},
	eprint={1805.00979},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/1805.00979}, 
}

@article{scikit-learn,
	title={Scikit-learn: Machine Learning in {P}ython},
	author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
	and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
	and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
	Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
	journal={Journal of Machine Learning Research},
	volume={12},
	pages={2825--2830},
	year={2011}
}

@misc{schröder_revisitinguncertaintybasedquerystrategies,
	title={Revisiting Uncertainty-based Query Strategies for Active Learning with Transformers}, 
	author={Christopher Schröder and Andreas Niekler and Martin Potthast},
	year={2022},
	eprint={2107.05687},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2107.05687}, 
}

@misc{schröder_surveyactivelearningtext,
	title={A Survey of Active Learning for Text Classification using Deep Neural Networks}, 
	author={Christopher Schröder and Andreas Niekler},
	year={2020},
	eprint={2008.07267},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2008.07267}, 
}

@misc{ueno_benchmarkingofquerystrategies,
	title={Benchmarking of Query Strategies: Towards Future Deep Active Learning}, 
	author={Shiryu Ueno and Yusei Yamada and Shunsuke Nakatsuka and Kunihito Kato},
	year={2023},
	eprint={2312.05751},
	archivePrefix={arXiv},
	primaryClass={cs.CV},
	url={https://arxiv.org/abs/2312.05751}, 
}

@misc{werner_comparableactivelearning,
	title={Towards Comparable Active Learning}, 
	author={Thorben Werner and Johannes Burchert and Lars Schmidt-Thieme},
	year={2023},
	eprint={2311.18356},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2311.18356}, 
}

@misc{zhan_comparativesurveydeepactive,
	title={A Comparative Survey of Deep Active Learning}, 
	author={Xueying Zhan and Qingzhong Wang and Kuan-hao Huang and Haoyi Xiong and Dejing Dou and Antoni B. Chan},
	year={2022},
	eprint={2203.13450},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2203.13450}, 
}

@ARTICLE{mnist,
	author={Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	journal={Proceedings of the IEEE}, 
	title={Gradient-based learning applied to document recognition}, 
	year={1998},
	volume={86},
	number={11},
	pages={2278-2324},
	keywords={Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
	doi={10.1109/5.726791}}

@article{ranked_batch_mode_query_strategy,
	title = {Ranked batch-mode active learning},
	journal = {Information Sciences},
	volume = {379},
	pages = {313-337},
	year = {2017},
	issn = {0020-0255},
	doi = {https://doi.org/10.1016/j.ins.2016.10.037},
	url = {https://www.sciencedirect.com/science/article/pii/S0020025516313949},
	author = {Thiago N.C. Cardoso and Rodrigo M. Silva and Sérgio Canuto and Mirella M. Moro and Marcos A. Gonçalves},
	keywords = {Active learning, Batch-mode, New ranking function, Paradigm change},
	abstract = {We introduce a new paradigm for Ranked Batch-Mode Active Learning. It relaxes traditional Batch-Mode Active Learning (BMAL) methods by generating a query whose answer is an optimized ranked list of instances to be labeled, according to some quality criteria, allowing batches to be of arbitrarily large sizes. This new paradigm avoids the main problem of traditional BMAL, namely the frequent stops for manual labeling, reconciliation and model reconstruction. In this article, we formally define this problem and introduce a framework that iteratively and effectively builds the ranked list. Our experimental evaluation shows our proposed Ranked Batch approach significantly reduces the number of algorithm executions (and, consequently, the manual labeling delays) while maintaining or even improving the quality of the selected instances. In fact, when using only unlabeled data, our results are much better than those produced by pool-based batch-mode active learning methods that rely on already labeled seeds or update their models with labeled instances, with gains of up to 25% in MacroF1. Finally, our solutions are also more effective than density-sensitive active learning methods in most of the envisioned scenarios, as demonstrated by our experiments.}
}


@article{cifar,
	title={Learning multiple layers of features from tiny images},
	author={Krizhevsky, Alex and others},
	year={2009}
}

@manual{skorch,
	author       = {Marian Tietz and Thomas J. Fan and Daniel Nouri and Benjamin Bossan and {skorch Developers}},
	title        = {skorch: A scikit-learn compatible neural network library that wraps PyTorch},
	month        = jul,
	year         = 2017,
	url          = {https://skorch.readthedocs.io/en/stable/}
}